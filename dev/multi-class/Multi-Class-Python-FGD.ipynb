{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "91563b1a-ecf7-4505-a59e-70e012ba8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f421c514-5587-4858-a5fa-0ac562c7c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2603,  5.3383],\n",
      "        [ 4.2518,  5.0986],\n",
      "        [ 2.1183,  3.8116],\n",
      "        [ 3.0115,  2.3589],\n",
      "        [ 2.9008,  4.8617],\n",
      "        [ 5.1086,  5.1326],\n",
      "        [ 2.5563,  1.6711],\n",
      "        [ 4.4466,  3.8073],\n",
      "        [ 2.6584,  1.7919],\n",
      "        [ 2.6213,  4.9914],\n",
      "        [ 2.4809,  4.1302],\n",
      "        [ 1.1887,  5.2070],\n",
      "        [ 2.4869,  4.3043],\n",
      "        [ 3.4805,  5.0592],\n",
      "        [ 3.8918,  3.2124],\n",
      "        [ 3.5684,  3.9414],\n",
      "        [ 3.6159,  3.6186],\n",
      "        [ 1.7725,  1.4366],\n",
      "        [ 4.0901,  3.2862],\n",
      "        [ 3.2045,  1.9775],\n",
      "        [ 4.7188,  2.3002],\n",
      "        [ 1.3007,  2.3323],\n",
      "        [ 1.2066,  3.3627],\n",
      "        [ 3.9632,  3.4090],\n",
      "        [ 3.3917,  1.2179],\n",
      "        [-2.6758, -2.8583],\n",
      "        [-5.2805, -3.3999],\n",
      "        [-3.6253, -3.6108],\n",
      "        [-6.0946, -5.4988],\n",
      "        [-3.9991, -5.1169],\n",
      "        [-4.9641, -3.6346],\n",
      "        [-4.4539, -6.0210],\n",
      "        [-4.6465, -5.4079],\n",
      "        [-5.5234, -2.7017],\n",
      "        [-3.2513, -5.4246],\n",
      "        [-2.7528, -2.5072],\n",
      "        [-3.0615, -6.0714],\n",
      "        [-6.5826, -2.9066],\n",
      "        [-5.1490, -6.8728],\n",
      "        [-5.5446, -6.7002],\n",
      "        [-3.2689, -5.0155],\n",
      "        [-3.3461, -5.6423],\n",
      "        [-6.8134, -2.6727],\n",
      "        [-3.6218, -3.6281],\n",
      "        [-5.8004, -5.9196],\n",
      "        [-2.7580, -4.9724],\n",
      "        [-3.3320, -6.6149],\n",
      "        [-4.2950, -4.2662],\n",
      "        [-6.1604, -5.2311],\n",
      "        [-6.6218, -6.6392],\n",
      "        [ 3.5031, -2.6199],\n",
      "        [ 3.0185, -3.8656],\n",
      "        [ 3.0949, -4.4700],\n",
      "        [ 3.7635, -2.5094],\n",
      "        [ 3.6917, -3.9639],\n",
      "        [ 1.4253, -6.0968],\n",
      "        [ 1.3932, -6.0491],\n",
      "        [ 1.0652, -4.5718],\n",
      "        [ 4.7996, -5.7887],\n",
      "        [ 1.7699, -5.8127],\n",
      "        [ 1.8021, -6.0111],\n",
      "        [ 1.5289, -6.1053],\n",
      "        [ 1.8133, -5.6445],\n",
      "        [ 4.0661, -3.2080],\n",
      "        [ 3.9175, -4.5569],\n",
      "        [ 2.9387, -4.9129],\n",
      "        [ 1.7788, -3.8451],\n",
      "        [ 4.6878, -4.7705],\n",
      "        [ 3.2312, -6.9324],\n",
      "        [ 4.8062, -2.8788],\n",
      "        [ 2.3940, -2.6583],\n",
      "        [ 4.1670, -6.8695],\n",
      "        [ 1.6816, -4.7151],\n",
      "        [ 5.3040, -6.4792],\n",
      "        [ 4.6384, -4.5285],\n",
      "        [-6.4219,  3.8642],\n",
      "        [-6.9695,  4.0415],\n",
      "        [-3.3791,  3.4352],\n",
      "        [-5.3905,  4.8096],\n",
      "        [-4.2726,  4.4077],\n",
      "        [-6.1402,  4.7202],\n",
      "        [-4.0631,  3.1786],\n",
      "        [-5.7732,  3.8566],\n",
      "        [-5.7057,  2.3973],\n",
      "        [-4.2144,  4.6344],\n",
      "        [-4.2210,  1.1039],\n",
      "        [-6.6275,  2.3057],\n",
      "        [-3.4277,  5.2370],\n",
      "        [-4.2237,  5.3273],\n",
      "        [-3.7243,  1.7485],\n",
      "        [-6.0882,  1.1203],\n",
      "        [-3.4356,  2.9054],\n",
      "        [-4.7420,  3.9519],\n",
      "        [-3.5167,  2.0618],\n",
      "        [-5.1024,  3.0856],\n",
      "        [-4.0259,  4.1422],\n",
      "        [-2.6676,  1.5427],\n",
      "        [-6.1275,  3.8984],\n",
      "        [-2.7399,  2.4058],\n",
      "        [-2.7007,  3.0725]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load data from CSV file using pandas\n",
    "df = pd.read_csv('data1.csv')\n",
    "\n",
    "# Split the dataframe into x and y tensors\n",
    "x = torch.from_numpy(df[['x1', 'x2']].to_numpy())\n",
    "y = torch.from_numpy(df['y'].to_numpy(dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "70ef594b-5286-4098-a228-a1effcd46771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18860\\1740726160.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(x.T).float().T\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18860\\1740726160.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_unique = torch.unique(torch.tensor(y))\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18860\\1740726160.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_indices = torch.searchsorted(y_unique, torch.tensor(y))\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(x.T).float().T\n",
    "\n",
    "# Convert y to a tensor of indices and one-hot encode it\n",
    "y_unique = torch.unique(torch.tensor(y))\n",
    "y_indices = torch.searchsorted(y_unique, torch.tensor(y))\n",
    "y_train = nn.functional.one_hot(y_indices, num_classes=len(y_unique)).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38efd010-fddb-438a-b086-d817ca685a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "n_hidden = 3\n",
    "D = X.shape[1]\n",
    "out_dim = y_train.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, n_hidden),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_hidden, out_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98d4c1b7-9dd9-4e4e-bbde-5c6fcfa6f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a2e66f99-2410-477f-b30f-eebbac5abf66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  250\n",
      "Loss:  1.1131099462509155\n",
      "Epoch  500\n",
      "Loss:  0.8203388452529907\n",
      "Epoch  750\n",
      "Loss:  0.5208479166030884\n",
      "Epoch  1000\n",
      "Loss:  0.329197496175766\n",
      "Epoch  1250\n",
      "Loss:  0.21610870957374573\n",
      "Epoch  1500\n",
      "Loss:  0.14689311385154724\n",
      "Epoch  1750\n",
      "Loss:  0.10169566422700882\n",
      "Epoch  2000\n",
      "Loss:  0.07326287031173706\n",
      "Epoch  2250\n",
      "Loss:  0.05266139656305313\n",
      "Epoch  2500\n",
      "Loss:  0.03975914791226387\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 2500\n",
    "show_every = epochs // 10\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss_sum = 0\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss_sum += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % show_every == 0:\n",
    "        print(\"Epoch \", epoch)\n",
    "        print(\"Loss: \", loss_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b4b95a56-8936-4f47-be79-6a9007d2fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(model, 'classification',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "36eedab5-ad96-4272-8626-485de48d4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "la.fit(DataLoader(TensorDataset(X, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a2d1e48d-47a8-448c-ad2b-7d6ddb343b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "la.optimize_prior_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "60fd6544-412c-4bda-911c-c4314a0683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probit_predictions = la(X, link_approx='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e41ff86f-cf3f-497f-9fb9-8b066bad02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_probit_df = pd.DataFrame(probit_predictions.numpy(), columns=['class1', 'class2', 'class3', 'class4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e8d01fca-036e-4d17-8e00-377df5ad58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_probit_df.to_csv('predictions1-Python.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0af060a6-43b6-4101-8825-244ec1292c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7583, 0.0355, 0.1054, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7586, 0.0354, 0.1052, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7557, 0.0356, 0.1067, 0.1020],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7587, 0.0354, 0.1050, 0.1009],\n",
      "        [0.7588, 0.0354, 0.1050, 0.1009],\n",
      "        [0.7582, 0.0353, 0.1052, 0.1013],\n",
      "        [0.7588, 0.0353, 0.1049, 0.1010],\n",
      "        [0.7589, 0.0353, 0.1049, 0.1009],\n",
      "        [0.7391, 0.0402, 0.1142, 0.1065],\n",
      "        [0.0175, 0.6928, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0175, 0.6926, 0.1337, 0.1562],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0175, 0.6927, 0.1338, 0.1560],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0175, 0.6927, 0.1337, 0.1561],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0175, 0.6921, 0.1338, 0.1566],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0174, 0.6929, 0.1338, 0.1559],\n",
      "        [0.0513, 0.1418, 0.7582, 0.0486],\n",
      "        [0.0359, 0.1351, 0.7853, 0.0436],\n",
      "        [0.0359, 0.1352, 0.7852, 0.0437],\n",
      "        [0.0858, 0.1589, 0.6919, 0.0633],\n",
      "        [0.0362, 0.1347, 0.7858, 0.0433],\n",
      "        [0.0386, 0.1675, 0.7405, 0.0534],\n",
      "        [0.0391, 0.1708, 0.7356, 0.0545],\n",
      "        [0.0369, 0.1660, 0.7451, 0.0519],\n",
      "        [0.0359, 0.1351, 0.7853, 0.0436],\n",
      "        [0.0354, 0.1403, 0.7795, 0.0448],\n",
      "        [0.0354, 0.1405, 0.7792, 0.0449],\n",
      "        [0.0367, 0.1553, 0.7588, 0.0492],\n",
      "        [0.0355, 0.1388, 0.7813, 0.0444],\n",
      "        [0.0505, 0.1426, 0.7576, 0.0493],\n",
      "        [0.0360, 0.1350, 0.7855, 0.0435],\n",
      "        [0.0358, 0.1353, 0.7851, 0.0437],\n",
      "        [0.0357, 0.1362, 0.7842, 0.0439],\n",
      "        [0.0363, 0.1344, 0.7862, 0.0430],\n",
      "        [0.0358, 0.1353, 0.7851, 0.0437],\n",
      "        [0.2223, 0.1640, 0.5460, 0.0677],\n",
      "        [0.0363, 0.1349, 0.7855, 0.0434],\n",
      "        [0.0358, 0.1353, 0.7852, 0.0437],\n",
      "        [0.0355, 0.1380, 0.7823, 0.0443],\n",
      "        [0.0359, 0.1352, 0.7853, 0.0437],\n",
      "        [0.0368, 0.1342, 0.7862, 0.0429],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6540],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6540],\n",
      "        [0.0764, 0.2007, 0.0702, 0.6527],\n",
      "        [0.0746, 0.2011, 0.0704, 0.6539],\n",
      "        [0.0765, 0.2008, 0.0699, 0.6527],\n",
      "        [0.0743, 0.2012, 0.0705, 0.6540],\n",
      "        [0.0744, 0.2012, 0.0705, 0.6539],\n",
      "        [0.0743, 0.2012, 0.0705, 0.6540],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6540],\n",
      "        [0.0794, 0.2010, 0.0698, 0.6498],\n",
      "        [0.0742, 0.2015, 0.0706, 0.6536],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6540],\n",
      "        [0.2336, 0.2045, 0.0803, 0.4815],\n",
      "        [0.1131, 0.2104, 0.0770, 0.5995],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6539],\n",
      "        [0.0742, 0.2013, 0.0706, 0.6538],\n",
      "        [0.0748, 0.2010, 0.0705, 0.6537],\n",
      "        [0.0745, 0.2012, 0.0705, 0.6539],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6539],\n",
      "        [0.0743, 0.2012, 0.0705, 0.6540],\n",
      "        [0.0765, 0.2008, 0.0700, 0.6527],\n",
      "        [0.0747, 0.2008, 0.0710, 0.6535],\n",
      "        [0.0743, 0.2012, 0.0706, 0.6540],\n",
      "        [0.0757, 0.2003, 0.0710, 0.6530],\n",
      "        [0.0807, 0.1995, 0.0714, 0.6484]])\n"
     ]
    }
   ],
   "source": [
    "print(probit_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c808641c-6918-47fc-b820-7b1f7e2b4732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9938,     0.0001,     0.0032,     0.0029],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0032,     0.0029],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9933,     0.0001,     0.0035,     0.0031],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0032,     0.0028],\n",
      "        [    0.9939,     0.0001,     0.0032,     0.0028],\n",
      "        [    0.9938,     0.0001,     0.0032,     0.0029],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0029],\n",
      "        [    0.9939,     0.0001,     0.0031,     0.0028],\n",
      "        [    0.9933,     0.0001,     0.0037,     0.0029],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0298],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9494,     0.0207,     0.0299],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9494,     0.0207,     0.0298],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9494,     0.0207,     0.0298],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9492,     0.0207,     0.0300],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0000,     0.9495,     0.0207,     0.0297],\n",
      "        [    0.0043,     0.0386,     0.9539,     0.0032],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.0113,     0.0404,     0.9454,     0.0029],\n",
      "        [    0.0018,     0.0370,     0.9578,     0.0034],\n",
      "        [    0.0017,     0.0540,     0.9396,     0.0048],\n",
      "        [    0.0017,     0.0555,     0.9380,     0.0049],\n",
      "        [    0.0017,     0.0553,     0.9382,     0.0049],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.0017,     0.0406,     0.9540,     0.0037],\n",
      "        [    0.0017,     0.0407,     0.9538,     0.0038],\n",
      "        [    0.0017,     0.0484,     0.9456,     0.0043],\n",
      "        [    0.0017,     0.0396,     0.9550,     0.0037],\n",
      "        [    0.0041,     0.0385,     0.9542,     0.0032],\n",
      "        [    0.0018,     0.0369,     0.9579,     0.0034],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.0017,     0.0376,     0.9572,     0.0035],\n",
      "        [    0.0019,     0.0370,     0.9577,     0.0034],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.1055,     0.0414,     0.8509,     0.0022],\n",
      "        [    0.0018,     0.0370,     0.9577,     0.0034],\n",
      "        [    0.0017,     0.0369,     0.9580,     0.0035],\n",
      "        [    0.0017,     0.0390,     0.9557,     0.0036],\n",
      "        [    0.0017,     0.0369,     0.9579,     0.0035],\n",
      "        [    0.0020,     0.0371,     0.9575,     0.0034],\n",
      "        [    0.0017,     0.0386,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0386,     0.0016,     0.9580],\n",
      "        [    0.0019,     0.0392,     0.0017,     0.9572],\n",
      "        [    0.0017,     0.0388,     0.0016,     0.9579],\n",
      "        [    0.0020,     0.0394,     0.0017,     0.9570],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0386,     0.0016,     0.9580],\n",
      "        [    0.0023,     0.0402,     0.0017,     0.9558],\n",
      "        [    0.0017,     0.0389,     0.0016,     0.9578],\n",
      "        [    0.0017,     0.0386,     0.0016,     0.9580],\n",
      "        [    0.0937,     0.0576,     0.0020,     0.8466],\n",
      "        [    0.0074,     0.0462,     0.0018,     0.9446],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0388,     0.0017,     0.9579],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9579],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0017,     0.0387,     0.0016,     0.9580],\n",
      "        [    0.0019,     0.0394,     0.0017,     0.9570],\n",
      "        [    0.0017,     0.0386,     0.0017,     0.9580],\n",
      "        [    0.0017,     0.0386,     0.0016,     0.9580],\n",
      "        [    0.0018,     0.0386,     0.0017,     0.9578],\n",
      "        [    0.0024,     0.0395,     0.0018,     0.9563]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(torch.softmax(model(X), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac439d6-5d33-42ed-b2a6-3160095a4364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
