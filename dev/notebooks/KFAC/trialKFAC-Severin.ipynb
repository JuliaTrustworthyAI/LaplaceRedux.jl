{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials for KFAC\n",
    "## Generic setup (regression task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `~/Builds/navimakarov/LaplaceRedux.jl/dev/notebooks/KFAC`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "using LaplaceRedux\n",
    "using LaplaceRedux.Curvature\n",
    "using LaplaceRedux.Data\n",
    "using Flux\n",
    "using Flux.Optimise: update!, Adam\n",
    "using Plots\n",
    "using Statistics\n",
    "using MLUtils\n",
    "using Zygote\n",
    "using Printf\n",
    "using NNlib\n",
    "using BenchmarkTools\n",
    "using Tullio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Any} with 6 entries:\n",
       "  :loss_fun   => :mse\n",
       "  :y          => [-1.262, -1.1485, 0.481103, 0.50312, 0.127531, 0.926667, 0.548…\n",
       "  :likelihood => :regression\n",
       "  :X          => [5.92924 5.43385 … 2.16465 2.10173]\n",
       "  :outdim     => 1\n",
       "  :data       => zip([[5.92924], [5.43385], [0.0184016], [7.39229], [3.0214], […"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init data\n",
    "n = 2000\n",
    "data_dict = Dict()\n",
    "bsize = 10\n",
    "\n",
    "x, y = LaplaceRedux.Data.toy_data_regression(n)\n",
    "xs = [[x] for x in x]\n",
    "X, Y = reduce(hcat, x), reduce(hcat, y)\n",
    "\n",
    "# dataloader = DataLoader((X, Y), batchsize=bsize)\n",
    "data = zip(xs, y)\n",
    "data_dict[:regression] = Dict(\n",
    "    :data => data,\n",
    "    :X => X,\n",
    "    :y => y,\n",
    "    :outdim => 1,\n",
    "    :loss_fun => :mse,\n",
    "    :likelihood => :regression,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "avg_loss(data) = 0.12874358820331147\n",
      "Epoch 40\n",
      "avg_loss(data) = 0.10347437301783545\n",
      "Epoch 60\n",
      "avg_loss(data) = 0.10231741089512186\n",
      "Epoch 80\n",
      "avg_loss(data) = 0.10168368867405946\n",
      "Epoch 100\n",
      "avg_loss(data) = 0.10121858614785856\n",
      "Epoch 120\n",
      "avg_loss(data) = 0.10084111537955492\n",
      "Epoch 140\n",
      "avg_loss(data) = 0.10052853379181098\n",
      "Epoch 160\n",
      "avg_loss(data) = 0.1002574346800815\n",
      "Epoch 180\n",
      "avg_loss(data) = 0.1000226570480998\n",
      "Epoch 200\n",
      "avg_loss(data) = 0.09982129551631228\n"
     ]
    }
   ],
   "source": [
    "# Train a NN model\n",
    "\n",
    "val = data_dict[:regression]\n",
    "\n",
    "# Unpack:\n",
    "data = val[:data]\n",
    "X = val[:X]\n",
    "y = val[:y]\n",
    "outdim = val[:outdim]\n",
    "loss_fun = val[:loss_fun]\n",
    "likelihood = val[:likelihood]\n",
    "\n",
    "# Neural network:\n",
    "n_hidden = 32\n",
    "D = size(X, 1)\n",
    "nn = Chain(Dense(D, n_hidden, σ), Dense(n_hidden, outdim))\n",
    "λ = 0.01\n",
    "sqnorm(x) = sum(abs2, x)\n",
    "weight_regularization(λ=λ) = 1 / 2 * λ^2 * sum(sqnorm, Flux.params(nn))\n",
    "loss(x, y) = getfield(Flux.Losses, loss_fun)(nn(x), y) + weight_regularization()\n",
    "\n",
    "\n",
    "opt = Adam()\n",
    "epochs = 200\n",
    "avg_loss(data) = mean(map(d -> loss(d[1], d[2]), data))\n",
    "show_every = epochs / 10\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    for d in data\n",
    "        gs = gradient(Flux.params(nn)) do\n",
    "            l = loss(d...)\n",
    "        end\n",
    "        update!(opt, Flux.params(nn), gs)\n",
    "    end\n",
    "    if epoch % show_every == 0\n",
    "        println(\"Epoch \" * string(epoch))\n",
    "        @show avg_loss(data)\n",
    "    end\n",
    "end\n",
    "\n",
    "H_facs = nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Hessian of a Neural Network Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(1 => 32, σ),                    \u001b[90m# 64 parameters\u001b[39m\n",
       "  Dense(32 => 1),                       \u001b[90m# 33 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m97 parameters, 644 bytes."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(x, ytrue; agg=sum) = Flux.Losses.mse(nn(x), ytrue, agg=agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.261995723816228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take one datapoint of the dataset\n",
    "x_1 = xs[1]\n",
    "y_1 = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grads(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the hessian of the loss\n",
    "grads = Zygote.gradient(() -> loss_fn(x_1, y_1), Flux.params(nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((layers = ((weight = Float32[-2.2066584; 1.411073; … ; 1.6480361; 0.62337846;;], bias = Float32[-0.3721656, 0.23798554, 0.31260532, -0.02089224, -0.34583318, -0.29921088, -0.013121896, 0.00014830951, 0.21144705, -0.0111340135  …  -0.3056786, -0.41584235, 0.0075681033, -0.40174413, -0.011366533, 0.25009236, -0.00035169677, -0.0008173855, 0.27795073, 0.10513635], σ = nothing), (weight = Float32[0.42643642 1.3213153 … 1.3520786 0.06196431], bias = Float32[1.8672906], σ = nothing)),),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alts = Zygote.gradient(nn -> Flux.Losses.mse(nn(x_1), y_1), nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(layers = ((weight = Float32[-2.2066584; 1.411073; … ; 1.6480361; 0.62337846;;], bias = Float32[-0.3721656, 0.23798554, 0.31260532, -0.02089224, -0.34583318, -0.29921088, -0.013121896, 0.00014830951, 0.21144705, -0.0111340135  …  -0.3056786, -0.41584235, 0.0075681033, -0.40174413, -0.011366533, 0.25009236, -0.00035169677, -0.0008173855, 0.27795073, 0.10513635], σ = nothing), (weight = Float32[0.42643642 1.3213153 … 1.3520786 0.06196431], bias = Float32[1.8672906], σ = nothing)),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alts = alts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"32×1 Matrix{Float32}\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(alts.layers[1].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"32×1 Matrix{Float32}\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(nn.layers[1].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert grads.grads[grads.params[1]] == alts.layers[1].weight\n",
    "@assert grads.grads[grads.params[2]] == alts.layers[1].bias\n",
    "@assert grads.grads[grads.params[3]] == alts.layers[2].weight\n",
    "@assert grads.grads[grads.params[4]] == alts.layers[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((layers = ((weight = Float32[-2.2066584; 1.411073; … ; 1.6480361; 0.62337846;;], bias = Float32[-0.3721656, 0.23798554, 0.31260532, -0.02089224, -0.34583318, -0.29921088, -0.013121896, 0.00014830951, 0.21144705, -0.0111340135  …  -0.3056786, -0.41584235, 0.0075681033, -0.40174413, -0.011366533, 0.25009236, -0.00035169677, -0.0008173855, 0.27795073, 0.10513635], σ = nothing), (weight = Float32[0.42643642 1.3213153 … 1.3520786 0.06196431], bias = Float32[1.8672906], σ = nothing)),),)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m25.066 μs\u001b[22m\u001b[39m … \u001b[35m  8.235 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 98.01%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m29.196 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m40.278 μs\u001b[22m\u001b[39m ± \u001b[32m138.012 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m5.79% ±  1.70%\n",
       "\n",
       "  \u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m▁\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m▁\u001b[39m\u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m▂\u001b[39m▄\u001b[39m▄\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  25.1 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        94 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m14.59 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m88\u001b[39m."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark Zygote.gradient(() -> Flux.Losses.mse($nn($x_1), $y_1), Flux.params($nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m16.640 μs\u001b[22m\u001b[39m … \u001b[35m  8.162 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 98.21%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m27.938 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m32.988 μs\u001b[22m\u001b[39m ± \u001b[32m114.243 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m4.79% ±  1.39%\n",
       "\n",
       "  \u001b[39m▄\u001b[39m▂\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m▁\u001b[39m\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m▂\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  16.6 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        78 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m10.56 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m56\u001b[39m."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark Zygote.gradient(nn -> Flux.Losses.mse(nn($x_1), $y_1), $nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## H = Zygote.hessian(nn -> Flux.Losses.mse(nn(x_1), y_1), nn)\n",
    "## H = ForwardDiff.hessian(nn -> Flux.Losses.mse(nn(x_1), y_1), nn)\n",
    "# MethodError: no method matching hessian(::var\"#47#48\", ::Chain{Tuple{Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})\n",
    "# H = Zygote.hessian(nn -> Flux.Losses.mse(nn(x_1), y_1), nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.213 ms (1554 allocations: 818.73 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97×97 Matrix{Float64}:\n",
       " -4.31483      -1.78604      -2.34605      …  -0.0784301    -2.36349\n",
       " -1.78604      -2.33189       1.50021          0.050153      1.51136\n",
       " -2.34605       1.50021      -2.77862          0.0658784     1.98524\n",
       "  0.156792     -0.100263     -0.1317          -0.00440283   -0.132679\n",
       "  2.59541      -1.65967      -2.18005         -0.0728808    -2.19626\n",
       "  2.24552      -1.43593      -1.88616      …  -0.0630556    -1.90018\n",
       "  0.0984774    -0.0629725    -0.0827174       -0.0027653    -0.0833323\n",
       " -0.00111304    0.000711744   0.000934909      3.12547e-5    0.000941859\n",
       " -1.58687       1.01474       1.33291          0.0445603     1.34282\n",
       "  0.0835587    -0.0534325    -0.0701862       -0.00234638   -0.0707079\n",
       "  2.7635       -1.76715      -2.32124      …  -0.0776009    -2.3385\n",
       "  0.144891     -0.092652     -0.121703        -0.00406862   -0.122608\n",
       " -2.37882       1.52117       1.99812          0.0667988     2.01298\n",
       "  ⋮                                        ⋱   ⋮            \n",
       " -1.68555       1.07784       1.4158       …   0.0473311     1.42632\n",
       " -0.495823      0.31706       0.416473         0.013923      0.419569\n",
       " -0.547085      0.34984       0.459532         0.0153625     0.462948\n",
       " -0.0141239     0.00903166    0.0118635        0.000396606   0.0119517\n",
       " -0.550057      0.35174       0.462028         0.0154459     0.465463\n",
       " -2.3134        1.47933       1.94317      …   0.0649617     1.95762\n",
       " -1.68222       1.07571       1.413            0.0472377     1.42351\n",
       " -0.000783948   0.000501305   0.000658487      2.20137e-5    0.000663383\n",
       " -0.000943983   0.000603641   0.000792911      2.65076e-5    0.000798806\n",
       " -1.71137       1.09435       1.43749          0.0480562     1.44817\n",
       " -0.0784301     0.050153      0.0658784    …   0.00220237    0.0663681\n",
       " -2.36349       1.51136       1.98524          0.0663681     2.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://fluxml.ai/Flux.jl/stable/destructure/\n",
    "model = nn\n",
    "theta, rebuild = Flux.destructure(model)\n",
    "\n",
    "function lossv(theta::Vector)\n",
    "    m = rebuild(theta)\n",
    "    Flux.Losses.mse(m(x_1), y_1)\n",
    "end;\n",
    "\n",
    "@btime Zygote.hessian(lossv, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = nnl\n",
    "# lossfn = model -> Flux.Losses.mse(model(x_1), y_1)\n",
    "# grad = model -> Zygote.gradient(model -> lossfn(model), model)\n",
    "# jacob = model -> Zygote.jacobian(grad, model)\n",
    "# jacob(model) ## does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## H = jacobian(() -> flat(gradient(() -> Flux.Losses.mse(nn(x_1), y_1), Flux.params(nn))), Flux.params(nn))\n",
    "# Can't differentiate foreigncall expression $(Expr(:foreigncall, :(:jl_eqtable_get), Any, svec(Any, Any, Any), 0, :(:ccall), %5, %3, %4)).\n",
    "# You might want to check the Zygote limitations documentation.\n",
    "# https://fluxml.ai/Zygote.jl/latest/limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size (generic function with 195 methods)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: size\n",
    "size(ps::Params) = (length(ps), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flat (generic function with 1 method)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat(grads::Zygote.Grads) = reduce(vcat, [vec(grads[t]) for t in grads.params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n",
      "(32,)\n",
      "(1, 32)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "foreach(x -> println(size(x)), grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kron1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct Kron1\n",
    "#    kfacs :: Union{Vector{Tuple{AbstractArray, AbstractArray}},Vector{Matrix},Nothing}\n",
    "    kfacs :: Vector{Tuple{AbstractArray, AbstractArray}}\n",
    "end\n",
    "\n",
    "Kron = Kron1\n",
    "    \n",
    "# mutable struct KronDecomposed\n",
    "#     eigenvectors :: Union{AbstractArray,Nothing}\n",
    "#     eigenvalues :: Union{AbstractArray,Nothing}\n",
    "#     damping :: Bool\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "== (generic function with 185 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +, ==, *\n",
    "\n",
    "function (+)(l::Kron, r::Kron)\n",
    "    @assert length(l.kfacs) == length(r.kfacs)\n",
    "    kfacs = [Tuple(Hi + Hj for (Hi, Hj) in zip(Fi, Fj))\n",
    "                for (Fi, Fj) in zip(l.kfacs, r.kfacs)]\n",
    "    return Kron(kfacs)\n",
    "end\n",
    "\n",
    "function (==)(l::Kron, r::Kron)\n",
    "    return l.kfacs == r.kfacs\n",
    "end\n",
    "\n",
    "# H = [[Fi + Fj for (Fi, Fj) in zip(Fi_row, Fj_row)] for (Fi_row, Fj_row) in zip(H.kfacs, H_batch.kfacs)]\n",
    "#        kfacs = [[Hi.add(Hj) for Hi, Hj in zip(Fi, Fj)]\n",
    "#                 for Fi, Fj in zip(self.kfacs, other.kfacs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Kron([([1 2], [3 4])])\n",
    "right = Kron([([5 6], [7 8])])\n",
    "total = left + right\n",
    "@test total.kfacs == [([6 8], [10 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Kron([([1 2], [3 4]), ([11 12], [13 14])])\n",
    "right = Kron([([5 6], [7 8]), ([15 16], [17 18])])\n",
    "total = left + right\n",
    "@test total.kfacs == [([6 8], [10 12]), ([26 28], [30 32])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Kron([])\n",
    "total = left + left\n",
    "@test total == left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "      Thrown: AssertionError"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Kron([([1 2], [3 4]), ([], [])])\n",
    "right = Kron([([5 6], [7 8])])\n",
    "@test_throws AssertionError left + right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Tuple{Int64, Int64}}:\n",
       " (1, 4)\n",
       " (2, 5)\n",
       " (3, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(zip([1, 2, 3], [4, 5, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 311 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function (*)(l::Real, r::Kron)\n",
    "        kfacs = [Tuple(^(l, 1/length(F)) * Hi for Hi in F) for F in r.kfacs]\n",
    "        return Kron(kfacs)\n",
    "end\n",
    "\n",
    "(*)(l::Kron, r::Real) = (*)(r, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = 4\n",
    "right = Kron([([5 6], [7 8])])\n",
    "@test left * right == right * left\n",
    "@test (left * right).kfacs == [([10 12], [14 16])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andrei's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init(model)\n",
    "    kfacs = []\n",
    "\n",
    "    for p in Flux.params(model)\n",
    "        if ndims(p) == 1  # bias\n",
    "            P = size(p, 1)\n",
    "            push!(kfacs, [zeros(P, P)])\n",
    "        elseif 4 >= ndims(p) >= 2  # fully connected or conv\n",
    "            if ndims(p) == 2  # fully connected\n",
    "                P_in, P_out = size(p)\n",
    "            elseif ndims(p) > 2\n",
    "                P_in, P_out = size(p, 1), prod(size(p)[2:end])\n",
    "            end\n",
    "            \n",
    "            push!(kfacs, [\n",
    "                zeros(P_in, P_in),\n",
    "                zeros(P_out, P_out)\n",
    "            ])\n",
    "        else\n",
    "            error(\"Invalid parameter shape in network.\")\n",
    "        end\n",
    "    end\n",
    "    # @show kfacs\n",
    "    # @show get_array_sizes(kfacs)\n",
    "    # @show print_arrays(kfacs)\n",
    "    return Kron(kfacs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitBeta (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function fitBeta(la::Laplace, data; batched::Bool=false, batchsize::Int, override::Bool=true)\n",
    "    if override\n",
    "        H = init(la.model)          \n",
    "        loss = 0.0\n",
    "        n_data = 0\n",
    "    end\n",
    "\n",
    "    # Training:\n",
    "    for d in data\n",
    "        x, y = d\n",
    "        loss_batch, H_batch =_curv_closure(la.curvature, x, y, length(data))\n",
    "        loss += loss_batch\n",
    "        @show(H_batch)\n",
    "        @show(H)\n",
    "        H = [[Fi + Fj for (Fi, Fj) in zip(Fi_row, Fj_row)] for (Fi_row, Fj_row) in zip(H.kfacs, H_batch.kfacs)]\n",
    "        n_data += batchsize\n",
    "    end\n",
    "\n",
    "    # Store output:\n",
    "    la.loss = loss                                                           # Loss\n",
    "    la.H = H                                                                 # Hessian\n",
    "    la.P = posterior_precision(la)                                           # posterior precision\n",
    "    la.Σ = posterior_covariance(la)                                          # posterior covariance\n",
    "    return la.n_data = n_data                                                # number of observations\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitAux (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting kron\n",
    "function fitAux(la, train_loader, override=true, damping=false)\n",
    "    if override\n",
    "        H_facs = nothing\n",
    "    end\n",
    "\n",
    "    if !isnothing(H_facs)\n",
    "        n_data_old = la.n_data\n",
    "        n_data_new = length(train_loader)\n",
    "        la.H = init(la.model) # re-init H non-decomposed\n",
    "        # discount previous Kronecker factors to sum up properly together with new ones\n",
    "        H_facs = _rescale_factors(H_facs, n_data_old / (n_data_old + n_data_new))\n",
    "    end\n",
    "\n",
    "    fitBeta(la, train_loader, batched=false, batchsize=1, override=override)\n",
    "\n",
    "    if isnothing(H_facs)\n",
    "        H_facs =la.H\n",
    "    else\n",
    "        # discount new factors that were computed assuming N = n_data_new\n",
    "        la.H = _rescale_factors(la.H, n_data_new / (n_data_new + n_data_old))\n",
    "        H_facs += la.H\n",
    "    end\n",
    "    # Decompose to self.H for all required quantities but keep H_facs for further inference\n",
    "    la.H = decompose(la.H_facs, damping=damping)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_curv_closure (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function _curv_closure(curvature, x, y, N)\n",
    "    return kron(curvature, x, y, N) #la.backend.kron(X, y, N=N)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterior_precision (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function posterior_precision(la::Laplace, H=la.H, P₀=la.P₀)\n",
    "    @assert !isnothing(H) \"Hessian not available. Either no value supplied or Laplace Approximation has not yet been estimated.\"\n",
    "    return H .+ P₀\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterior_covariance (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function posterior_covariance(la::Laplace, P=posterior_precision(la))\n",
    "    @assert !isnothing(P) \"Posterior precision not available. Either no value supplied or Laplace Approximation has not yet been estimated.\"\n",
    "    return inv(P)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kron (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function kron(curvature, x, y, N)\n",
    "    #context = ifelse(self.stochastic, KFAC, KFLR)\n",
    "    loss = curvature.factor * curvature.loss_fun(x, y)\n",
    "    𝐠 = gradient(() -> curvature.loss_fun(x, y), Flux.params(curvature.model))\n",
    "    𝐠 = reduce(vcat, [vec(𝐠[i]') for i in curvature.params])  \n",
    "    # backpack(context()) do\n",
    "    #     backward(loss)\n",
    "    # end\n",
    "    kron = Kron(𝐠)\n",
    "    @show(kron)\n",
    "    kron = _rescale_kron_factors(kron, length(y), N)\n",
    "    return curvature.factor * loss, kron#curvature.factor * detach(loss), curvature.factor * kron\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decompose (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function decompose(kron,damping=false)\n",
    "    \"\"\"\n",
    "    Eigendecompose Kronecker factors and turn into `KronDecomposed`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    damping : bool\n",
    "        use damping\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kron_decomposed : KronDecomposed\n",
    "    \"\"\"\n",
    "    eigvecs = []\n",
    "    eigvals = []\n",
    "    for F in kron.kfacs\n",
    "        Qs = []\n",
    "        ls = []\n",
    "        for Hi in F\n",
    "            l, Q = symeig(Hi)\n",
    "            push!(Qs, Q)\n",
    "            push!(ls, l)\n",
    "        push!(eigvecs, Qs)\n",
    "        push!(eigvals, ls)\n",
    "        end\n",
    "    end\n",
    "    return KronDecomposed(eigvecs, eigvals, damping=damping)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_rescale_factors (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function _rescale_factors(kron, factor)\n",
    "    for F in kron.kfacs\n",
    "        if length(F) == 2\n",
    "            F[1] *= factor\n",
    "        end\n",
    "    end\n",
    "    return kron\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_rescale_kron_factors (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function _rescale_kron_factors(kron, M, N)\n",
    "    # Renormalize Kronecker factor to sum up correctly over N data points with batches of M\n",
    "    # for M=N (full-batch) just M/N=1\n",
    "    for F in kron.kfacs\n",
    "        if length(F) == 2\n",
    "            F[1] *= M/N\n",
    "        end\n",
    "    end\n",
    "    return kron\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid iteration specification",
     "output_type": "error",
     "traceback": [
      "syntax: invalid iteration specification",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:2"
     ]
    }
   ],
   "source": [
    "function _get_kron_factors(la)\n",
    "    return Kron([p.kfac for p la.model.parameters])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200-element DataLoader(::Tuple{Matrix{Float64}, Matrix{Float64}}, batchsize=10)\n",
       "  with first element:\n",
       "  (1×10 Matrix{Float64}, 1×10 Matrix{Float64},)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataloader = DataLoader((X, Y), batchsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_la (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function fit_la(nn, dataloader, X, y)\n",
    "#     la_b = Laplace(nn; likelihood=:regression, λ=λ, subset_of_weights=:all)\n",
    "#     fitAux(la_b, dataloader)\n",
    "#     plot(la_b, X, y )\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit_la(nn, dataloader, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
