{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f17de2-78ab-440a-816f-5fb6bae540a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make a replica of LA as in the julia example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72fe05d-e9f3-444e-beaf-46fe85619244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from laplace import Laplace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(43)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d12100-6d73-430f-af73-695ebe2b95c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data from csv\n",
    "\n",
    "# Load data from CSV file using pandas\n",
    "df = pd.read_csv('data1.csv')\n",
    "\n",
    "# Split the dataframe into x and y tensors\n",
    "x = torch.from_numpy(df[['x1', 'x2']].to_numpy()).to(torch.float32)\n",
    "y = torch.from_numpy(df['y'].to_numpy(dtype=int))\n",
    "\n",
    "X = x.T\n",
    "\n",
    "y_unique = torch.unique(y)\n",
    "y_indices = y - 1\n",
    "y_train = nn.functional.one_hot(y_indices, num_classes=len(y_unique)).float()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a101f250-11a1-455c-ac7c-69028d430442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "data = list(zip(x, y_train))\n",
    "n_hidden = 3\n",
    "D = X.shape[0]  # == 2\n",
    "out_dim = y_train.shape[1]  # == 4\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, n_hidden),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_hidden, out_dim)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "# epochs = 200\n",
    "# avg_loss = lambda data: torch.mean(torch.stack([loss_fn(model(x), y) for (x, y) in data]))\n",
    "# show_every = epochs // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b51d72-3fc5-4123-ab97-66c78668d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model from json\n",
    "\n",
    "with open('nn.json') as fin:\n",
    "    nn_json_str = fin.read()\n",
    "    nn_json = json.loads(nn_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08e656d-4e54-4f73-882b-bb1e41112a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': [-0.14515024, 0.80743283, 1.2083956],\n",
       "  'weight': [[-0.49617776, -0.29888734, 2.791775],\n",
       "   [-1.1155951, 2.777497, -0.07422561]]},\n",
       " {'bias': [-0.5658274, 0.6530026, -0.5378328, 0.25649628],\n",
       "  'weight': [[-4.0386014, 1.5438478, 0.19519025, -2.0000153],\n",
       "   [-0.27907616, -4.3666024, -5.0731287, 1.5551064],\n",
       "   [1.7367028, -3.2249343, 2.2207005, -4.285545]]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bad416-e229-4ad1-9ae0-02339e272cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4913/2716246838.py:12: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  tensor_b = torch.tensor(layer_read['bias']).T\n"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad():\n",
    "\n",
    "assert len(model.state_dict()) == 2 * len(nn_json)\n",
    "iter_states = iter(model.state_dict())\n",
    "\n",
    "# for layer in model.state_dict():\n",
    "#     print(layer)\n",
    "for layer_read in nn_json:\n",
    "    state_w = next(iter_states)\n",
    "    state_b = next(iter_states)\n",
    "    tensor_w = torch.tensor(layer_read['weight']).T\n",
    "    tensor_b = torch.tensor(layer_read['bias']).T\n",
    "    model.state_dict()[state_w].data.copy_(tensor_w)\n",
    "    model.state_dict()[state_b].data.copy_(tensor_b)\n",
    "    # model.state_dict()[layer].data.fill_(const)\n",
    "    \n",
    "# NOTE: DOES NOT WORK\n",
    "# params = list(model.parameters())\n",
    "# assert len(params) == 2 * len(nn_json)\n",
    "# for idx_layer in range(len(nn_json)):\n",
    "#     layer = nn_json[idx_layer]\n",
    "#     idx_param_w = idx_layer * 2\n",
    "#     idx_param_b = idx_param_w + 1\n",
    "#     print(torch.tensor(layer['weight']).T)\n",
    "#     print(torch.tensor(layer['bias']).T)\n",
    "#     params[idx_param_w].data = torch.tensor(layer['weight']).T\n",
    "#     params[idx_param_b].data = torch.tensor(layer['bias']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d92d8e1-b1f3-49cd-bac6-adf2abc7f4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.4962, -1.1156],\n",
       "         [-0.2989,  2.7775],\n",
       "         [ 2.7918, -0.0742]]),\n",
       " tensor([-0.1452,  0.8074,  1.2084]),\n",
       " tensor([[-4.0386, -0.2791,  1.7367],\n",
       "         [ 1.5438, -4.3666, -3.2249],\n",
       "         [ 0.1952, -5.0731,  2.2207],\n",
       "         [-2.0000,  1.5551, -4.2855]]),\n",
       " tensor([-0.5658,  0.6530, -0.5378,  0.2565])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.state_dict()[layer].data for layer in model.state_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1000d90-54be-4c70-909c-c15b378af563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_hat = torch.argmax(torch.softmax(model.forward(x), dim=1), dim=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42caf855-b472-4980-ad7c-a8f142d3c7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat == y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9524777-b323-46d5-ac43-b0efd0930e74",
   "metadata": {},
   "source": [
    "## Laplace Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcad8437-2019-4c23-a727-50d58ea325d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(model, 'classification',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1538669-15b9-4771-8d62-7dfb66b4c826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la.fit(DataLoader(TensorDataset(x, y_train), batch_size=1))\n",
    "# NOTE: batch size 1 since there is no batching in Julia (yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc1f43a-dd1c-4e8d-b509-a0a8dc371ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     7.3767,     -3.7364,     -0.0546,      0.0092,     -0.0039,\n",
       "              0.0019,     -0.6562,      0.0065,      0.0006,     -0.0466,\n",
       "              1.0685,     -0.5575,     -0.3250,     -0.9833,      0.2835,\n",
       "              0.1213,     -0.0023,      0.2356,      0.2502,     -0.0829,\n",
       "              0.0384,      0.6027,     -0.7324,      0.2051,     -0.0754],\n",
       "        [    -3.7364,      2.2330,      0.0092,     -0.0060,      0.0019,\n",
       "             -0.0060,      0.2223,     -0.0026,     -0.0009,      0.1228,\n",
       "             -0.8440,      0.2922,     -0.0784,      0.4128,     -0.2649,\n",
       "             -0.0386,      0.0576,     -0.0692,     -0.0058,      0.3736,\n",
       "              0.0419,     -0.4785,      0.1213,     -0.0320,      0.3892],\n",
       "        [    -0.0546,      0.0092,      0.0174,      0.0058,     -0.0001,\n",
       "             -0.0001,      0.0065,      0.0020,     -0.0000,      0.0012,\n",
       "              0.0069,      0.0062,      0.0204,      0.0144,     -0.0003,\n",
       "              0.0081,     -0.0179,     -0.0205,     -0.0297,     -0.0033,\n",
       "              0.0147,      0.0072,      0.0240,     -0.0105,     -0.0207],\n",
       "        [     0.0092,     -0.0060,      0.0058,      0.0028,     -0.0001,\n",
       "             -0.0001,     -0.0026,      0.0010,     -0.0000,     -0.0011,\n",
       "              0.0016,      0.0017,      0.0022,     -0.0039,     -0.0004,\n",
       "              0.0046,     -0.0097,     -0.0088,     -0.0057,      0.0119,\n",
       "              0.0075,      0.0006,      0.0008,     -0.0045,      0.0031],\n",
       "        [    -0.0039,      0.0019,     -0.0001,     -0.0001,      0.0016,\n",
       "              0.0020,      0.0006,     -0.0000,      0.0009,     -0.0008,\n",
       "              0.0080,      0.0117,     -0.0006,     -0.0002,     -0.0108,\n",
       "              0.0001,      0.0005,      0.0114,      0.0013,     -0.0082,\n",
       "             -0.0123,      0.0078,     -0.0008,      0.0006,     -0.0076],\n",
       "        [     0.0019,     -0.0060,     -0.0001,     -0.0001,      0.0020,\n",
       "              0.0178,     -0.0009,     -0.0000,      0.0013,      0.0009,\n",
       "              0.0366,      0.0329,      0.0542,     -0.0002,      0.0396,\n",
       "             -0.0557,      0.0016,     -0.0390,      0.0005,     -0.0380,\n",
       "             -0.0335,      0.0367,      0.0544,     -0.0545,     -0.0366],\n",
       "        [    -0.6562,      0.2223,      0.0065,     -0.0026,      0.0006,\n",
       "             -0.0009,      0.3263,     -0.0029,     -0.0007,     -0.1562,\n",
       "             -0.2854,     -0.1574,      0.1706,      0.1955,      0.0777,\n",
       "              0.0294,      0.0275,      0.0631,     -0.0438,      0.0624,\n",
       "              0.0166,     -0.4065,      0.2809,      0.0681,      0.0574],\n",
       "        [     0.0065,     -0.0026,      0.0020,      0.0010,     -0.0000,\n",
       "             -0.0000,     -0.0029,      0.0012,     -0.0000,      0.0001,\n",
       "              0.0012,      0.0020,     -0.0038,     -0.0032,     -0.0001,\n",
       "             -0.0023,     -0.0066,     -0.0069,      0.0060,      0.0086,\n",
       "              0.0050,      0.0017,     -0.0049,     -0.0087,      0.0120],\n",
       "        [     0.0006,     -0.0009,     -0.0000,     -0.0000,      0.0009,\n",
       "              0.0013,     -0.0007,     -0.0000,      0.0009,      0.0004,\n",
       "              0.0102,      0.0087,     -0.0110,     -0.0001,     -0.0077,\n",
       "              0.0114,      0.0005,      0.0082,     -0.0007,     -0.0106,\n",
       "             -0.0091,      0.0102,     -0.0112,      0.0119,     -0.0109],\n",
       "        [    -0.0466,      0.1228,      0.0012,     -0.0011,     -0.0008,\n",
       "              0.0009,     -0.1562,      0.0001,      0.0004,      0.3194,\n",
       "              0.1905,      0.2777,     -0.0360,     -0.0033,     -0.0123,\n",
       "             -0.2269,     -0.0046,     -0.2558,     -0.0565,     -0.1826,\n",
       "             -0.0096,      0.4804,     -0.0387,     -0.2582,     -0.1834],\n",
       "        [     1.0685,     -0.8440,      0.0069,      0.0016,      0.0080,\n",
       "              0.0366,     -0.2854,      0.0012,      0.0102,      0.1905,\n",
       "              2.1906,      1.1435,     -0.0033,     -0.0193,     -0.0098,\n",
       "             -0.0046,     -0.3331,     -0.3329,     -0.1826,     -1.8382,\n",
       "             -0.8008,      2.1949,     -0.0194,     -0.3345,     -1.8410],\n",
       "        [    -0.5575,      0.2922,      0.0062,      0.0017,      0.0117,\n",
       "              0.0329,     -0.1574,      0.0020,      0.0087,      0.2777,\n",
       "              1.1435,      1.4463,     -0.0123,     -0.0098,     -0.0234,\n",
       "             -0.2558,     -0.3329,     -0.6211,     -0.0096,     -0.8008,\n",
       "             -0.8018,      1.4488,     -0.0234,     -0.6219,     -0.8035],\n",
       "        [    -0.3250,     -0.0784,      0.0204,      0.0022,     -0.0006,\n",
       "              0.0542,      0.1706,     -0.0038,     -0.0110,     -0.0360,\n",
       "             -0.0033,     -0.0123,      3.1620,      0.1504,      1.0625,\n",
       "             -2.6280,     -0.0024,     -1.0497,     -0.4980,     -0.1447,\n",
       "             -0.0006,     -0.0387,      3.2745,     -2.6841,     -0.5516],\n",
       "        [    -0.9833,      0.4128,      0.0144,     -0.0039,     -0.0002,\n",
       "             -0.0002,      0.1955,     -0.0032,     -0.0001,     -0.0033,\n",
       "             -0.0193,     -0.0098,      0.1504,      0.3238,      0.0104,\n",
       "             -0.0024,     -0.0008,     -0.0002,     -0.1447,     -0.3037,\n",
       "             -0.0004,     -0.0194,      0.3269,     -0.0028,     -0.3047],\n",
       "        [     0.2835,     -0.2649,     -0.0003,     -0.0004,     -0.0108,\n",
       "              0.0396,      0.0777,     -0.0001,     -0.0077,     -0.0123,\n",
       "             -0.0098,     -0.0234,      1.0625,      0.0104,      1.1368,\n",
       "             -1.0497,     -0.0002,     -1.1126,     -0.0006,     -0.0004,\n",
       "             -0.0008,     -0.0234,      1.1391,     -1.1146,     -0.0010],\n",
       "        [     0.1213,     -0.0386,      0.0081,      0.0046,      0.0001,\n",
       "             -0.0557,      0.0294,     -0.0023,      0.0114,     -0.2269,\n",
       "             -0.0046,     -0.2558,     -2.6280,     -0.0024,     -1.0497,\n",
       "              2.9007,      0.0168,      1.3145,     -0.0458,     -0.0098,\n",
       "             -0.0090,     -0.2582,     -2.6841,      2.9932,     -0.0509],\n",
       "        [    -0.0023,      0.0576,     -0.0179,     -0.0097,      0.0005,\n",
       "              0.0016,      0.0275,     -0.0066,      0.0005,     -0.0046,\n",
       "             -0.3331,     -0.3329,     -0.0024,     -0.0008,     -0.0002,\n",
       "              0.0168,      0.3715,      0.3450,     -0.0098,     -0.0376,\n",
       "             -0.0119,     -0.3345,     -0.0028,      0.3750,     -0.0377],\n",
       "        [     0.2356,     -0.0692,     -0.0205,     -0.0088,      0.0114,\n",
       "             -0.0390,      0.0631,     -0.0069,      0.0082,     -0.2558,\n",
       "             -0.3329,     -0.6211,     -1.0497,     -0.0002,     -1.1126,\n",
       "              1.3145,      0.3450,      1.7553,     -0.0090,     -0.0119,\n",
       "             -0.0217,     -0.6219,     -1.1146,      1.7583,     -0.0217],\n",
       "        [     0.2502,     -0.0058,     -0.0297,     -0.0057,      0.0013,\n",
       "              0.0005,     -0.0438,      0.0060,     -0.0007,     -0.0565,\n",
       "             -0.1826,     -0.0096,     -0.4980,     -0.1447,     -0.0006,\n",
       "             -0.0458,     -0.0098,     -0.0090,      0.6003,      0.3372,\n",
       "              0.0193,     -0.1834,     -0.5516,     -0.0509,      0.7860],\n",
       "        [    -0.0829,      0.3736,     -0.0033,      0.0119,     -0.0082,\n",
       "             -0.0380,      0.0624,      0.0086,     -0.0106,     -0.1826,\n",
       "             -1.8382,     -0.8008,     -0.1447,     -0.3037,     -0.0004,\n",
       "             -0.0098,     -0.0376,     -0.0119,      0.3372,      2.1795,\n",
       "              0.8130,     -1.8410,     -0.3047,     -0.0377,      2.1835],\n",
       "        [     0.0384,      0.0419,      0.0147,      0.0075,     -0.0123,\n",
       "             -0.0335,      0.0166,      0.0050,     -0.0091,     -0.0096,\n",
       "             -0.8008,     -0.8018,     -0.0006,     -0.0004,     -0.0008,\n",
       "             -0.0090,     -0.0119,     -0.0217,      0.0193,      0.8130,\n",
       "              0.8243,     -0.8035,     -0.0010,     -0.0217,      0.8263],\n",
       "        [     0.6027,     -0.4785,      0.0072,      0.0006,      0.0078,\n",
       "              0.0367,     -0.4065,      0.0017,      0.0102,      0.4804,\n",
       "              2.1949,      1.4488,     -0.0387,     -0.0194,     -0.0234,\n",
       "             -0.2582,     -0.3345,     -0.6219,     -0.1834,     -1.8410,\n",
       "             -0.8035,      2.5265,     -0.0564,     -0.6256,     -1.8446],\n",
       "        [    -0.7324,      0.1213,      0.0240,      0.0008,     -0.0008,\n",
       "              0.0544,      0.2809,     -0.0049,     -0.0112,     -0.0387,\n",
       "             -0.0194,     -0.0234,      3.2745,      0.3269,      1.1391,\n",
       "             -2.6841,     -0.0028,     -1.1146,     -0.5516,     -0.3047,\n",
       "             -0.0010,     -0.0564,      3.5220,     -2.7529,     -0.7127],\n",
       "        [     0.2051,     -0.0320,     -0.0105,     -0.0045,      0.0006,\n",
       "             -0.0545,      0.0681,     -0.0087,      0.0119,     -0.2582,\n",
       "             -0.3345,     -0.6219,     -2.6841,     -0.0028,     -1.1146,\n",
       "              2.9932,      0.3750,      1.7583,     -0.0509,     -0.0377,\n",
       "             -0.0217,     -0.6256,     -2.7529,      3.4583,     -0.0799],\n",
       "        [    -0.0754,      0.3892,     -0.0207,      0.0031,     -0.0076,\n",
       "             -0.0366,      0.0574,      0.0120,     -0.0109,     -0.1834,\n",
       "             -1.8410,     -0.8035,     -0.5516,     -0.3047,     -0.0010,\n",
       "             -0.0509,     -0.0377,     -0.0217,      0.7860,      2.1835,\n",
       "              0.8263,     -1.8446,     -0.7127,     -0.0799,      2.6371]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.posterior.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f7e2af-8dfc-4d7d-bb04-060aef0f3df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = la(x, pred_type='glm', link_approx='probit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
