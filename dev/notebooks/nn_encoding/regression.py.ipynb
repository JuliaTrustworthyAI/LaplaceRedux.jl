{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cecfc6fb70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from laplace import Laplace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv\n",
    "\n",
    "# Load data from CSV file using pandas\n",
    "df = pd.read_csv('data_regression.csv')\n",
    "\n",
    "# Split the dataframe into x and y tensors\n",
    "data = torch.from_numpy(df[['xs', 'y']].to_numpy()).to(torch.float32)\n",
    "x = torch.from_numpy(df['xs'].to_numpy()).to(torch.float32)\n",
    "y = torch.from_numpy(df['y'].to_numpy()).to(torch.float32)\n",
    "\n",
    "#y_unique = torch.unique(y)\n",
    "#y_indices = y - 1\n",
    "#y_indices = y_indices.long()\n",
    "#y_train = nn.functional.one_hot(y_indices, num_classes=len(y_unique)).float()\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "n_hidden = 10\n",
    "D = 1\n",
    "out_dim = 1 \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, n_hidden),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_hidden, out_dim)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': [-1.1201183,\n",
       "   -1.0552441,\n",
       "   -1.1727674,\n",
       "   1.0405303,\n",
       "   1.1344997,\n",
       "   -1.0677602,\n",
       "   1.9962846,\n",
       "   1.04113,\n",
       "   -2.8023236,\n",
       "   1.1533123],\n",
       "  'weight': [[0.25581408,\n",
       "    0.24827705,\n",
       "    0.25862476,\n",
       "    0.4965463,\n",
       "    -1.3918695,\n",
       "    0.24902664,\n",
       "    -0.7361471,\n",
       "    -0.24590988,\n",
       "    0.7512668,\n",
       "    -0.6878244]]},\n",
       " {'bias': [0.5303483],\n",
       "  'weight': [[1.339898],\n",
       "   [0.9142657],\n",
       "   [0.85277814],\n",
       "   [0.45185313],\n",
       "   [-0.4072362],\n",
       "   [0.86708283],\n",
       "   [1.2918717],\n",
       "   [-0.77205473],\n",
       "   [-1.8449564],\n",
       "   [0.4374265]]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('nn_regression.json') as fin:\n",
    "    nn_json_str = fin.read()\n",
    "    nn_json = json.loads(nn_json_str)\n",
    "\n",
    "nn_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeli\\AppData\\Local\\Temp\\ipykernel_29104\\3249112778.py:10: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n",
      "  tensor_b = torch.tensor(layer_read['bias']).T\n"
     ]
    }
   ],
   "source": [
    "assert len(model.state_dict()) == 2 * len(nn_json)\n",
    "iter_states = iter(model.state_dict())\n",
    "\n",
    "# for layer in model.state_dict():\n",
    "#     print(layer)\n",
    "for layer_read in nn_json:\n",
    "    state_w = next(iter_states)\n",
    "    state_b = next(iter_states)\n",
    "    tensor_w = torch.tensor(layer_read['weight']).T\n",
    "    tensor_b = torch.tensor(layer_read['bias']).T\n",
    "    model.state_dict()[state_w].data.copy_(tensor_w)\n",
    "    model.state_dict()[state_b].data.copy_(tensor_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2558],\n",
       "        [ 0.2483],\n",
       "        [ 0.2586],\n",
       "        [ 0.4965],\n",
       "        [-1.3919],\n",
       "        [ 0.2490],\n",
       "        [-0.7361],\n",
       "        [-0.2459],\n",
       "        [ 0.7513],\n",
       "        [-0.6878]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.1201, -1.0552, -1.1728,  1.0405,  1.1345, -1.0678,  1.9963,  1.0411,\n",
       "        -2.8023,  1.1533])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3399,  0.9143,  0.8528,  0.4519, -0.4072,  0.8671,  1.2919, -0.7721,\n",
       "         -1.8450,  0.4374]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5303])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for val in model.state_dict().values():\n",
    "    display(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\myenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.1229e+02,  4.1711e+02,  3.9173e+02,  2.1577e+01, -6.8919e+00,\n",
      "          3.9609e+02,  2.4293e+02, -3.5245e+02, -4.8363e+02,  5.7804e+01,\n",
      "          1.1815e+02,  8.0638e+01,  7.5375e+01,  5.9110e+00, -3.3075e+00,\n",
      "          7.6526e+01,  5.8729e+01, -6.8142e+01, -1.0526e+02,  1.5174e+01,\n",
      "          2.0757e+02,  2.0985e+02,  2.0421e+02,  3.6163e+02,  1.1458e+01,\n",
      "          2.0908e+02,  7.5008e+01,  1.6580e+02,  2.6270e+02,  4.8867e+01,\n",
      "          3.7581e+02],\n",
      "        [ 4.1711e+02,  2.8416e+02,  2.6685e+02,  1.4749e+01, -4.7497e+00,\n",
      "          2.6984e+02,  1.6586e+02, -2.4010e+02, -3.2980e+02,  3.9503e+01,\n",
      "          8.0638e+01,  5.5036e+01,  5.1440e+01,  4.0581e+00, -2.2897e+00,\n",
      "          5.2229e+01,  4.0195e+01, -4.6508e+01, -7.1905e+01,  1.0403e+01,\n",
      "          1.4151e+02,  1.4307e+02,  1.3921e+02,  2.4676e+02,  7.9509e+00,\n",
      "          1.4255e+02,  5.1509e+01,  1.1331e+02,  1.7893e+02,  3.3587e+01,\n",
      "          2.5650e+02],\n",
      "        [ 3.9173e+02,  2.6685e+02,  2.5063e+02,  1.3727e+01, -4.3422e+00,\n",
      "          2.5341e+02,  1.5470e+02, -2.2548e+02, -3.0853e+02,  3.6770e+01,\n",
      "          7.5375e+01,  5.1440e+01,  4.8089e+01,  3.7421e+00, -2.0757e+00,\n",
      "          4.8818e+01,  3.7286e+01, -4.3469e+01, -6.6987e+01,  9.6163e+00,\n",
      "          1.3267e+02,  1.3412e+02,  1.3053e+02,  2.3081e+02,  7.1775e+00,\n",
      "          1.3363e+02,  4.7456e+01,  1.0556e+02,  1.6811e+02,  3.0891e+01,\n",
      "          2.3978e+02],\n",
      "        [ 2.1577e+01,  1.4749e+01,  1.3727e+01,  1.3466e+00, -8.5491e-01,\n",
      "          1.3989e+01,  1.3108e+01, -1.2464e+01, -2.1856e+01,  3.5042e+00,\n",
      "          5.9110e+00,  4.0581e+00,  3.7421e+00,  5.7171e-01, -5.3760e-01,\n",
      "          3.8446e+00,  4.2417e+00, -3.4315e+00, -6.1176e+00,  1.2944e+00,\n",
      "          8.5150e+00,  8.6806e+00,  8.3286e+00,  1.7392e+01,  2.1081e+00,\n",
      "          8.6372e+00,  7.3704e+00,  1.0126e+01,  8.9424e+00,  5.1544e+00,\n",
      "          1.8831e+01],\n",
      "        [-6.8919e+00, -4.7497e+00, -4.3422e+00, -8.5491e-01,  8.9517e-01,\n",
      "         -4.4952e+00, -6.0242e+00,  4.0183e+00,  7.5898e+00, -1.9562e+00,\n",
      "         -3.3075e+00, -2.2897e+00, -2.0757e+00, -5.3760e-01,  6.5805e-01,\n",
      "         -2.1651e+00, -2.8872e+00,  1.9389e+00,  3.2072e+00, -1.0576e+00,\n",
      "         -3.9086e+00, -4.0309e+00, -3.7939e+00, -9.6038e+00, -2.6948e+00,\n",
      "         -4.0035e+00, -6.7849e+00, -6.9485e+00, -2.6700e+00, -5.0172e+00,\n",
      "         -1.1003e+01],\n",
      "        [ 3.9609e+02,  2.6984e+02,  2.5341e+02,  1.3989e+01, -4.4952e+00,\n",
      "          2.5624e+02,  1.5735e+02, -2.2800e+02, -3.1299e+02,  3.7466e+01,\n",
      "          7.6526e+01,  5.2229e+01,  4.8818e+01,  3.8446e+00, -2.1651e+00,\n",
      "          4.9566e+01,  3.8106e+01, -4.4136e+01, -6.8204e+01,  9.8584e+00,\n",
      "          1.3435e+02,  1.3583e+02,  1.3217e+02,  2.3420e+02,  7.5149e+00,\n",
      "          1.3533e+02,  4.8793e+01,  1.0749e+02,  1.6992e+02,  3.1810e+01,\n",
      "          2.4342e+02],\n",
      "        [ 2.4293e+02,  1.6586e+02,  1.5470e+02,  1.3108e+01, -6.0242e+00,\n",
      "          1.5735e+02,  1.4408e+02, -1.4013e+02, -2.5365e+02,  3.6278e+01,\n",
      "          5.8729e+01,  4.0195e+01,  3.7286e+01,  4.2417e+00, -2.8872e+00,\n",
      "          3.8106e+01,  4.0311e+01, -3.3969e+01, -6.4469e+01,  1.0997e+01,\n",
      "          8.8556e+01,  9.0037e+01,  8.6760e+01,  1.7256e+02,  9.7244e+00,\n",
      "          8.9623e+01,  5.6459e+01,  9.2622e+01,  1.0133e+02,  3.7256e+01,\n",
      "          1.8285e+02],\n",
      "        [-3.5245e+02, -2.4010e+02, -2.2548e+02, -1.2464e+01,  4.0183e+00,\n",
      "         -2.2800e+02, -1.4013e+02,  2.0288e+02,  2.7861e+02, -3.3378e+01,\n",
      "         -6.8142e+01, -4.6508e+01, -4.3469e+01, -3.4315e+00,  1.9389e+00,\n",
      "         -4.4136e+01, -3.3969e+01,  3.9301e+01,  6.0752e+01, -8.7941e+00,\n",
      "         -1.1958e+02, -1.2090e+02, -1.1764e+02, -2.0853e+02, -6.7360e+00,\n",
      "         -1.2046e+02, -4.3554e+01, -9.5765e+01, -1.5119e+02, -2.8405e+01,\n",
      "         -2.1676e+02],\n",
      "        [-4.8363e+02, -3.2980e+02, -3.0853e+02, -2.1856e+01,  7.5898e+00,\n",
      "         -3.1299e+02, -2.5365e+02,  2.7861e+02,  4.7509e+02, -6.1230e+01,\n",
      "         -1.0526e+02, -7.1905e+01, -6.6987e+01, -6.1176e+00,  3.2072e+00,\n",
      "         -6.8204e+01, -6.4469e+01,  6.0752e+01,  1.1138e+02, -1.6554e+01,\n",
      "         -1.6813e+02, -1.7051e+02, -1.6501e+02, -3.1225e+02, -1.0183e+01,\n",
      "         -1.6979e+02, -8.0894e+01, -1.5607e+02, -2.0453e+02, -5.1897e+01,\n",
      "         -3.2684e+02],\n",
      "        [ 5.7804e+01,  3.9503e+01,  3.6770e+01,  3.5042e+00, -1.9562e+00,\n",
      "          3.7466e+01,  3.6278e+01, -3.3378e+01, -6.1230e+01,  9.4641e+00,\n",
      "          1.5174e+01,  1.0403e+01,  9.6163e+00,  1.2944e+00, -1.0576e+00,\n",
      "          9.8584e+00,  1.0997e+01, -8.7941e+00, -1.6554e+01,  3.1723e+00,\n",
      "          2.2050e+01,  2.2461e+01,  2.1576e+01,  4.4451e+01,  3.7957e+00,\n",
      "          2.2351e+01,  1.7085e+01,  2.5127e+01,  2.3900e+01,  1.1587e+01,\n",
      "          4.7646e+01],\n",
      "        [ 1.1815e+02,  8.0638e+01,  7.5375e+01,  5.9110e+00, -3.3075e+00,\n",
      "          7.6526e+01,  5.8729e+01, -6.8142e+01, -1.0526e+02,  1.5174e+01,\n",
      "          2.8812e+01,  1.9757e+01,  1.8279e+01,  2.5466e+00, -2.3528e+00,\n",
      "          1.8726e+01,  1.7989e+01, -1.6706e+01, -2.7208e+01,  5.4699e+00,\n",
      "          4.4565e+01,  4.5299e+01,  4.3683e+01,  8.6219e+01,  1.0273e+01,\n",
      "          4.5095e+01,  3.1835e+01,  4.7301e+01,  5.0009e+01,  2.2556e+01,\n",
      "          9.2697e+01],\n",
      "        [ 8.0638e+01,  5.5036e+01,  5.1440e+01,  4.0581e+00, -2.2897e+00,\n",
      "          5.2229e+01,  4.0195e+01, -4.6508e+01, -7.1905e+01,  1.0403e+01,\n",
      "          1.9757e+01,  1.3549e+01,  1.2532e+01,  1.7623e+00, -1.6373e+00,\n",
      "          1.2841e+01,  1.2370e+01, -1.1457e+01, -1.8649e+01,  3.7728e+00,\n",
      "          3.0493e+01,  3.0999e+01,  2.9888e+01,  5.9108e+01,  7.1662e+00,\n",
      "          3.0859e+01,  2.2018e+01,  3.2529e+01,  3.4124e+01,  1.5620e+01,\n",
      "          6.3594e+01],\n",
      "        [ 7.5375e+01,  5.1440e+01,  4.8089e+01,  3.7421e+00, -2.0757e+00,\n",
      "          4.8818e+01,  3.7286e+01, -4.3469e+01, -6.6987e+01,  9.6163e+00,\n",
      "          1.8279e+01,  1.2532e+01,  1.1598e+01,  1.6000e+00, -1.4703e+00,\n",
      "          1.1879e+01,  1.1366e+01, -1.0597e+01, -1.7248e+01,  3.4462e+00,\n",
      "          2.8351e+01,  2.8814e+01,  2.7792e+01,  5.4721e+01,  6.4081e+00,\n",
      "          2.8685e+01,  2.0008e+01,  2.9913e+01,  3.1914e+01,  1.4160e+01,\n",
      "          5.8788e+01],\n",
      "        [ 5.9110e+00,  4.0581e+00,  3.7421e+00,  5.7171e-01, -5.3760e-01,\n",
      "          3.8446e+00,  4.2417e+00, -3.4315e+00, -6.1176e+00,  1.2944e+00,\n",
      "          2.5466e+00,  1.7623e+00,  1.6000e+00,  4.1905e-01, -4.9665e-01,\n",
      "          1.6668e+00,  1.9762e+00, -1.4924e+00, -2.3026e+00,  7.3911e-01,\n",
      "          3.1591e+00,  3.2499e+00,  3.0720e+00,  7.4569e+00,  2.4148e+00,\n",
      "          3.2291e+00,  5.0595e+00,  5.3064e+00,  2.4391e+00,  3.8395e+00,\n",
      "          8.5730e+00],\n",
      "        [-3.3075e+00, -2.2897e+00, -2.0757e+00, -5.3760e-01,  6.5805e-01,\n",
      "         -2.1651e+00, -2.8872e+00,  1.9389e+00,  3.2072e+00, -1.0576e+00,\n",
      "         -2.3528e+00, -1.6373e+00, -1.4703e+00, -4.9665e-01,  6.4782e-01,\n",
      "         -1.5467e+00, -1.9273e+00,  1.3880e+00,  1.8635e+00, -8.1053e-01,\n",
      "         -2.6058e+00, -2.7022e+00, -2.5211e+00, -6.8860e+00, -3.1408e+00,\n",
      "         -2.6817e+00, -5.9091e+00, -5.5038e+00, -1.3381e+00, -4.5947e+00,\n",
      "         -8.2253e+00],\n",
      "        [ 7.6526e+01,  5.2229e+01,  4.8818e+01,  3.8446e+00, -2.1651e+00,\n",
      "          4.9566e+01,  3.8106e+01, -4.4136e+01, -6.8204e+01,  9.8584e+00,\n",
      "          1.8726e+01,  1.2841e+01,  1.1879e+01,  1.6668e+00, -1.5467e+00,\n",
      "          1.2171e+01,  1.1714e+01, -1.0859e+01, -1.7674e+01,  3.5705e+00,\n",
      "          2.8920e+01,  2.9399e+01,  2.8346e+01,  5.6029e+01,  6.7666e+00,\n",
      "          2.9266e+01,  2.0826e+01,  3.0810e+01,  3.2386e+01,  1.4771e+01,\n",
      "          6.0271e+01],\n",
      "        [ 5.8729e+01,  4.0195e+01,  3.7286e+01,  4.2417e+00, -2.8872e+00,\n",
      "          3.8106e+01,  4.0311e+01, -3.3969e+01, -6.4469e+01,  1.0997e+01,\n",
      "          1.7989e+01,  1.2370e+01,  1.1366e+01,  1.9762e+00, -1.9273e+00,\n",
      "          1.1714e+01,  1.3798e+01, -1.0462e+01, -1.9158e+01,  4.3247e+00,\n",
      "          2.4540e+01,  2.5083e+01,  2.3958e+01,  5.2451e+01,  7.9941e+00,\n",
      "          2.4947e+01,  2.5332e+01,  3.2310e+01,  2.4072e+01,  1.7943e+01,\n",
      "          5.7480e+01],\n",
      "        [-6.8142e+01, -4.6508e+01, -4.3469e+01, -3.4315e+00,  1.9389e+00,\n",
      "         -4.4136e+01, -3.3969e+01,  3.9301e+01,  6.0752e+01, -8.7941e+00,\n",
      "         -1.6706e+01, -1.1457e+01, -1.0597e+01, -1.4924e+00,  1.3880e+00,\n",
      "         -1.0859e+01, -1.0462e+01,  9.6876e+00,  1.5765e+01, -3.1927e+00,\n",
      "         -2.5778e+01, -2.6206e+01, -2.5266e+01, -4.9980e+01, -6.0782e+00,\n",
      "         -2.6087e+01, -1.8643e+01, -2.7518e+01, -2.8836e+01, -1.3229e+01,\n",
      "         -5.3780e+01],\n",
      "        [-1.0526e+02, -7.1905e+01, -6.6987e+01, -6.1176e+00,  3.2072e+00,\n",
      "         -6.8204e+01, -6.4469e+01,  6.0752e+01,  1.1138e+02, -1.6554e+01,\n",
      "         -2.7208e+01, -1.8649e+01, -1.7248e+01, -2.3026e+00,  1.8635e+00,\n",
      "         -1.7674e+01, -1.9158e+01,  1.5765e+01,  2.9427e+01, -5.5016e+00,\n",
      "         -3.9843e+01, -4.0571e+01, -3.8997e+01, -7.9765e+01, -7.2603e+00,\n",
      "         -4.0375e+01, -2.9974e+01, -4.4815e+01, -4.3817e+01, -2.0460e+01,\n",
      "         -8.5487e+01],\n",
      "        [ 1.5174e+01,  1.0403e+01,  9.6163e+00,  1.2944e+00, -1.0576e+00,\n",
      "          9.8584e+00,  1.0997e+01, -8.7941e+00, -1.6554e+01,  3.1723e+00,\n",
      "          5.4699e+00,  3.7728e+00,  3.4462e+00,  7.3911e-01, -8.1053e-01,\n",
      "          3.5705e+00,  4.3247e+00, -3.1927e+00, -5.5016e+00,  1.4721e+00,\n",
      "          7.0765e+00,  7.2572e+00,  6.8944e+00,  1.5948e+01,  3.5906e+00,\n",
      "          7.2141e+00,  9.2484e+00,  1.0581e+01,  6.1813e+00,  6.7701e+00,\n",
      "          1.7870e+01],\n",
      "        [ 2.0757e+02,  1.4151e+02,  1.3267e+02,  8.5150e+00, -3.9086e+00,\n",
      "          1.3435e+02,  8.8556e+01, -1.1958e+02, -1.6813e+02,  2.2050e+01,\n",
      "          4.4565e+01,  3.0493e+01,  2.8351e+01,  3.1591e+00, -2.6058e+00,\n",
      "          2.8920e+01,  2.4540e+01, -2.5778e+01, -3.9843e+01,  7.0765e+00,\n",
      "          7.4104e+01,  7.5098e+01,  7.2790e+01,  1.3537e+02,  1.1088e+01,\n",
      "          7.4797e+01,  3.9379e+01,  6.8084e+01,  8.8677e+01,  2.7350e+01,\n",
      "          1.4329e+02],\n",
      "        [ 2.0985e+02,  1.4307e+02,  1.3412e+02,  8.6806e+00, -4.0309e+00,\n",
      "          1.3583e+02,  9.0037e+01, -1.2090e+02, -1.7051e+02,  2.2461e+01,\n",
      "          4.5299e+01,  3.0999e+01,  2.8814e+01,  3.2499e+00, -2.7022e+00,\n",
      "          2.9399e+01,  2.5083e+01, -2.6206e+01, -4.0571e+01,  7.2572e+00,\n",
      "          7.5098e+01,  7.6115e+01,  7.3760e+01,  1.3752e+02,  1.1526e+01,\n",
      "          7.5808e+01,  4.0507e+01,  6.9450e+01,  8.9622e+01,  2.8174e+01,\n",
      "          1.4567e+02],\n",
      "        [ 2.0421e+02,  1.3921e+02,  1.3053e+02,  8.3286e+00, -3.7939e+00,\n",
      "          1.3217e+02,  8.6760e+01, -1.1764e+02, -1.6501e+02,  2.1576e+01,\n",
      "          4.3683e+01,  2.9888e+01,  2.7792e+01,  3.0720e+00, -2.5211e+00,\n",
      "          2.8346e+01,  2.3958e+01, -2.5266e+01, -3.8997e+01,  6.8944e+00,\n",
      "          7.2790e+01,  7.3760e+01,  7.1503e+01,  1.3274e+02,  1.0712e+01,\n",
      "          7.3465e+01,  3.8292e+01,  6.6579e+01,  8.7262e+01,  2.6572e+01,\n",
      "          1.4044e+02],\n",
      "        [ 3.6163e+02,  2.4676e+02,  2.3081e+02,  1.7392e+01, -9.6038e+00,\n",
      "          2.3420e+02,  1.7256e+02, -2.0853e+02, -3.1225e+02,  4.4451e+01,\n",
      "          8.6219e+01,  5.9108e+01,  5.4721e+01,  7.4569e+00, -6.8860e+00,\n",
      "          5.6029e+01,  5.2451e+01, -4.9980e+01, -7.9765e+01,  1.5948e+01,\n",
      "          1.3537e+02,  1.3752e+02,  1.3274e+02,  2.5907e+02,  3.0188e+01,\n",
      "          1.3691e+02,  9.2909e+01,  1.4025e+02,  1.5344e+02,  6.5893e+01,\n",
      "          2.7804e+02],\n",
      "        [ 1.1458e+01,  7.9509e+00,  7.1775e+00,  2.1081e+00, -2.6948e+00,\n",
      "          7.5149e+00,  9.7244e+00, -6.7360e+00, -1.0183e+01,  3.7957e+00,\n",
      "          1.0273e+01,  7.1662e+00,  6.4081e+00,  2.4148e+00, -3.1408e+00,\n",
      "          6.7666e+00,  7.9941e+00, -6.0782e+00, -7.2603e+00,  3.5906e+00,\n",
      "          1.1088e+01,  1.1526e+01,  1.0712e+01,  3.0188e+01,  1.6610e+01,\n",
      "          1.1435e+01,  2.7919e+01,  2.5192e+01,  4.9285e+00,  2.2181e+01,\n",
      "          3.6808e+01],\n",
      "        [ 2.0908e+02,  1.4255e+02,  1.3363e+02,  8.6372e+00, -4.0035e+00,\n",
      "          1.3533e+02,  8.9623e+01, -1.2046e+02, -1.6979e+02,  2.2351e+01,\n",
      "          4.5095e+01,  3.0859e+01,  2.8685e+01,  3.2291e+00, -2.6817e+00,\n",
      "          2.9266e+01,  2.4947e+01, -2.6087e+01, -4.0375e+01,  7.2141e+00,\n",
      "          7.4797e+01,  7.5808e+01,  7.3465e+01,  1.3691e+02,  1.1435e+01,\n",
      "          7.5502e+01,  4.0248e+01,  6.9098e+01,  8.9302e+01,  2.7988e+01,\n",
      "          1.4501e+02],\n",
      "        [ 7.5008e+01,  5.1509e+01,  4.7456e+01,  7.3704e+00, -6.7849e+00,\n",
      "          4.8793e+01,  5.6459e+01, -4.3554e+01, -8.0894e+01,  1.7085e+01,\n",
      "          3.1835e+01,  2.2018e+01,  2.0008e+01,  5.0595e+00, -5.9091e+00,\n",
      "          2.0826e+01,  2.5332e+01, -1.8643e+01, -2.9974e+01,  9.2484e+00,\n",
      "          3.9379e+01,  4.0507e+01,  3.8292e+01,  9.2909e+01,  2.7919e+01,\n",
      "          4.0248e+01,  6.1802e+01,  6.5581e+01,  3.0620e+01,  4.6442e+01,\n",
      "          1.0630e+02],\n",
      "        [ 1.6580e+02,  1.1331e+02,  1.0556e+02,  1.0126e+01, -6.9485e+00,\n",
      "          1.0749e+02,  9.2622e+01, -9.5765e+01, -1.5607e+02,  2.5127e+01,\n",
      "          4.7301e+01,  3.2529e+01,  2.9913e+01,  5.3064e+00, -5.5038e+00,\n",
      "          3.0810e+01,  3.2310e+01, -2.7518e+01, -4.4815e+01,  1.0581e+01,\n",
      "          6.8084e+01,  6.9450e+01,  6.6579e+01,  1.4025e+02,  2.5192e+01,\n",
      "          6.9098e+01,  6.5581e+01,  8.4351e+01,  6.9620e+01,  4.7792e+01,\n",
      "          1.5401e+02],\n",
      "        [ 2.6270e+02,  1.7893e+02,  1.6811e+02,  8.9424e+00, -2.6700e+00,\n",
      "          1.6992e+02,  1.0133e+02, -1.5119e+02, -2.0453e+02,  2.3900e+01,\n",
      "          5.0009e+01,  3.4124e+01,  3.1914e+01,  2.4391e+00, -1.3381e+00,\n",
      "          3.2386e+01,  2.4072e+01, -2.8836e+01, -4.3817e+01,  6.1813e+00,\n",
      "          8.8677e+01,  8.9622e+01,  8.7262e+01,  1.5344e+02,  4.9285e+00,\n",
      "          8.9302e+01,  3.0620e+01,  6.9620e+01,  1.1297e+02,  1.9997e+01,\n",
      "          1.5931e+02],\n",
      "        [ 4.8867e+01,  3.3587e+01,  3.0891e+01,  5.1544e+00, -5.0172e+00,\n",
      "          3.1810e+01,  3.7256e+01, -2.8405e+01, -5.1897e+01,  1.1587e+01,\n",
      "          2.2556e+01,  1.5620e+01,  1.4160e+01,  3.8395e+00, -4.5947e+00,\n",
      "          1.4771e+01,  1.7943e+01, -1.3229e+01, -2.0460e+01,  6.7701e+00,\n",
      "          2.7350e+01,  2.8174e+01,  2.6572e+01,  6.5893e+01,  2.2181e+01,\n",
      "          2.7988e+01,  4.6442e+01,  4.7792e+01,  1.9997e+01,  3.5269e+01,\n",
      "          7.6121e+01],\n",
      "        [ 3.7581e+02,  2.5650e+02,  2.3978e+02,  1.8831e+01, -1.1003e+01,\n",
      "          2.4342e+02,  1.8285e+02, -2.1676e+02, -3.2684e+02,  4.7646e+01,\n",
      "          9.2697e+01,  6.3594e+01,  5.8788e+01,  8.5730e+00, -8.2253e+00,\n",
      "          6.0271e+01,  5.7480e+01, -5.3780e+01, -8.5487e+01,  1.7870e+01,\n",
      "          1.4329e+02,  1.4567e+02,  1.4044e+02,  2.7804e+02,  3.6808e+01,\n",
      "          1.4501e+02,  1.0630e+02,  1.5401e+02,  1.5931e+02,  7.6121e+01,\n",
      "          3.0000e+02]])\n"
     ]
    }
   ],
   "source": [
    "la = Laplace(model, 'regression',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')\n",
    "\n",
    "X = x.unsqueeze(1)\n",
    "\n",
    "la.fit(DataLoader(TensorDataset(X, y), batch_size=1))\n",
    "\n",
    "hessian = la.H\n",
    "torch.set_printoptions(precision=4, sci_mode=True)\n",
    "print(hessian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
