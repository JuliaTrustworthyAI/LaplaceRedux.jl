{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding a neural network from a JSON file to Python, then encoding the hessian from laplace.py to a CSV (regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Read the dataset\n",
    "- Step 2: Initialize model\n",
    "- Step 3: Read the weights and biases from the JSON file, then load them into the previously initialized model\n",
    "- Step 4: Generate the hessians and write them to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19f019bbc50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "from laplace import Laplace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(43)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv\n",
    "\n",
    "# Load data from CSV file using pandas\n",
    "df = pd.read_csv('data_regression.csv')\n",
    "\n",
    "# Split the dataframe into x and y tensors\n",
    "data = torch.from_numpy(df[['xs', 'y']].to_numpy()).to(torch.float32)\n",
    "x = torch.from_numpy(df['xs'].to_numpy()).to(torch.float32)\n",
    "y = torch.from_numpy(df['y'].to_numpy()).to(torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "n_hidden = 10\n",
    "D = 1\n",
    "out_dim = 1 \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, n_hidden),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden, out_dim)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Read the weights and biases from the JSON file, then load them into the previously initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': [-0.42261407,\n",
       "   -0.21227753,\n",
       "   -0.0096151605,\n",
       "   -0.7529069,\n",
       "   1.3016218,\n",
       "   3.116596,\n",
       "   -2.1422381,\n",
       "   -1.2806743,\n",
       "   0.78418183,\n",
       "   -1.3360132],\n",
       "  'weight': [[-0.55855876,\n",
       "    0.2368329,\n",
       "    0.7279194,\n",
       "    1.1712134,\n",
       "    -0.2849682,\n",
       "    -0.82284534,\n",
       "    0.76305974,\n",
       "    0.28283465,\n",
       "    -0.24539436,\n",
       "    0.6470228]]},\n",
       " {'bias': [0.13576016],\n",
       "  'weight': [[-0.27233723],\n",
       "   [0.7866149],\n",
       "   [0.26231468],\n",
       "   [0.16347119],\n",
       "   [-1.6750962],\n",
       "   [1.7097319],\n",
       "   [-1.3647312],\n",
       "   [1.6296383],\n",
       "   [-1.1626163],\n",
       "   [-0.75578994]]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('nn_regression.json') as fin:\n",
    "    nn_json_str = fin.read()\n",
    "    nn_json = json.loads(nn_json_str)\n",
    "\n",
    "nn_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeli\\AppData\\Local\\Temp\\ipykernel_28676\\3249112778.py:10: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n",
      "  tensor_b = torch.tensor(layer_read['bias']).T\n"
     ]
    }
   ],
   "source": [
    "assert len(model.state_dict()) == 2 * len(nn_json)\n",
    "iter_states = iter(model.state_dict())\n",
    "\n",
    "# for layer in model.state_dict():\n",
    "#     print(layer)\n",
    "for layer_read in nn_json:\n",
    "    state_w = next(iter_states)\n",
    "    state_b = next(iter_states)\n",
    "    tensor_w = torch.tensor(layer_read['weight']).T\n",
    "    tensor_b = torch.tensor(layer_read['bias']).T\n",
    "    model.state_dict()[state_w].data.copy_(tensor_w)\n",
    "    model.state_dict()[state_b].data.copy_(tensor_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5586],\n",
       "        [ 0.2368],\n",
       "        [ 0.7279],\n",
       "        [ 1.1712],\n",
       "        [-0.2850],\n",
       "        [-0.8228],\n",
       "        [ 0.7631],\n",
       "        [ 0.2828],\n",
       "        [-0.2454],\n",
       "        [ 0.6470]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.4226, -0.2123, -0.0096, -0.7529,  1.3016,  3.1166, -2.1422, -1.2807,\n",
       "         0.7842, -1.3360])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2723,  0.7866,  0.2623,  0.1635, -1.6751,  1.7097, -1.3647,  1.6296,\n",
       "         -1.1626, -0.7558]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1358])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for val in model.state_dict().values():\n",
    "    display(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate the hessians and write them to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the unsqueeze() method with the argument 1 to add an extra dimension\n",
    "# this extra dimension converts each value into an array of its own\n",
    "X = x.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\myenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "la = Laplace(model, 'regression',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')\n",
    "\n",
    "la.fit(DataLoader(TensorDataset(X, y), batch_size=1))\n",
    "\n",
    "hessian = la.H\n",
    "array = hessian.numpy()\n",
    "np.savetxt('hessian_regression_all_full_ggn.csv', array, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(model, 'regression',\n",
    "             subset_of_weights='last_layer',\n",
    "             hessian_structure='full')\n",
    "\n",
    "la.fit(DataLoader(TensorDataset(X, y), batch_size=1))\n",
    "\n",
    "hessian = la.H\n",
    "array = hessian.numpy()\n",
    "np.savetxt('hessian_regression_ll_full_ggn.csv', array, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(model, 'regression',\n",
    "             subset_of_weights='subnetwork',\n",
    "             subnetwork_indices = torch.LongTensor([1, 3, 5, 6, 7, 9]),\n",
    "             hessian_structure='full')\n",
    "\n",
    "la.fit(DataLoader(TensorDataset(X, y), batch_size=1))\n",
    "\n",
    "hessian = la.H\n",
    "array = hessian.numpy()\n",
    "np.savetxt('hessian_regression_subnet_full_ggn.csv', array, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
