{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding a neural network generated with Julia into a JSON file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: generate a non-linear dataset\n",
    "- Step 2: Write data to a CSV file\n",
    "- Step 3: Build the neural network\n",
    "- Step 4: Train the neural network\n",
    "- Step 5: Encode NN to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\dev\\notebooks\\two-class`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "using Pkg; Pkg.activate(\".\")\n",
    "\n",
    "using Flux, Plots, Random, Statistics, LaplaceRedux\n",
    "using Flux.Optimise: update!, Adam\n",
    "theme(:lime)\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "using JSON\n",
    "using Serialization\n",
    "using Tullio\n",
    "\n",
    "using LinearAlgebra\n",
    "using Zygote\n",
    "\n",
    "Random.seed!(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: generate a non-linear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip([[1.6801393795620563, 3.5263544599281134], [4.363742277837995, 2.6917177869381694], [4.532470758397958, 5.30055885839391], [4.530641576744509, 3.2990163059418425], [3.5734780996754285, 3.4242794223236332], [4.449988593431152, 5.100834667776773], [3.2926827627045308, 3.727440437758293], [1.4481509071599454, 5.3609283716244684], [1.1374273782015822, 3.924623406623718], [1.924779917904933, 3.8171052896062365]  …  [-3.9146176308560983, 5.370221049178135], [-2.8753043050807747, 5.17113262441957], [-4.972008358231747, 1.443881045144713], [-6.325299124070565, 4.255017998387671], [-3.9904034595383386, 2.3492050148489825], [-2.8946158215244315, 1.3070612432912136], [-6.8073184865731085, 2.902228473095165], [-5.1149402113688645, 2.3935217156788036], [-5.717635911186631, 1.0902405592489193], [-2.6799715829629784, 1.5350155638884901]], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs, ys = LaplaceRedux.Data.toy_data_multi(50)\n",
    "X = hcat(xs...) # bring into tabular format\n",
    "data = zip(xs,ys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Write data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file for writing\n",
    "file = \"data.csv\"\n",
    "csv_file = open(file, \"w\")\n",
    "\n",
    "# Write the header\n",
    "write(csv_file, \"x1,x2,y\\n\")\n",
    "\n",
    "# Write the data\n",
    "for ((x1, x2), y) in data\n",
    "    write(csv_file, \"$x1,$x2,$y\\n\")\n",
    "end\n",
    "\n",
    "# Close the CSV file\n",
    "close(csv_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_hidden = 15\n",
    "D = size(X,1)\n",
    "nn = Chain(\n",
    "    Dense(D, n_hidden, σ),\n",
    "    Dense(n_hidden, length(unique(ys)))\n",
    ")\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "avg_loss(data) = -5.322127319086576"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20\n",
      "avg_loss(data) = -13.961049915297181\n",
      "Epoch 30\n",
      "avg_loss(data) = -24.72785834289505\n",
      "Epoch 40\n",
      "avg_loss(data) = -35.44095220747735\n",
      "Epoch 50\n",
      "avg_loss(data) = -45.80643894855723\n",
      "Epoch 60\n",
      "avg_loss(data) = -55.943613144858205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "avg_loss(data) = -65.90990911008669\n",
      "Epoch 80\n",
      "avg_loss(data) = -75.74368146738935\n",
      "Epoch 90\n",
      "avg_loss(data) = -85.47325754155388\n",
      "Epoch 100\n",
      "avg_loss(data) = -95.12010918060746\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(1e-3)\n",
    "epochs = 100\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "show_every = epochs/10\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(Flux.params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, Flux.params(nn), gs)\n",
    "  end\n",
    "  if epoch % show_every == 0\n",
    "    println(\"Epoch \" * string(epoch))\n",
    "    @show avg_loss(data)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Encode NN to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_json_nn(nn::Chain)::String = JSON.json([Dict(:weight => nn.layers[i].weight, :bias => nn.layers[i].bias) for i in range(1, length(nn.layers))])\n",
    "# Export as JSON\n",
    "write(\"nn.json\", serialize_json_nn(nn))\n",
    "serialize(\"nn-binary.jlb\", nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Matrix{Float64}(::Vector{Any})\nClosest candidates are:\n  Array{T, N}(::AbstractArray{S, N}) where {T, N, S} at array.jl:626\n  Array{T, N}(!Matched::Union{Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}} where T, Union{Base.LogicalIndex{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Base.ReinterpretArray{T, N, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s14\"}, var\"#s14\"}} where var\"#s14\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Base.ReshapedArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}}, SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}} where var\"#s15\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, SubArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, Base.ReshapedArray{<:Any, <:Any, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, var\"#s16\"}} where var\"#s16\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Adjoint{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Diagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, LowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Symmetric{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Transpose{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Tridiagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitLowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitUpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, PermutedDimsArray{T, N, <:Any, <:Any, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}} where {T, N}}) where {T, N} at C:\\Users\\adeli\\.julia\\packages\\NNlibCUDA\\C6t0p\\src\\batchedadjtrans.jl:16\n  Matrix{T}(!Matched::Diagonal) where T at C:\\Users\\adeli\\.julia\\juliaup\\julia-1.8.5+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\diagonal.jl:82\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Matrix{Float64}(::Vector{Any})\n",
      "Closest candidates are:\n",
      "  Array{T, N}(::AbstractArray{S, N}) where {T, N, S} at array.jl:626\n",
      "  Array{T, N}(!Matched::Union{Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}} where T, Union{Base.LogicalIndex{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Base.ReinterpretArray{T, N, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s14\"}, var\"#s14\"}} where var\"#s14\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Base.ReshapedArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}}, SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}} where var\"#s15\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, SubArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, Base.ReshapedArray{<:Any, <:Any, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, var\"#s16\"}} where var\"#s16\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Adjoint{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Diagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, LowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Symmetric{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Transpose{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Tridiagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitLowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitUpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, PermutedDimsArray{T, N, <:Any, <:Any, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}} where {T, N}}) where {T, N} at C:\\Users\\adeli\\.julia\\packages\\NNlibCUDA\\C6t0p\\src\\batchedadjtrans.jl:16\n",
      "  Matrix{T}(!Matched::Diagonal) where T at C:\\Users\\adeli\\.julia\\juliaup\\julia-1.8.5+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\diagonal.jl:82\n",
      "  ...\n",
      "\n",
      "Stacktrace:\n",
      " [1] convert(#unused#::Type{Matrix{Float64}}, a::Vector{Any})\n",
      "   @ Base .\\array.jl:617\n",
      " [2] (::var\"#117#118\")(layer::Dict{String, Any})\n",
      "   @ Main c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\dev\\notebooks\\two-class\\two-class.jl.ipynb:6\n",
      " [3] iterate\n",
      "   @ .\\generator.jl:47 [inlined]\n",
      " [4] _collect(c::Vector{Any}, itr::Base.Generator{Vector{Any}, var\"#117#118\"}, #unused#::Base.EltypeUnknown, isz::Base.HasShape{1})\n",
      "   @ Base .\\array.jl:807\n",
      " [5] collect_similar(cont::Vector{Any}, itr::Base.Generator{Vector{Any}, var\"#117#118\"})\n",
      "   @ Base .\\array.jl:716\n",
      " [6] map(f::Function, A::Vector{Any})\n",
      "   @ Base .\\abstractarray.jl:2933\n",
      " [7] top-level scope\n",
      "   @ c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\dev\\notebooks\\two-class\\two-class.jl.ipynb:6"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "json_string = read(\"nn.json\", String)\n",
    "parsed_data = JSON.parse(json_string)\n",
    "\n",
    "# Convert JSON string back to neural network\n",
    "nndes = Chain(map(layer -> Dense(convert(Matrix{Float64}, layer[\"weight\"]), convert(Array{Float64, 1}, layer[\"bias\"])), parsed_data))\n",
    "\n",
    "println(nn)\n",
    "println(nndes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
