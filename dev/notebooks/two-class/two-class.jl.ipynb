{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding a neural network generated with Julia into a JSON file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: generate a non-linear dataset\n",
    "- Step 2: Write data to a CSV file\n",
    "- Step 3: Build the neural network\n",
    "- Step 4: Train the neural network\n",
    "- Step 5: Encode NN to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "using Pkg; Pkg.activate(\".\")\n",
    "\n",
    "using Flux, Plots, Random, Statistics, LaplaceRedux\n",
    "using Flux.Optimise: update!, Adam\n",
    "theme(:lime)\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "using JSON\n",
    "using Serialization\n",
    "using Tullio\n",
    "\n",
    "using LinearAlgebra\n",
    "using Zygote\n",
    "\n",
    "Random.seed!(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: generate a non-linear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip([[1.2810855910752834, 0.9537556211870458], [1.9474772862101295, 1.9447957837448069], [1.6636346147891956, 4.8628177740880245], [1.2489738983854946, 0.5580423579013771], [2.871567531990057, 3.8997622868544735], [2.6735996163580333, 2.060337078130556], [2.2579852508892126, 2.118623127686306], [4.112431480759879, 1.6708445365124773], [4.913409450634119, 4.619188930199143], [0.9249415185713727, 4.583347540628576]  …  [-3.8718411489872095, 4.605441383957622], [-2.82690755957905, 0.9430727186165219], [-2.9682923550013265, 2.782447703989634], [-3.742254048942101, 2.0556485379415905], [-3.0160641261110595, 1.4538519714978864], [-0.8216229870174887, 3.9991152958403244], [-0.676817480886136, 2.6732572835074833], [-1.0647606740819762, 3.84544106009164], [-4.697040240569821, 1.0950690324757328], [-2.521217278628995, 1.1608140597795131]], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs, ys = LaplaceRedux.Data.toy_data_non_linear(200)\n",
    "X = hcat(xs...) # bring into tabular format\n",
    "data = zip(xs,ys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Write data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file for writing\n",
    "file = \"data.csv\"\n",
    "csv_file = open(file, \"w\")\n",
    "\n",
    "# Write the header\n",
    "write(csv_file, \"x1,x2,y\\n\")\n",
    "\n",
    "# Write the data\n",
    "for ((x1, x2), y) in data\n",
    "    write(csv_file, \"$x1,$x2,$y\\n\")\n",
    "end\n",
    "\n",
    "# Close the CSV file\n",
    "close(csv_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_hidden = 7\n",
    "D = size(X,1)\n",
    "nn = Chain(\n",
    "    Dense(D, n_hidden, σ),\n",
    "    Dense(n_hidden, 1)\n",
    ")\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Layer with Float32 parameters got Float64 input.\n",
      "│   The input will be converted, but any earlier layers may be very slow.\n",
      "│   layer = Dense(2 => 7, σ)\n",
      "│   summary(x) = 2-element Vector{Float64}\n",
      "└ @ Flux C:\\Users\\adeli\\.julia\\packages\\Flux\\FWgS0\\src\\layers\\stateless.jl:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss(data) = 0.6876893395930529\n",
      "Epoch 20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg_loss(data) = 0.6438441320508719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "avg_loss(data) = 0.5680330287199468"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40\n",
      "avg_loss(data) = 0.47009542301297186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "avg_loss(data) = 0.3704357376694679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "avg_loss(data) = 0.2882214645668864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "avg_loss(data) = 0.22462922818958758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "avg_loss(data) = 0.17650087805464865"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90\n",
      "avg_loss(data) = 0.1410102225281298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      "avg_loss(data) = 0.11529439479578286\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(1e-3)\n",
    "epochs = 100\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "show_every = epochs/10\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(Flux.params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, Flux.params(nn), gs)\n",
    "  end\n",
    "  if epoch % show_every == 0\n",
    "    println(\"Epoch \" * string(epoch))\n",
    "    @show avg_loss(data)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Encode NN to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_json_nn(nn::Chain)::String = JSON.json([Dict(:weight => nn.layers[i].weight, :bias => nn.layers[i].bias) for i in range(1, length(nn.layers))])\n",
    "# Export as JSON\n",
    "write(\"nn.json\", serialize_json_nn(nn))\n",
    "serialize(\"nn-binary.jlb\", nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Matrix{Float64}(::Vector{Any})\nClosest candidates are:\n  Array{T, N}(::AbstractArray{S, N}) where {T, N, S} at array.jl:626\n  Array{T, N}(!Matched::Union{Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}} where T, Union{Base.LogicalIndex{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Base.ReinterpretArray{T, N, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s14\"}, var\"#s14\"}} where var\"#s14\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Base.ReshapedArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}}, SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}} where var\"#s15\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, SubArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, Base.ReshapedArray{<:Any, <:Any, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, var\"#s16\"}} where var\"#s16\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Adjoint{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Diagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, LowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Symmetric{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Transpose{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Tridiagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitLowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitUpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, PermutedDimsArray{T, N, <:Any, <:Any, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}} where {T, N}}) where {T, N} at C:\\Users\\adeli\\.julia\\packages\\NNlibCUDA\\C6t0p\\src\\batchedadjtrans.jl:16\n  Matrix{T}(!Matched::Diagonal) where T at C:\\Users\\adeli\\.julia\\juliaup\\julia-1.8.5+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\diagonal.jl:82\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Matrix{Float64}(::Vector{Any})\n",
      "Closest candidates are:\n",
      "  Array{T, N}(::AbstractArray{S, N}) where {T, N, S} at array.jl:626\n",
      "  Array{T, N}(!Matched::Union{Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}} where T, Union{Base.LogicalIndex{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Base.ReinterpretArray{T, N, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s14\"}, var\"#s14\"}} where var\"#s14\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Base.ReshapedArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}}, SubArray{<:Any, <:Any, var\"#s15\"}, var\"#s15\"}} where var\"#s15\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, SubArray{T, N, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, Base.ReshapedArray{<:Any, <:Any, <:Union{Base.ReinterpretArray{<:Any, <:Any, <:Any, <:Union{SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, SubArray{<:Any, <:Any, var\"#s16\"}, var\"#s16\"}}, var\"#s16\"}} where var\"#s16\"<:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}, Adjoint{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Diagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, LowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Symmetric{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Transpose{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, Tridiagonal{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitLowerTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UnitUpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, UpperTriangular{T, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}, PermutedDimsArray{T, N, <:Any, <:Any, <:Union{NNlib.BatchedAdjoint{T, <:CUDA.CuArray{T}}, NNlib.BatchedTranspose{T, <:CUDA.CuArray{T}}}}} where {T, N}}) where {T, N} at C:\\Users\\adeli\\.julia\\packages\\NNlibCUDA\\C6t0p\\src\\batchedadjtrans.jl:16\n",
      "  Matrix{T}(!Matched::Diagonal) where T at C:\\Users\\adeli\\.julia\\juliaup\\julia-1.8.5+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.8\\LinearAlgebra\\src\\diagonal.jl:82\n",
      "  ...\n",
      "\n",
      "Stacktrace:\n",
      " [1] convert(#unused#::Type{Matrix{Float64}}, a::Vector{Any})\n",
      "   @ Base .\\array.jl:617\n",
      " [2] (::var\"#43#44\")(layer::Dict{String, Any})\n",
      "   @ Main c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\dev\\notebooks\\two-class\\two-class.jl.ipynb:6\n",
      " [3] iterate\n",
      "   @ .\\generator.jl:47 [inlined]\n",
      " [4] _collect(c::Vector{Any}, itr::Base.Generator{Vector{Any}, var\"#43#44\"}, #unused#::Base.EltypeUnknown, isz::Base.HasShape{1})\n",
      "   @ Base .\\array.jl:807\n",
      " [5] collect_similar(cont::Vector{Any}, itr::Base.Generator{Vector{Any}, var\"#43#44\"})\n",
      "   @ Base .\\array.jl:716\n",
      " [6] map(f::Function, A::Vector{Any})\n",
      "   @ Base .\\abstractarray.jl:2933\n",
      " [7] top-level scope\n",
      "   @ c:\\Users\\adeli\\OneDrive\\Desktop\\facultate\\2nd year\\Q4 - Software Project\\LaplaceRedux.jl\\dev\\notebooks\\two-class\\two-class.jl.ipynb:6"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "json_string = read(\"nn.json\", String)\n",
    "parsed_data = JSON.parse(json_string)\n",
    "\n",
    "# Convert JSON string back to neural network\n",
    "nndes = Chain(map(layer -> Dense(convert(Matrix{Float64}, layer[\"weight\"]), convert(Array{Float64, 1}, layer[\"bias\"])), parsed_data))\n",
    "\n",
    "println(nn)\n",
    "println(nndes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
