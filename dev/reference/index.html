<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · LaplaceRedux.jl</title><meta name="title" content="Reference · LaplaceRedux.jl"/><meta property="og:title" content="Reference · LaplaceRedux.jl"/><meta property="twitter:title" content="Reference · LaplaceRedux.jl"/><meta name="description" content="Documentation for LaplaceRedux.jl."/><meta property="og:description" content="Documentation for LaplaceRedux.jl."/><meta property="twitter:description" content="Documentation for LaplaceRedux.jl."/><meta property="og:url" content="https://juliatrustworthyai.github.io/LaplaceRedux.jl/reference/"/><meta property="twitter:url" content="https://juliatrustworthyai.github.io/LaplaceRedux.jl/reference/"/><link rel="canonical" href="https://juliatrustworthyai.github.io/LaplaceRedux.jl/reference/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="LaplaceRedux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">LaplaceRedux.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/logit/">Logistic Regression</a></li><li><a class="tocitem" href="../tutorials/mlp/">MLP Binary Classifier</a></li><li><a class="tocitem" href="../tutorials/multi/">MLP Multi-Label Classifier</a></li><li><a class="tocitem" href="../tutorials/regression/">MLP Regression</a></li><li><a class="tocitem" href="../tutorials/prior/">A note on the prior ...</a></li><li><a class="tocitem" href="../tutorials/calibration/">Calibrated forecasts</a></li></ul></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Exported-functions"><span>Exported functions</span></a></li><li><a class="tocitem" href="#Internal-functions"><span>Internal functions</span></a></li></ul></li><li><a class="tocitem" href="../mlj_interface/">MLJ interface</a></li><li><a class="tocitem" href="../resources/_resources/">Additional Resources</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/main/docs/src/reference.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="All-functions-and-types"><a class="docs-heading-anchor" href="#All-functions-and-types">All functions and types</a><a id="All-functions-and-types-1"></a><a class="docs-heading-anchor-permalink" href="#All-functions-and-types" title="Permalink"></a></h1><ul><li><a href="#LaplaceRedux.AbstractDecomposition"><code>LaplaceRedux.AbstractDecomposition</code></a></li><li><a href="#LaplaceRedux.AbstractLaplace-Tuple{AbstractArray}"><code>LaplaceRedux.AbstractLaplace</code></a></li><li><a href="#LaplaceRedux.AbstractLaplace"><code>LaplaceRedux.AbstractLaplace</code></a></li><li><a href="#LaplaceRedux.Curvature.CurvatureInterface"><code>LaplaceRedux.Curvature.CurvatureInterface</code></a></li><li><a href="#LaplaceRedux.Curvature.EmpiricalFisher"><code>LaplaceRedux.Curvature.EmpiricalFisher</code></a></li><li><a href="#LaplaceRedux.Curvature.GGN"><code>LaplaceRedux.Curvature.GGN</code></a></li><li><a href="#LaplaceRedux.EstimationParams"><code>LaplaceRedux.EstimationParams</code></a></li><li><a href="#LaplaceRedux.EstimationParams-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}"><code>LaplaceRedux.EstimationParams</code></a></li><li><a href="#LaplaceRedux.FullHessian"><code>LaplaceRedux.FullHessian</code></a></li><li><a href="#LaplaceRedux.HessianStructure"><code>LaplaceRedux.HessianStructure</code></a></li><li><a href="#LaplaceRedux.Kron"><code>LaplaceRedux.Kron</code></a></li><li><a href="#LaplaceRedux.KronDecomposed"><code>LaplaceRedux.KronDecomposed</code></a></li><li><a href="#LaplaceRedux.KronHessian"><code>LaplaceRedux.KronHessian</code></a></li><li><a href="#LaplaceRedux.Laplace"><code>LaplaceRedux.Laplace</code></a></li><li><a href="#LaplaceRedux.Laplace-Tuple{Any}"><code>LaplaceRedux.Laplace</code></a></li><li><a href="#LaplaceRedux.LaplaceClassifier"><code>LaplaceRedux.LaplaceClassifier</code></a></li><li><a href="#LaplaceRedux.LaplaceParams"><code>LaplaceRedux.LaplaceParams</code></a></li><li><a href="#LaplaceRedux.LaplaceRegressor"><code>LaplaceRedux.LaplaceRegressor</code></a></li><li><a href="#LaplaceRedux.Posterior-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.Posterior</code></a></li><li><a href="#LaplaceRedux.Posterior"><code>LaplaceRedux.Posterior</code></a></li><li><a href="#LaplaceRedux.Prior"><code>LaplaceRedux.Prior</code></a></li><li><a href="#LaplaceRedux.Prior-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}"><code>LaplaceRedux.Prior</code></a></li><li><a href="#Base.:*-Tuple{Real, LaplaceRedux.Kron}"><code>Base.:*</code></a></li><li><a href="#Base.:*-Tuple{LaplaceRedux.KronDecomposed, Number}"><code>Base.:*</code></a></li><li><a href="#Base.:+-Tuple{LaplaceRedux.KronDecomposed, LinearAlgebra.Diagonal}"><code>Base.:+</code></a></li><li><a href="#Base.:+-Tuple{LaplaceRedux.KronDecomposed, Number}"><code>Base.:+</code></a></li><li><a href="#Base.:+-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}"><code>Base.:+</code></a></li><li><a href="#Base.:==-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}"><code>Base.:==</code></a></li><li><a href="#Base.getindex-Tuple{LaplaceRedux.Kron, Int64}"><code>Base.getindex</code></a></li><li><a href="#Base.getindex-Tuple{LaplaceRedux.KronDecomposed, Int64}"><code>Base.getindex</code></a></li><li><a href="#Base.length-Tuple{LaplaceRedux.KronDecomposed}"><code>Base.length</code></a></li><li><a href="#Flux.params-Tuple{Laplace}"><code>Flux.params</code></a></li><li><a href="#Flux.params-Tuple{Any, LaplaceRedux.EstimationParams}"><code>Flux.params</code></a></li><li><a href="#LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}"><code>LaplaceRedux.Curvature.full_batched</code></a></li><li><a href="#LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}"><code>LaplaceRedux.Curvature.full_batched</code></a></li><li><a href="#LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}"><code>LaplaceRedux.Curvature.full_unbatched</code></a></li><li><a href="#LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}"><code>LaplaceRedux.Curvature.full_unbatched</code></a></li><li><a href="#LaplaceRedux.Curvature.gradients-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray, Union{Number, AbstractArray}}"><code>LaplaceRedux.Curvature.gradients</code></a></li><li><a href="#LaplaceRedux.Curvature.jacobians-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians</code></a></li><li><a href="#LaplaceRedux.Curvature.jacobians_batched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians_batched</code></a></li><li><a href="#LaplaceRedux.Curvature.jacobians_unbatched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians_unbatched</code></a></li><li><a href="#LaplaceRedux.Data.toy_data_linear"><code>LaplaceRedux.Data.toy_data_linear</code></a></li><li><a href="#LaplaceRedux.Data.toy_data_multi"><code>LaplaceRedux.Data.toy_data_multi</code></a></li><li><a href="#LaplaceRedux.Data.toy_data_non_linear"><code>LaplaceRedux.Data.toy_data_non_linear</code></a></li><li><a href="#LaplaceRedux.Data.toy_data_regression"><code>LaplaceRedux.Data.toy_data_regression</code></a></li><li><a href="#LaplaceRedux._H_factor-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._H_factor</code></a></li><li><a href="#LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.KronHessian, Any}"><code>LaplaceRedux._fit!</code></a></li><li><a href="#LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.FullHessian, Any}"><code>LaplaceRedux._fit!</code></a></li><li><a href="#LaplaceRedux._init_H-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._init_H</code></a></li><li><a href="#LaplaceRedux._weight_penalty-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._weight_penalty</code></a></li><li><a href="#LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.KronHessian, Any}"><code>LaplaceRedux.approximate</code></a></li><li><a href="#LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.FullHessian, Tuple}"><code>LaplaceRedux.approximate</code></a></li><li><a href="#LaplaceRedux.clamp-Tuple{LinearAlgebra.Eigen}"><code>LaplaceRedux.clamp</code></a></li><li><a href="#LaplaceRedux.convert_subnetwork_indices-Tuple{Vector{Vector{Int64}}, AbstractArray}"><code>LaplaceRedux.convert_subnetwork_indices</code></a></li><li><a href="#LaplaceRedux.dataset_shape-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}"><code>LaplaceRedux.dataset_shape</code></a></li><li><a href="#LaplaceRedux.decompose-Tuple{LaplaceRedux.Kron}"><code>LaplaceRedux.decompose</code></a></li><li><a href="#LaplaceRedux.default_build-Tuple{Int64, Any}"><code>LaplaceRedux.default_build</code></a></li><li><a href="#LaplaceRedux.empirical_frequency_binary_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}"><code>LaplaceRedux.empirical_frequency_binary_classification</code></a></li><li><a href="#LaplaceRedux.empirical_frequency_regression-Tuple{Any, Vector{Distributions.Normal{Float64}}}"><code>LaplaceRedux.empirical_frequency_regression</code></a></li><li><a href="#LaplaceRedux.extract_mean_and_variance-Union{Tuple{Array{Distributions.Normal{T}, 1}}, Tuple{T}} where T&lt;:AbstractFloat"><code>LaplaceRedux.extract_mean_and_variance</code></a></li><li><a href="#LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, Any}"><code>LaplaceRedux.fit!</code></a></li><li><a href="#LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, MLUtils.DataLoader}"><code>LaplaceRedux.fit!</code></a></li><li><a href="#LaplaceRedux.functional_variance-Tuple{Any, Any}"><code>LaplaceRedux.functional_variance</code></a></li><li><a href="#LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.FullHessian, Any}"><code>LaplaceRedux.functional_variance</code></a></li><li><a href="#LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.KronHessian, Matrix}"><code>LaplaceRedux.functional_variance</code></a></li><li><a href="#LaplaceRedux.get_loss_fun-Tuple{Symbol, Flux.Chain}"><code>LaplaceRedux.get_loss_fun</code></a></li><li><a href="#LaplaceRedux.get_loss_type-Tuple{Symbol, Flux.Chain}"><code>LaplaceRedux.get_loss_type</code></a></li><li><a href="#LaplaceRedux.get_map_estimate-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.get_map_estimate</code></a></li><li><a href="#LaplaceRedux.get_prior_mean-Tuple{Laplace}"><code>LaplaceRedux.get_prior_mean</code></a></li><li><a href="#LaplaceRedux.glm_predictive_distribution-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}"><code>LaplaceRedux.glm_predictive_distribution</code></a></li><li><a href="#LaplaceRedux.has_softmax_or_sigmoid_final_layer-Tuple{Flux.Chain}"><code>LaplaceRedux.has_softmax_or_sigmoid_final_layer</code></a></li><li><a href="#LaplaceRedux.hessian_approximation-Tuple{LaplaceRedux.AbstractLaplace, Any}"><code>LaplaceRedux.hessian_approximation</code></a></li><li><a href="#LaplaceRedux.instantiate_curvature!-Tuple{LaplaceRedux.EstimationParams, Any, Symbol, Symbol}"><code>LaplaceRedux.instantiate_curvature!</code></a></li><li><a href="#LaplaceRedux.interleave-Tuple"><code>LaplaceRedux.interleave</code></a></li><li><a href="#LaplaceRedux.inv_square_form-Tuple{LaplaceRedux.KronDecomposed, Matrix}"><code>LaplaceRedux.inv_square_form</code></a></li><li><a href="#LaplaceRedux.log_det_posterior_precision-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_posterior_precision</code></a></li><li><a href="#LaplaceRedux.log_det_prior_precision-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_prior_precision</code></a></li><li><a href="#LaplaceRedux.log_det_ratio-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_ratio</code></a></li><li><a href="#LaplaceRedux.log_likelihood-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_likelihood</code></a></li><li><a href="#LaplaceRedux.log_marginal_likelihood-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_marginal_likelihood</code></a></li><li><a href="#LaplaceRedux.logdetblock-Tuple{Tuple{LinearAlgebra.Eigen, LinearAlgebra.Eigen}, Number}"><code>LaplaceRedux.logdetblock</code></a></li><li><a href="#LaplaceRedux.mm-Tuple{LaplaceRedux.KronDecomposed, Any}"><code>LaplaceRedux.mm</code></a></li><li><a href="#LaplaceRedux.n_params-Tuple{Laplace}"><code>LaplaceRedux.n_params</code></a></li><li><a href="#LaplaceRedux.n_params-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.n_params</code></a></li><li><a href="#LaplaceRedux.optimize_prior!-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.optimize_prior!</code></a></li><li><a href="#LaplaceRedux.outdim-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.outdim</code></a></li><li><a href="#LaplaceRedux.outdim-Tuple{Flux.Chain}"><code>LaplaceRedux.outdim</code></a></li><li><a href="#LaplaceRedux.posterior_covariance"><code>LaplaceRedux.posterior_covariance</code></a></li><li><a href="#LaplaceRedux.posterior_precision"><code>LaplaceRedux.posterior_precision</code></a></li><li><a href="#LaplaceRedux.predict-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}"><code>LaplaceRedux.predict</code></a></li><li><a href="#LaplaceRedux.prior_precision-Tuple{Laplace}"><code>LaplaceRedux.prior_precision</code></a></li><li><a href="#LaplaceRedux.probit-Tuple{AbstractArray, AbstractArray}"><code>LaplaceRedux.probit</code></a></li><li><a href="#LaplaceRedux.rescale_stddev-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, T}} where T&lt;:AbstractFloat"><code>LaplaceRedux.rescale_stddev</code></a></li><li><a href="#LaplaceRedux.sharpness_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}"><code>LaplaceRedux.sharpness_classification</code></a></li><li><a href="#LaplaceRedux.sharpness_regression-Tuple{Vector{Distributions.Normal{Float64}}}"><code>LaplaceRedux.sharpness_regression</code></a></li><li><a href="#LaplaceRedux.sigma_scaling-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, Vector{&lt;:AbstractFloat}}} where T&lt;:AbstractFloat"><code>LaplaceRedux.sigma_scaling</code></a></li><li><a href="#LaplaceRedux.validate_subnetwork_indices-Tuple{Union{Nothing, Vector{Vector{Int64}}}, Any}"><code>LaplaceRedux.validate_subnetwork_indices</code></a></li><li><a href="#LinearAlgebra.det-Tuple{LaplaceRedux.KronDecomposed}"><code>LinearAlgebra.det</code></a></li><li><a href="#LinearAlgebra.logdet-Tuple{LaplaceRedux.KronDecomposed}"><code>LinearAlgebra.logdet</code></a></li><li><a href="#MLJModelInterface.fit-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any, Any}"><code>MLJModelInterface.fit</code></a></li><li><a href="#MLJModelInterface.fitted_params-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}"><code>MLJModelInterface.fitted_params</code></a></li><li><a href="#MLJModelInterface.is_same_except-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Symbol}}"><code>MLJModelInterface.is_same_except</code></a></li><li><a href="#MLJModelInterface.predict-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}"><code>MLJModelInterface.predict</code></a></li><li><a href="#MLJModelInterface.training_losses-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}"><code>MLJModelInterface.training_losses</code></a></li><li><a href="#MLJModelInterface.update-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Any, 5}}"><code>MLJModelInterface.update</code></a></li><li><a href="#LaplaceRedux.@zb-Tuple{Any}"><code>LaplaceRedux.@zb</code></a></li></ul><h2 id="Exported-functions"><a class="docs-heading-anchor" href="#Exported-functions">Exported functions</a><a id="Exported-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Exported-functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Laplace" href="#LaplaceRedux.Laplace"><code>LaplaceRedux.Laplace</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Laplace</code></pre><p>Concrete type for Laplace approximation. This type is a subtype of <code>AbstractLaplace</code> and is used to store all the necessary information for a Laplace approximation.</p><p><strong>Fields</strong></p><ul><li><code>model::Flux.Chain</code>: The model to be approximated.</li><li><code>likelihood::Symbol</code>: The likelihood function to be used.</li><li><code>est_params::</code><a href="#LaplaceRedux.EstimationParams"><code>EstimationParams</code></a>: The estimation parameters.</li><li><code>prior::</code><a href="#LaplaceRedux.Prior"><code>Prior</code></a>: The parameters defining prior distribution.</li><li><code>posterior::</code><a href="#LaplaceRedux.Posterior"><code>Posterior</code></a>: The posterior distribution.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L50-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Laplace-Tuple{Any}" href="#LaplaceRedux.Laplace-Tuple{Any}"><code>LaplaceRedux.Laplace</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Laplace(model::Any; likelihood::Symbol, kwargs...)</code></pre><p>Outer constructor for Laplace approximation. This function constructs a Laplace object from a given model and likelihood function.</p><p><strong>Arguments</strong></p><ul><li><code>model::Any</code>: The model to be approximated (a Flux.Chain).</li><li><code>likelihood::Symbol</code>: The likelihood function to be used. Possible values are <code>:regression</code> and <code>:classification</code>.</li></ul><p><strong>Keyword Arguments</strong></p><p>See <a href="#LaplaceRedux.LaplaceParams"><code>LaplaceParams</code></a> for a description of the keyword arguments.</p><p><strong>Returns</strong></p><ul><li><code>la::Laplace</code>: The Laplace object.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Flux, LaplaceRedux
nn = Chain(Dense(2,1))
la = Laplace(nn, likelihood=:regression)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L71-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.LaplaceClassifier" href="#LaplaceRedux.LaplaceClassifier"><code>LaplaceRedux.LaplaceClassifier</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LaplaceClassifier</code></pre><p>A model type for constructing a laplace classifier, based on <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">LaplaceClassifier = @load LaplaceClassifier pkg=LaplaceRedux</code></pre><p>Do <code>model = LaplaceClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>LaplaceClassifier(model=...)</code>.</p><p><code>LaplaceClassifier</code> implements the <a href="https://proceedings.neurips.cc/paper/2021/hash/a3923dbe2f702eff254d67b48ae2f06e-Abstract.html">Laplace Redux – Effortless Bayesian Deep Learning</a>, originally published in Daxberger, E., Kristiadi, A., Immer, A., Eschenhagen, R., Bauer, M., Hennig, P. (2021): &quot;Laplace Redux – Effortless Bayesian Deep Learning.&quot;, NIPS&#39;21: Proceedings of the 35th International Conference on Neural Information Processing Systems*, Article No. 1537, pp. 20089–20103 for classification models.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, given a dataset X,y and a <code>Flux_Chain</code> adapted to the dataset, pass the chain to the model</p><pre><code class="language-julia hljs">laplace_model = LaplaceClassifier(model = Flux_Chain,kwargs...)</code></pre><p>then bind an instance <code>laplace_model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(laplace_model, X, y)</code></pre><p>where</p><ul><li><p><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:OrderedFactor</code> or <code>&lt;:Multiclass</code>; check the scitype with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyperparameters (format: name-type-default value-restrictions)</strong></p><ul><li><p><code>model::Union{Flux.Chain,Nothing} = nothing</code>:                                                     Either nothing or a Flux model provided by the user and compatible with the dataset. In the former case, LaplaceRedux will use a standard MLP with 2 hidden layers with 20 neurons each.</p></li><li><p><code>flux_loss = Flux.Losses.logitcrossentropy</code> :                                                     a Flux loss function</p></li><li><p><code>optimiser = Adam()</code>                                                                              a Flux optimiser</p></li><li><p><code>epochs::Integer = 1000::(_ &gt; 0)</code>:                                                                the number of training epochs.</p></li><li><p><code>batch_size::Integer = 32::(_ &gt; 0)</code>:                                                              the batch size.</p></li><li><p><code>subset_of_weights::Symbol = :all::(_ in (:all, :last_layer, :subnetwork))</code>:                      the subset of weights to use, either <code>:all</code>, <code>:last_layer</code>, or <code>:subnetwork</code>.</p></li><li><p><code>subnetwork_indices = nothing</code>:                                                                   the indices of the subnetworks.</p></li><li><p><code>hessian_structure::Union{HessianStructure,Symbol,String} = :full::(_ in (:full, :diagonal))</code>:    the structure of the Hessian matrix, either <code>:full</code> or <code>:diagonal</code>.</p></li><li><p><code>backend::Symbol = :GGN::(_ in (:GGN, :EmpiricalFisher))</code>:                                        the backend to use, either <code>:GGN</code> or <code>:EmpiricalFisher</code>.</p></li><li><p><code>σ::Float64 = 1.0</code>:                                                                               the standard deviation of the prior distribution.</p></li><li><p><code>μ₀::Float64 = 0.0</code>:                                                                              the mean of the prior distribution.</p></li><li><p><code>P₀::Union{AbstractMatrix,UniformScaling,Nothing} = nothing</code>:                                     the covariance matrix of the prior distribution.</p></li><li><p><code>fit_prior_nsteps::Int = 100::(_ &gt; 0)</code>:                                                          the number of steps used to fit the priors.</p></li><li><p><code>link_approx::Symbol = :probit::(_ in (:probit, :plugin))</code>:                                       the approximation to adopt to compute the probabilities.</p></li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are probabilistic, but uncalibrated.</p></li><li><p><code>predict_mode(mach, Xnew)</code>: instead return the mode of each prediction above.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>μ</code>: The mean of the posterior distribution.</p></li><li><p><code>H</code>: The Hessian of the posterior distribution.</p></li><li><p><code>P</code>: The precision matrix of the posterior distribution.</p></li><li><p><code>Σ</code>: The covariance matrix of the posterior distribution.</p></li><li><p><code>n_data</code>: The number of data points.</p></li><li><p><code>n_params</code>: The number of parameters.</p></li><li><p><code>n_out</code>: The number of outputs.</p></li><li><p><code>loss</code>: The loss value of the posterior distribution.</p></li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>loss_history</code>: an array containing the total loss per epoch.</li></ul><p><strong>Accessor functions</strong></p><ul><li><code>training_losses(mach)</code>: return the loss history from report</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using MLJ
LaplaceClassifier = @load LaplaceClassifier pkg=LaplaceRedux

X, y = @load_iris

# Define the Flux Chain model
using Flux
model = Chain(
    Dense(4, 10, relu),
    Dense(10, 10, relu),
    Dense(10, 3)
)

#Define the LaplaceClassifier
model = LaplaceClassifier(model=model)

mach = machine(model, X, y) |&gt; fit!

Xnew = (sepal_length = [6.4, 7.2, 7.4],
        sepal_width = [2.8, 3.0, 2.8],
        petal_length = [5.6, 5.8, 6.1],
        petal_width = [2.1, 1.6, 1.9],)
yhat = predict(mach, Xnew) # probabilistic predictions
predict_mode(mach, Xnew)   # point predictions
training_losses(mach)      # loss history per epoch
pdf.(yhat, &quot;virginica&quot;)    # probabilities for the &quot;verginica&quot; class
fitted_params(mach)        # NamedTuple with the fitted params of Laplace
</code></pre><p>See also <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L578-L593">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.LaplaceRegressor" href="#LaplaceRedux.LaplaceRegressor"><code>LaplaceRedux.LaplaceRegressor</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LaplaceRegressor</code></pre><p>A model type for constructing a laplace regressor, based on <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">LaplaceRegressor = @load LaplaceRegressor pkg=LaplaceRedux</code></pre><p>Do <code>model = LaplaceRegressor()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>LaplaceRegressor(model=...)</code>.</p><p><code>LaplaceRegressor</code> implements the <a href="https://proceedings.neurips.cc/paper/2021/hash/a3923dbe2f702eff254d67b48ae2f06e-Abstract.html">Laplace Redux – Effortless Bayesian Deep Learning</a>, originally published in Daxberger, E., Kristiadi, A., Immer, A., Eschenhagen, R., Bauer, M., Hennig, P. (2021): &quot;Laplace Redux – Effortless Bayesian Deep Learning.&quot;, NIPS&#39;21: Proceedings of the 35th International Conference on Neural Information Processing Systems*, Article No. 1537, pp. 20089–20103 for regression models.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, given a dataset X,y and a <code>Flux_Chain</code> adapted to the dataset, pass the chain to the model</p><pre><code class="language-julia hljs">laplace_model = LaplaceRegressor(model = Flux_Chain,kwargs...)</code></pre><p>then bind an instance <code>laplace_model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(laplace_model, X, y)</code></pre><p>where</p><ul><li><p><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:Continuous</code>; check the scitype with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyperparameters (format: name-type-default value-restrictions)</strong></p><ul><li><p><code>model::Union{Flux.Chain,Nothing} = nothing</code>:                                                     Either nothing or a Flux model provided by the user and compatible with the dataset. In the former case, LaplaceRedux will use a standard MLP with 2 hidden layers with 20 neurons each.</p></li><li><p><code>flux_loss = Flux.Losses.logitcrossentropy</code> :                                                     a Flux loss function</p></li><li><p><code>optimiser = Adam()</code>                                                                              a Flux optimiser</p></li><li><p><code>epochs::Integer = 1000::(_ &gt; 0)</code>:                                                                the number of training epochs.</p></li><li><p><code>batch_size::Integer = 32::(_ &gt; 0)</code>:                                                              the batch size.</p></li><li><p><code>subset_of_weights::Symbol = :all::(_ in (:all, :last_layer, :subnetwork))</code>:                      the subset of weights to use, either <code>:all</code>, <code>:last_layer</code>, or <code>:subnetwork</code>.</p></li><li><p><code>subnetwork_indices = nothing</code>:                                                                   the indices of the subnetworks.</p></li><li><p><code>hessian_structure::Union{HessianStructure,Symbol,String} = :full::(_ in (:full, :diagonal))</code>:    the structure of the Hessian matrix, either <code>:full</code> or <code>:diagonal</code>.</p></li><li><p><code>backend::Symbol = :GGN::(_ in (:GGN, :EmpiricalFisher))</code>:                                        the backend to use, either <code>:GGN</code> or <code>:EmpiricalFisher</code>.</p></li><li><p><code>σ::Float64 = 1.0</code>:                                                                               the standard deviation of the prior distribution.</p></li><li><p><code>μ₀::Float64 = 0.0</code>:                                                                              the mean of the prior distribution.</p></li><li><p><code>P₀::Union{AbstractMatrix,UniformScaling,Nothing} = nothing</code>:                                     the covariance matrix of the prior distribution.</p></li><li><p><code>fit_prior_nsteps::Int = 100::(_ &gt; 0)</code>:                                                          the number of steps used to fit the priors.</p></li></ul><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are probabilistic, but uncalibrated.</p></li><li><p><code>predict_mode(mach, Xnew)</code>: instead return the mode of each prediction above.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>μ</code>: The mean of the posterior distribution.</p></li><li><p><code>H</code>: The Hessian of the posterior distribution.</p></li><li><p><code>P</code>: The precision matrix of the posterior distribution.</p></li><li><p><code>Σ</code>: The covariance matrix of the posterior distribution.</p></li><li><p><code>n_data</code>: The number of data points.</p></li><li><p><code>n_params</code>: The number of parameters.</p></li><li><p><code>n_out</code>: The number of outputs.</p></li></ul><ul><li><code>loss</code>: The loss value of the posterior distribution.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>loss_history</code>: an array containing the total loss per epoch.</li></ul><p><strong>Accessor functions</strong></p><ul><li><code>training_losses(mach)</code>: return the loss history from report</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using MLJ
using Flux
LaplaceRegressor = @load LaplaceRegressor pkg=LaplaceRedux
model = Chain(
    Dense(4, 10, relu),
    Dense(10, 10, relu),
    Dense(10, 1)
)
model = LaplaceRegressor(model=model)

X, y = make_regression(100, 4; noise=0.5, sparse=0.2, outliers=0.1)
mach = machine(model, X, y) |&gt; fit!

Xnew, _ = make_regression(3, 4; rng=123)
yhat = predict(mach, Xnew) # probabilistic predictions
predict_mode(mach, Xnew)   # point predictions
training_losses(mach)      # loss history per epoch
fitted_params(mach)        # NamedTuple with the fitted params of Laplace
</code></pre><p>See also <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L720-L735">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.empirical_frequency_binary_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}" href="#LaplaceRedux.empirical_frequency_binary_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}"><code>LaplaceRedux.empirical_frequency_binary_classification</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">empirical_frequency_binary_classification(y_binary, distributions::Vector{Bernoulli{Float64}}; n_bins::Int=20)</code></pre><p>FOR BINARY CLASSIFICATION MODELS.<br/>Given a calibration dataset <span>$(x_t, y_t)$</span> for <span>$i ∈ {1,...,T}$</span> let <span>$p_t= H(x_t)∈[0,1]$</span> be the forecasted probability. <br/>We group the <span>$p_t$</span> into intervals <span>$I_j$</span> for <span>$j= 1,2,...,m$</span> that form a partition of [0,1].  The function computes the observed average <span>$p_j= T^-1_j ∑_{t:p_t ∈ I_j} y_j$</span> in each interval <span>$I_j$</span>.  <br/>Source: <a href="https://arxiv.org/abs/1807.00263">Kuleshov, Fenner, Ermon 2018</a></p><p>Inputs: <br/>    - <code>y_binary</code>: the array of outputs <span>$y_t$</span> numerically coded: 1 for the target class, 0 for the null class. <br/>    - <code>distributions</code>: an array of Bernoulli distributions <br/>    - <code>n_bins</code>: number of equally spaced bins to use.</p><p>Outputs: <br/>    - <code>num_p_per_interval</code>: array with the number of probabilities falling within interval. <br/>    - <code>emp_avg</code>: array with the observed empirical average per interval. <br/>    - <code>bin_centers</code>: array with the centers of the bins. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L85-L104">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.empirical_frequency_regression-Tuple{Any, Vector{Distributions.Normal{Float64}}}" href="#LaplaceRedux.empirical_frequency_regression-Tuple{Any, Vector{Distributions.Normal{Float64}}}"><code>LaplaceRedux.empirical_frequency_regression</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">empirical_frequency_regression(Y_cal, distributions::Distributions.Normal, n_bins=20)</code></pre><p>Dispatched version for Normal distributions FOR REGRESSION MODELS.  <br/>Given a calibration dataset <span>$(x_t, y_t)$</span> for <span>$i ∈ {1,...,T}$</span> and an array of predicted distributions, the function calculates the empirical frequency</p><p class="math-container">\[p^hat_j = {y_t|F_t(y_t)&lt;= p_j, t= 1,....,T}/T,\]</p><p>where <span>$T$</span> is the number of calibration points, <span>$p_j$</span> is the confidence level and <span>$F_t$</span> is the  cumulative distribution function of the predicted distribution targeting <span>$y_t$</span>. <br/>Source: <a href="https://arxiv.org/abs/1807.00263">Kuleshov, Fenner, Ermon 2018</a></p><p>Inputs: <br/>    - <code>Y_cal</code>: a vector of values <span>$y_t$</span><br/>    - <code>distributions</code>:a Vector{Distributions.Normal{Float64}} of distributions stacked row-wise.<br/>        For example the output of LaplaceRedux.predict(la,X<em>cal). <br/>    - `n</em>bins`: number of equally spaced bins to use.<br/>Outputs:<br/>    - <code>counts</code>: an array cointaining the empirical frequencies for each quantile interval.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L22-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.extract_mean_and_variance-Union{Tuple{Array{Distributions.Normal{T}, 1}}, Tuple{T}} where T&lt;:AbstractFloat" href="#LaplaceRedux.extract_mean_and_variance-Union{Tuple{Array{Distributions.Normal{T}, 1}}, Tuple{T}} where T&lt;:AbstractFloat"><code>LaplaceRedux.extract_mean_and_variance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">extract_mean_and_variance(distr::Vector{Normal{&lt;: AbstractFloat}})</code></pre><p>Extract the mean and the variance of each distributions and return them in two separate lists.</p><p>Inputs: - <code>distributions</code>: a Vector of Normal distributions </p><p>Outputs: - <code>means</code>: the list of the means - <code>variances</code>:  the list of the variances </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L145-L153">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, Any}" href="#LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, Any}"><code>LaplaceRedux.fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit!(la::AbstractLaplace,data)</code></pre><p>Fits the Laplace approximation for a data set. The function returns the number of observations (n_data) that were used to update the Laplace object. It does not return the updated Laplace object itself because the function modifies the input Laplace object in place (as denoted by the use of &#39;!&#39; in the function&#39;s name).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">using Flux, LaplaceRedux
x, y = LaplaceRedux.Data.toy_data_linear()
data = zip(x,y)
nn = Chain(Dense(2,1))
la = Laplace(nn)
fit!(la, data)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/fitting.jl#L13-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, MLUtils.DataLoader}" href="#LaplaceRedux.fit!-Tuple{LaplaceRedux.AbstractLaplace, MLUtils.DataLoader}"><code>LaplaceRedux.fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Fit the Laplace approximation, with batched data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/fitting.jl#L43-L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.glm_predictive_distribution-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}" href="#LaplaceRedux.glm_predictive_distribution-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}"><code>LaplaceRedux.glm_predictive_distribution</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">glm_predictive_distribution(la::AbstractLaplace, X::AbstractArray)</code></pre><p>Computes the linearized GLM predictive from neural network with a Laplace approximation to the posterior <span>$p(\theta|\mathcal{D})=\mathcal{N}(\hat\theta,\Sigma)$</span>.  This is the distribution on network outputs given by <span>$p(f(x)|x,\mathcal{D})\approx \mathcal{N}(f(x;\hat\theta),{\mathbf{J}_{\hat\theta}}^\intercal\Sigma\mathbf{J}_{\hat\theta})$</span>.  For the Bayesian predictive distribution, see <a href="#LaplaceRedux.predict-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}"><code>predict</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>la::AbstractLaplace</code>: A Laplace object.</li><li><code>X::AbstractArray</code>: Input data.</li></ul><p><strong>Returns</strong></p><ul><li><code>normal_distr</code> A normal distribution N(fμ,fvar) approximating the predictive distribution p(y|X) given the input data X.- <code>normal_distr</code> A normal distribution N(fμ,fvar) approximating the predictive distribution p(y|X) given the input data X.</li><li><code>fμ::AbstractArray</code>: Mean of the predictive distribution. The output shape is column-major as in Flux.</li><li><code>fvar::AbstractArray</code>: Variance of the predictive distribution. The output shape is column-major as in Flux.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Flux, LaplaceRedux
using LaplaceRedux.Data: toy_data_linear
x, y = toy_data_linear()
data = zip(x,y)
nn = Chain(Dense(2,1))
la = Laplace(nn; likelihood=:classification)
fit!(la, data)
glm_predictive_distribution(la, hcat(x...))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L37-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.optimize_prior!-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.optimize_prior!-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.optimize_prior!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">optimize_prior!(
    la::AbstractLaplace; 
    n_steps::Int=100, lr::Real=1e-1,
    λinit::Union{Nothing,Real}=nothing,
    σinit::Union{Nothing,Real}=nothing
)</code></pre><p>Optimize the prior precision post-hoc through Empirical Bayes (marginal log-likelihood maximization).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/optimize_prior.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.posterior_covariance" href="#LaplaceRedux.posterior_covariance"><code>LaplaceRedux.posterior_covariance</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posterior_covariance(la::AbstractLaplace, P=la.P)</code></pre><p>Computes the posterior covariance <span>$∑$</span> as the inverse of the posterior precision: <span>$\Sigma=P^{-1}$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L55-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.posterior_precision" href="#LaplaceRedux.posterior_precision"><code>LaplaceRedux.posterior_precision</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posterior_precision(la::AbstractLaplace, H=la.posterior.H, P₀=la.prior.P₀)</code></pre><p>Computes the posterior precision <span>$P$</span> for a fitted Laplace Approximation as follows,</p><p><span>$P = \sum_{n=1}^N\nabla_{\theta}^2 \log p(\mathcal{D}_n|\theta)|_{\hat\theta} + \nabla_{\theta}^2 \log p(\theta)|_{\hat\theta}$</span></p><p>where <span>$\sum_{n=1}^N\nabla_{\theta}^2\log p(\mathcal{D}_n|\theta)|_{\hat\theta}=H$</span> is the Hessian and <span>$\nabla_{\theta}^2 \log p(\theta)|_{\hat\theta}=P_0$</span> is the prior precision and <span>$\hat\theta$</span> is the MAP estimate.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L41-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.predict-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}" href="#LaplaceRedux.predict-Tuple{LaplaceRedux.AbstractLaplace, AbstractArray}"><code>LaplaceRedux.predict</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">predict(
    la::AbstractLaplace,
    X::AbstractArray;
    link_approx=:probit,
    predict_proba::Bool=true,
    ret_distr::Bool=false,
)</code></pre><p>Computes the Bayesian predictivie distribution from a neural network with a Laplace approximation to the posterior <span>$p(\theta | \mathcal{D}) = \mathcal{N}(\hat\theta, \Sigma)$</span>.</p><p><strong>Arguments</strong></p><ul><li><code>la::AbstractLaplace</code>: A Laplace object.</li><li><code>X::AbstractArray</code>: Input data.</li><li><code>link_approx::Symbol=:probit</code>: Link function approximation. Options are <code>:probit</code> and <code>:plugin</code>.</li><li><code>predict_proba::Bool=true</code>: If <code>true</code> (default) apply a sigmoid or a softmax function to the output of the Flux model.</li><li><code>return_distr::Bool=false</code>: if <code>false</code> (default), the function outputs either the direct output of the chain or pseudo-probabilities (if <code>predict_proba=true</code>).   if <code>true</code> predict returns a probability distribution.</li></ul><p><strong>Returns</strong></p><p>For classification tasks:</p><ol><li>If <code>ret_distr</code> is <code>false</code>, <code>predict</code> returns <code>fμ</code>, i.e. the mean of the predictive distribution, which corresponds to the MAP estimate if the link function is set to <code>:plugin</code>, otherwise the probit approximation. The output shape is column-major as in Flux.</li><li>If <code>ret_distr</code> is <code>true</code>, <code>predict</code> returns a Bernoulli distribution in binary classification tasks and a categorical distribution in multiclassification tasks.</li></ol><p>For regression tasks:</p><ol><li>If <code>ret_distr</code> is <code>false</code>, <code>predict</code> returns the mean and the variance of the predictive distribution. The output shape is column-major as in Flux.</li><li>If <code>ret_distr</code> is <code>true</code>, <code>predict</code> returns the predictive posterior distribution, namely:</li></ol><p><span>$p(y|x,\mathcal{D})\approx \mathcal{N}(f(x;\hat\theta),{\mathbf{J}_{\hat\theta}}^\intercal\Sigma\mathbf{J}_{\hat\theta} + \sigma^2 \mathbf{I})$</span></p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Flux, LaplaceRedux
using LaplaceRedux.Data: toy_data_linear
x, y = toy_data_linear()
data = zip(x,y)
nn = Chain(Dense(2,1))
la = Laplace(nn; likelihood=:classification)
fit!(la, data)
predict(la, hcat(x...))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L78-L124">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.rescale_stddev-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, T}} where T&lt;:AbstractFloat" href="#LaplaceRedux.rescale_stddev-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, T}} where T&lt;:AbstractFloat"><code>LaplaceRedux.rescale_stddev</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">rescale_stddev(distr::Vector{Normal{T}}, s::T) where {T&lt;:AbstractFloat}</code></pre><p>Rescale the standard deviation of the Normal distributions received as argument and return a vector of rescaled Normal distributions. Inputs: <br/>    - <code>distr</code>: a Vector of Normal distributions      - <code>s</code>: a scale factor of type T.</p><p>Outputs: <br/>    - <code>Vector{Normal{T}}</code>: a Vector of rescaled Normal distributions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L189-L198">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.sharpness_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}" href="#LaplaceRedux.sharpness_classification-Tuple{Any, Vector{Distributions.Bernoulli{Float64}}}"><code>LaplaceRedux.sharpness_classification</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sharpness_classification(y_binary,distributions::Distributions.Bernoulli)</code></pre><p>dispatched for Bernoulli Distributions FOR BINARY CLASSIFICATION MODELS.  <br/>Assess  the sharpness of the model by looking at the distribution of model predictions.   When forecasts are sharp, most predictions are close to either 0 or 1   <br/>Source: <a href="https://arxiv.org/abs/1807.00263">Kuleshov, Fenner, Ermon 2018</a></p><p>Inputs:  <br/>    - <code>y_binary</code>: the array of outputs  <span>$y_t$</span>  numerically coded: 1 for the target class, 0 for the negative result.  <br/>    - <code>distributions</code>: an array of Bernoulli distributions describing the probability of of the output belonging to the target class <br/> Outputs:  <br/>    -  <code>mean_class_one</code>: a scalar that measure the average prediction for the target class  <br/>    -  <code>mean_class_zero</code>: a scalar that measure the average prediction for the null class  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L62-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.sharpness_regression-Tuple{Vector{Distributions.Normal{Float64}}}" href="#LaplaceRedux.sharpness_regression-Tuple{Vector{Distributions.Normal{Float64}}}"><code>LaplaceRedux.sharpness_regression</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sharpness_regression(distributions::Distributions.Normal)</code></pre><p>Dispatched version for Normal distributions FOR REGRESSION MODELS.  <br/>Given a calibration dataset <span>$(x_t, y_t)$</span> for <span>$i ∈ {1,...,T}$</span> and an array of predicted distributions, the function calculates the  sharpness of the predicted distributions, i.e., the average of the variances <span>$\sigma^2(F_t)$</span> predicted by the forecaster for each <span>$x_t$</span>. <br/>source: <a href="https://arxiv.org/abs/1807.00263">Kuleshov, Fenner, Ermon 2018</a></p><p>Inputs: <br/>    - <code>distributions</code>: an array of normal distributions <span>$F(x_t)$</span> stacked row-wise. <br/>Outputs: <br/>    - <code>sharpness</code>: a scalar that measure the level of sharpness of the regressor</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L4-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.sigma_scaling-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, Vector{&lt;:AbstractFloat}}} where T&lt;:AbstractFloat" href="#LaplaceRedux.sigma_scaling-Union{Tuple{T}, Tuple{Array{Distributions.Normal{T}, 1}, Vector{&lt;:AbstractFloat}}} where T&lt;:AbstractFloat"><code>LaplaceRedux.sigma_scaling</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sigma_scaling(distr::Vector{Normal{T}}, y_cal::Vector{&lt;:AbstractFloat}) where T &lt;: AbstractFloat</code></pre><p>Compute the value of  Σ that maximize the conditional log-likelihood:</p><p class="math-container">\[ m ln(Σ) +1/2 * Σ^{-2} ∑_{i=1}^{i=m} || y_cal_i -   ̄y_mean_i ||^2 / σ^2_i \]</p><p>where m is the number of elements in the calibration set (x<em>cal,y</em>cal). <br/>Source: <a href="https://proceedings.mlr.press/v121/laves20a.html">Laves,Ihler,Fast, Kahrs, Ortmaier,2020</a> Inputs: <br/>    - <code>distr</code>: a Vector of Normal distributions <br/>    - <code>y_cal</code>: a Vector of true results.</p><p>Outputs: <br/>    - <code>sigma</code>: the scalar that maximize the likelihood.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/calibration_functions.jl#L163-L179">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.predict-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}" href="#MLJModelInterface.predict-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}"><code>MLJModelInterface.predict</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>function MMI.predict(m::LaplaceRegressor, fitresult, Xnew)</p><p>Predicts the response for new data using a fitted Laplace  model.</p><p><strong>Arguments</strong></p><ul><li><code>m::LaplaceRegressor</code>: The Laplace  model.</li><li><code>fitresult</code>: The result of the fitting procedure.</li><li><code>Xnew</code>: The new data for which predictions are to be made.</li></ul><p><strong>Returns</strong></p><pre><code class="nohighlight hljs">for LaplaceRegressor:
- An array of Normal distributions, each centered around the predicted mean and variance for the corresponding input in `Xnew`.
for LaplaceClassifier:
- `MLJBase.UnivariateFinite`: The predicted class probabilities for the new data.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L496-L512">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.CurvatureInterface" href="#LaplaceRedux.Curvature.CurvatureInterface"><code>LaplaceRedux.Curvature.CurvatureInterface</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Base type for any curvature interface.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/Curvature.jl#L12">source</a></section></article><h2 id="Internal-functions"><a class="docs-heading-anchor" href="#Internal-functions">Internal functions</a><a id="Internal-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Internal-functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.AbstractDecomposition" href="#LaplaceRedux.AbstractDecomposition"><code>LaplaceRedux.AbstractDecomposition</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Abstract type of Hessian decompositions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.AbstractLaplace" href="#LaplaceRedux.AbstractLaplace"><code>LaplaceRedux.AbstractLaplace</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Abstract base type for all Laplace approximations in this library. All subclasses implemented are parametric.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.AbstractLaplace-Tuple{AbstractArray}" href="#LaplaceRedux.AbstractLaplace-Tuple{AbstractArray}"><code>LaplaceRedux.AbstractLaplace</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">(la::AbstractLaplace)(X::AbstractArray)</code></pre><p>Calling a model with Laplace Approximation on an array of inputs is equivalent to explicitly calling the <code>predict</code> function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L216-L220">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.EstimationParams" href="#LaplaceRedux.EstimationParams"><code>LaplaceRedux.EstimationParams</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">EstimationParams</code></pre><p>Container for the parameters of a Laplace approximation. </p><p><strong>Fields</strong></p><ul><li><code>subset_of_weights::Symbol</code>: the subset of weights to consider. Possible values are <code>:all</code>, <code>:last_layer</code>, and <code>:subnetwork</code>.</li><li><code>subnetwork_indices::Union{Nothing,Vector{Vector{Int}}}</code>: the indices of the subnetwork. Possible values are <code>nothing</code> or a vector of vectors of integers.</li><li><code>hessian_structure::HessianStructure</code>: the structure of the Hessian. Possible values are <code>:full</code> and <code>:kron</code> or a concrete subtype of <code>HessianStructure</code>.</li><li><code>curvature::Union{Curvature.CurvatureInterface,Nothing}</code>: the curvature interface. Possible values are <code>nothing</code> or a concrete subtype of <code>CurvatureInterface</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.EstimationParams-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}" href="#LaplaceRedux.EstimationParams-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}"><code>LaplaceRedux.EstimationParams</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">EstimationParams(params::LaplaceParams)</code></pre><p>Extracts the estimation parameters from a <code>LaplaceParams</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.FullHessian" href="#LaplaceRedux.FullHessian"><code>LaplaceRedux.FullHessian</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Concrete type for full Hessian structure. This is the default structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.HessianStructure" href="#LaplaceRedux.HessianStructure"><code>LaplaceRedux.HessianStructure</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Abstract type for Hessian structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Kron" href="#LaplaceRedux.Kron"><code>LaplaceRedux.Kron</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Kronecker-factored approximate curvature representation for a neural network model. Each element in kfacs represents two Kronecker factors (𝐆, 𝐀), such that the full block Hessian approximation would be approximated as 𝐀⊗𝐆.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L16-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.KronDecomposed" href="#LaplaceRedux.KronDecomposed"><code>LaplaceRedux.KronDecomposed</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">KronDecomposed</code></pre><p>Decomposed Kronecker-factored approximate curvature representation for a neural network model.</p><p>Decomposition is required to add the prior (diagonal matrix) to the posterior (<code>KronDecomposed</code>). It also has the benefits of reducing the costs for computation of inverses and log-determinants.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L67-L74">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.KronHessian" href="#LaplaceRedux.KronHessian"><code>LaplaceRedux.KronHessian</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Concrete type for Kronecker-factored Hessian structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/kron.jl#L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.LaplaceParams" href="#LaplaceRedux.LaplaceParams"><code>LaplaceRedux.LaplaceParams</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LaplaceParams</code></pre><p>Container for the parameters of a Laplace approximation.</p><p><strong>Fields</strong></p><ul><li><code>subset_of_weights::Symbol</code>: the subset of weights to consider. Possible values are <code>:all</code>, <code>:last_layer</code>, and <code>:subnetwork</code>.</li><li><code>subnetwork_indices::Union{Nothing,Vector{Vector{Int}}}</code>: the indices of the subnetwork. Possible values are <code>nothing</code> or a vector of vectors of integers.</li><li><code>hessian_structure::HessianStructure</code>: the structure of the Hessian. Possible values are <code>:full</code> and <code>:kron</code> or a concrete subtype of <code>HessianStructure</code>.</li><li><code>backend::Symbol</code>: the backend to use. Possible values are <code>:GGN</code> and <code>:Fisher</code>.</li><li><code>curvature::Union{Curvature.CurvatureInterface,Nothing}</code>: the curvature interface. Possible values are <code>nothing</code> or a concrete subtype of <code>CurvatureInterface</code>.</li><li><code>σ::Real</code>: the observation noise</li><li><code>μ₀::Real</code>: the prior mean</li><li><code>λ::Real</code>: the prior precision</li><li><code>P₀::Union{Nothing,AbstractMatrix,UniformScaling}</code>: the prior precision matrix</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/core_struct.jl#L17-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Posterior" href="#LaplaceRedux.Posterior"><code>LaplaceRedux.Posterior</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Posterior</code></pre><p>Container for the results of a Laplace approximation.</p><p><strong>Fields</strong></p><ul><li><code>μ::AbstractVector</code>: the MAP estimate of the parameters</li><li><code>H::Union{AbstractArray,AbstractDecomposition,Nothing}</code>: the Hessian matrix</li><li><code>P::Union{AbstractArray,AbstractDecomposition,Nothing}</code>: the posterior precision matrix</li><li><code>Σ::Union{AbstractArray,Nothing}</code>: the posterior covariance matrix</li><li><code>n_data::Union{Int,Nothing}</code>: the number of data points</li><li><code>n_params::Union{Int,Nothing}</code>: the number of parameters</li><li><code>n_out::Union{Int,Nothing}</code>: the number of outputs</li><li><code>loss::Real</code>: the loss value</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/posterior.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Posterior-Tuple{Any, LaplaceRedux.EstimationParams}" href="#LaplaceRedux.Posterior-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.Posterior</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Posterior(model::Any, est_params::EstimationParams)</code></pre><p>Outer constructor for <code>Posterior</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/posterior.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Prior" href="#LaplaceRedux.Prior"><code>LaplaceRedux.Prior</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Prior</code></pre><p>Container for the prior parameters of a Laplace approximation.</p><p><strong>Fields</strong></p><ul><li><code>σ::Real</code>: the observation noise</li><li><code>μ₀::Real</code>: the prior mean</li><li><code>λ::Real</code>: the prior precision</li><li><code>P₀::Union{Nothing,AbstractMatrix,UniformScaling}</code>: the prior precision matrix</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/prior.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Prior-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}" href="#LaplaceRedux.Prior-Tuple{LaplaceRedux.LaplaceParams, Any, Symbol}"><code>LaplaceRedux.Prior</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Prior(params::LaplaceParams)</code></pre><p>Extracts the prior parameters from a <code>LaplaceParams</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/prior.jl#L20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:*-Tuple{LaplaceRedux.KronDecomposed, Number}" href="#Base.:*-Tuple{LaplaceRedux.KronDecomposed, Number}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Multiply by a scalar by changing the eigenvalues. Distribute the scalar along the factors of a block.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L117-L119">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:*-Tuple{Real, LaplaceRedux.Kron}" href="#Base.:*-Tuple{Real, LaplaceRedux.Kron}"><code>Base.:*</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Kronecker-factored curvature scalar scaling.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L42-L44">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:+-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}" href="#Base.:+-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}"><code>Base.:+</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Kronecker-factored curvature sum.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L24-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:+-Tuple{LaplaceRedux.KronDecomposed, LinearAlgebra.Diagonal}" href="#Base.:+-Tuple{LaplaceRedux.KronDecomposed, LinearAlgebra.Diagonal}"><code>Base.:+</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Shift the factors by a diagonal (assumed uniform scaling)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L110-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:+-Tuple{LaplaceRedux.KronDecomposed, Number}" href="#Base.:+-Tuple{LaplaceRedux.KronDecomposed, Number}"><code>Base.:+</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Shift the factors by a scalar across the diagonal.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L103-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.:==-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}" href="#Base.:==-Tuple{LaplaceRedux.Kron, LaplaceRedux.Kron}"><code>Base.:==</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Kronecker-factored curvature equality.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L35-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.getindex-Tuple{LaplaceRedux.Kron, Int64}" href="#Base.getindex-Tuple{LaplaceRedux.Kron, Int64}"><code>Base.getindex</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Get Kronecker-factored block represenation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L53-L55">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.getindex-Tuple{LaplaceRedux.KronDecomposed, Int64}" href="#Base.getindex-Tuple{LaplaceRedux.KronDecomposed, Int64}"><code>Base.getindex</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Get i-th block of a a Kronecker-factored curvature.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L138-L140">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.length-Tuple{LaplaceRedux.KronDecomposed}" href="#Base.length-Tuple{LaplaceRedux.KronDecomposed}"><code>Base.length</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Number of blocks in a Kronecker-factored curvature.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L131-L133">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Flux.params-Tuple{Any, LaplaceRedux.EstimationParams}" href="#Flux.params-Tuple{Any, LaplaceRedux.EstimationParams}"><code>Flux.params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Flux.params(model::Any, params::EstimationParams)</code></pre><p>Extracts the parameters of a model based on the subset of weights specified in the <code>EstimationParams</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Flux.params-Tuple{Laplace}" href="#Flux.params-Tuple{Laplace}"><code>Flux.params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Flux.params(la::Laplace)</code></pre><p>Overloads the <code>params</code> function for a <code>Laplace</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux._H_factor-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux._H_factor-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._H_factor</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">_H_factor(la::AbstractLaplace)</code></pre><p>Returns the factor σ⁻², where σ is used in the zero-centered Gaussian prior p(θ) = N(θ;0,σ²I)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L80-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.FullHessian, Any}" href="#LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.FullHessian, Any}"><code>LaplaceRedux._fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">_fit!(la::Laplace, hessian_structure::FullHessian, data; batched::Bool=false, batchsize::Int, override::Bool=true)</code></pre><p>Fit a Laplace approximation to the posterior distribution of a model using the full Hessian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/full.jl#L19-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.KronHessian, Any}" href="#LaplaceRedux._fit!-Tuple{Laplace, LaplaceRedux.KronHessian, Any}"><code>LaplaceRedux._fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">_fit!(la::Laplace, hessian_structure::KronHessian, data; batched::Bool=false, batchsize::Int, override::Bool=true)</code></pre><p>Fit a Laplace approximation to the posterior distribution of a model using the Kronecker-factored Hessian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/kron.jl#L102-L106">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux._init_H-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux._init_H-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._init_H</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">_init_H(la::AbstractLaplace)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L87-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux._weight_penalty-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux._weight_penalty-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux._weight_penalty</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">_weight_penalty(la::AbstractLaplace)</code></pre><p>The weight penalty term is a regularization term used to prevent overfitting. Weight regularization methods such as weight decay introduce a penalty to the loss function when training a neural network to encourage the network to use small weights. Smaller weights in a neural network can result in a model that is more stable and less likely to overfit the training dataset, in turn having better performance when  making a prediction on new data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L94-L101">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.FullHessian, Tuple}" href="#LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.FullHessian, Tuple}"><code>LaplaceRedux.approximate</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">approximate(curvature::CurvatureInterface, hessian_structure::FullHessian, d::Tuple; batched::Bool=false)</code></pre><p>Compute the full approximation, for either a single input-output datapoint or a batch of such. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/full.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.KronHessian, Any}" href="#LaplaceRedux.approximate-Tuple{LaplaceRedux.Curvature.CurvatureInterface, LaplaceRedux.KronHessian, Any}"><code>LaplaceRedux.approximate</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">approximate(curvature::CurvatureInterface, hessian_structure::KronHessian, data; batched::Bool=false)</code></pre><p>Compute the eigendecomposed Kronecker-factored approximate curvature as the Fisher information matrix.</p><p>Note, since the network predictive distribution is used in a weighted sum, and the number of backward passes is linear in the number of target classes, e.g. 100 for CIFAR-100.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/kron.jl#L6-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.clamp-Tuple{LinearAlgebra.Eigen}" href="#LaplaceRedux.clamp-Tuple{LinearAlgebra.Eigen}"><code>LaplaceRedux.clamp</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Clamp eigenvalues in an eigendecomposition to be non-negative.</p><p>Since the Fisher information matrix is a positive-semidefinite by construction, the (near-zero) negative eigenvalues should be neglected.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L83-L88">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.convert_subnetwork_indices-Tuple{Vector{Vector{Int64}}, AbstractArray}" href="#LaplaceRedux.convert_subnetwork_indices-Tuple{Vector{Vector{Int64}}, AbstractArray}"><code>LaplaceRedux.convert_subnetwork_indices</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>convert<em>subnetwork</em>indices(subnetwork_indices::AbstractArray)</p><p>Converts the subnetwork indices from the user given format [theta, row, column] to an Int i that corresponds to the index of that weight in the flattened array of weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/subnet.jl#L30-L35">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.dataset_shape-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}" href="#LaplaceRedux.dataset_shape-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any}"><code>LaplaceRedux.dataset_shape</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">function dataset_shape(model::LaplaceRegression, X, y)</code></pre><p>Compute the the number of features of the X input dataset and  the number of variables to predict from  the y  output dataset.</p><p><strong>Arguments</strong></p><ul><li><code>model::LaplaceModels</code>: The Laplace  model to fit.</li><li><code>X</code>: The input data for training.</li><li><code>y</code>: The target labels for training one-hot encoded.</li></ul><p><strong>Returns</strong></p><ul><li>(input size, output size)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L69-L81">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.decompose-Tuple{LaplaceRedux.Kron}" href="#LaplaceRedux.decompose-Tuple{LaplaceRedux.Kron}"><code>LaplaceRedux.decompose</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">decompose(K::Kron)</code></pre><p>Eigendecompose Kronecker factors and turn into <code>KronDecomposed</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L93-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.default_build-Tuple{Int64, Any}" href="#LaplaceRedux.default_build-Tuple{Int64, Any}"><code>LaplaceRedux.default_build</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">default_build( seed::Int, shape)</code></pre><p>Builds a default MLP Flux model compatible with the dimensions of the dataset, with reproducible initial weights.</p><p><strong>Arguments</strong></p><ul><li><code>seed::Int</code>: The seed for random number generation.</li><li><code>shape</code>: a tuple containing the dimensions of the input layer and the output layer.</li></ul><p><strong>Returns</strong></p><ul><li>The constructed Flux model, which consist in a simple MLP with 2 hidden layers with 20 neurons each and an input and output layers compatible with the dataset.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L94-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.functional_variance-Tuple{Any, Any}" href="#LaplaceRedux.functional_variance-Tuple{Any, Any}"><code>LaplaceRedux.functional_variance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">functional_variance(la::AbstractLaplace, 𝐉::AbstractArray)</code></pre><p>Computes the functional variance for the GLM predictive as <code>map(j -&gt; (j&#39; * Σ * j), eachrow(𝐉))</code> which is a (output x output) predictive covariance matrix. Formally, we have <span>${\mathbf{J}_{\hat\theta}}^\intercal\Sigma\mathbf{J}_{\hat\theta}$</span> where <span>$\mathbf{J}_{\hat\theta}=\nabla_{\theta}f(x;\theta)|\hat\theta$</span> is the Jacobian evaluated at the MAP estimate.</p><p>Dispatches to the appropriate method based on the Hessian structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L26-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.FullHessian, Any}" href="#LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.FullHessian, Any}"><code>LaplaceRedux.functional_variance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>functional<em>variance(la::Laplace, hessian</em>structure::FullHessian, 𝐉)</p><p>Computes the functional variance for the GLM predictive as <code>map(j -&gt; (j&#39; * Σ * j), eachrow(𝐉))</code> which is a (output x output) predictive covariance matrix. Formally, we have <span>${\mathbf{J}_{\hat\theta}}^\intercal\Sigma\mathbf{J}_{\hat\theta}$</span> where <span>$\mathbf{J}_{\hat\theta}=\nabla_{\theta}f(x;\theta)|\hat\theta$</span> is the Jacobian evaluated at the MAP estimate.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/full.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.KronHessian, Matrix}" href="#LaplaceRedux.functional_variance-Tuple{Laplace, LaplaceRedux.KronHessian, Matrix}"><code>LaplaceRedux.functional_variance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">functional_variance(la::Laplace, hessian_structure::KronHessian, 𝐉::Matrix)</code></pre><p>Compute functional variance for the GLM predictive: as the diagonal of the K×K predictive output covariance matrix 𝐉𝐏⁻¹𝐉ᵀ, where K is the number of outputs, 𝐏 is the posterior precision, and 𝐉 is the Jacobian of model output <code>𝐉=∇f(x;θ)|θ̂</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/kron.jl#L135-L140">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.get_loss_fun-Tuple{Symbol, Flux.Chain}" href="#LaplaceRedux.get_loss_fun-Tuple{Symbol, Flux.Chain}"><code>LaplaceRedux.get_loss_fun</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_loss_fun(likelihood::Symbol)</code></pre><p>Helper function to choose loss function based on specified model <code>likelihood</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/utils.jl#L4-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.get_loss_type-Tuple{Symbol, Flux.Chain}" href="#LaplaceRedux.get_loss_type-Tuple{Symbol, Flux.Chain}"><code>LaplaceRedux.get_loss_type</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_loss_type(likelihood::Symbol)</code></pre><p>Choose loss function type based on specified model <code>likelihood</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/utils.jl#L16-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.get_map_estimate-Tuple{Any, LaplaceRedux.EstimationParams}" href="#LaplaceRedux.get_map_estimate-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.get_map_estimate</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_map_estimate(model::Any, est_params::EstimationParams)</code></pre><p>Helper function to extract the MAP estimate of the parameters for the model based on the subset of weights specified in the <code>EstimationParams</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L87-L91">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.get_prior_mean-Tuple{Laplace}" href="#LaplaceRedux.get_prior_mean-Tuple{Laplace}"><code>LaplaceRedux.get_prior_mean</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_prior_mean(la::Laplace)</code></pre><p>Helper function to extract the prior mean of the parameters from a Laplace approximation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L15-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.has_softmax_or_sigmoid_final_layer-Tuple{Flux.Chain}" href="#LaplaceRedux.has_softmax_or_sigmoid_final_layer-Tuple{Flux.Chain}"><code>LaplaceRedux.has_softmax_or_sigmoid_final_layer</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">has_softmax_or_sigmoid_final_layer(model::Flux.Chain)</code></pre><p>Check if the FLux model ends with a sigmoid or with a softmax layer</p><p>Input:     - <code>model</code>: the Flux Chain object that represent the neural network. Return:     - <code>has_finaliser</code>: true if the check is positive, false otherwise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L5-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.hessian_approximation-Tuple{LaplaceRedux.AbstractLaplace, Any}" href="#LaplaceRedux.hessian_approximation-Tuple{LaplaceRedux.AbstractLaplace, Any}"><code>LaplaceRedux.hessian_approximation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hessian_approximation(la::AbstractLaplace, d; batched::Bool=false)</code></pre><p>Computes the local Hessian approximation at a single datapoint <code>d</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/fitting.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.instantiate_curvature!-Tuple{LaplaceRedux.EstimationParams, Any, Symbol, Symbol}" href="#LaplaceRedux.instantiate_curvature!-Tuple{LaplaceRedux.EstimationParams, Any, Symbol, Symbol}"><code>LaplaceRedux.instantiate_curvature!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">instantiate_curvature!(params::EstimationParams, model::Any, likelihood::Symbol, backend::Symbol)</code></pre><p>Instantiates the curvature interface for a Laplace approximation. The curvature interface is a concrete subtype of <a href="#LaplaceRedux.Curvature.CurvatureInterface"><code>CurvatureInterface</code></a> and is used to compute the Hessian matrix. The curvature interface is stored in the <code>curvature</code> field of the <code>EstimationParams</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L97-L101">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.interleave-Tuple" href="#LaplaceRedux.interleave-Tuple"><code>LaplaceRedux.interleave</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Interleave elements of multiple iterables in order provided.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L60-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.inv_square_form-Tuple{LaplaceRedux.KronDecomposed, Matrix}" href="#LaplaceRedux.inv_square_form-Tuple{LaplaceRedux.KronDecomposed, Matrix}"><code>LaplaceRedux.inv_square_form</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>function inv<em>square</em>form(K::KronDecomposed, W::Matrix)</p><p>Special function to compute the inverse square form 𝐉𝐏⁻¹𝐉ᵀ (or 𝐖𝐊⁻¹𝐖ᵀ)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/kron.jl#L145-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.log_det_posterior_precision-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.log_det_posterior_precision-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_posterior_precision</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">log_det_posterior_precision(la::AbstractLaplace)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L152-L156">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.log_det_prior_precision-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.log_det_prior_precision-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_prior_precision</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">log_det_prior_precision(la::AbstractLaplace)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L145-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.log_det_ratio-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.log_det_ratio-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_det_ratio</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">log_det_ratio(la::AbstractLaplace)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L136-L140">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.log_likelihood-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.log_likelihood-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_likelihood</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">log_likelihood(la::AbstractLaplace)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L65-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.log_marginal_likelihood-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.log_marginal_likelihood-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.log_marginal_likelihood</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">log_marginal_likelihood(la::AbstractLaplace; P₀::Union{Nothing,UniformScaling}=nothing, σ::Union{Nothing, Real}=nothing)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L110-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.logdetblock-Tuple{Tuple{LinearAlgebra.Eigen, LinearAlgebra.Eigen}, Number}" href="#LaplaceRedux.logdetblock-Tuple{Tuple{LinearAlgebra.Eigen, LinearAlgebra.Eigen}, Number}"><code>LaplaceRedux.logdetblock</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">logdetblock(block::Tuple{Eigen,Eigen}, delta::Number)</code></pre><p>Log-determinant of a block in KronDecomposed, shifted by delta by on the diagonal.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L149-L153">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.mm-Tuple{LaplaceRedux.KronDecomposed, Any}" href="#LaplaceRedux.mm-Tuple{LaplaceRedux.KronDecomposed, Any}"><code>LaplaceRedux.mm</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Matrix-multuply for the KronDecomposed Hessian approximation K and a 2-d matrix W, applying an exponent to K and transposing W before multiplication. Return <code>(K^x)W^T</code>, where <code>x</code> is the exponent.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L177-L181">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.n_params-Tuple{Any, LaplaceRedux.EstimationParams}" href="#LaplaceRedux.n_params-Tuple{Any, LaplaceRedux.EstimationParams}"><code>LaplaceRedux.n_params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">n_params(model::Any, params::EstimationParams)</code></pre><p>Helper function to determine the number of parameters of a <code>Flux.Chain</code> with Laplace approximation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/estimation_params.jl#L73-L77">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.n_params-Tuple{Laplace}" href="#LaplaceRedux.n_params-Tuple{Laplace}"><code>LaplaceRedux.n_params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LaplaceRedux.n_params(la::Laplace)</code></pre><p>Overloads the <code>n_params</code> function for a <code>Laplace</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L8-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.outdim-Tuple{Flux.Chain}" href="#LaplaceRedux.outdim-Tuple{Flux.Chain}"><code>LaplaceRedux.outdim</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">outdim(model::Chain)</code></pre><p>Helper function to determine the output dimension of a <code>Flux.Chain</code>, corresponding to the number of neurons on the last layer of the NN.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/utils.jl#L34-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.outdim-Tuple{LaplaceRedux.AbstractLaplace}" href="#LaplaceRedux.outdim-Tuple{LaplaceRedux.AbstractLaplace}"><code>LaplaceRedux.outdim</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">outdim(la::AbstractLaplace)</code></pre><p>Helper function to determine the output dimension, corresponding to the number of neurons  on the last layer of the NN, of a <code>Flux.Chain</code> with Laplace approximation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L33-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.prior_precision-Tuple{Laplace}" href="#LaplaceRedux.prior_precision-Tuple{Laplace}"><code>LaplaceRedux.prior_precision</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">prior_precision(la::Laplace)</code></pre><p>Helper function to extract the prior precision matrix from a Laplace approximation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/utils.jl#L24-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.probit-Tuple{AbstractArray, AbstractArray}" href="#LaplaceRedux.probit-Tuple{AbstractArray, AbstractArray}"><code>LaplaceRedux.probit</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">probit(fμ::AbstractArray, fvar::AbstractArray)</code></pre><p>Compute the probit approximation of the predictive distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/baselaplace/predicting.jl#L205-L209">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.validate_subnetwork_indices-Tuple{Union{Nothing, Vector{Vector{Int64}}}, Any}" href="#LaplaceRedux.validate_subnetwork_indices-Tuple{Union{Nothing, Vector{Vector{Int64}}}, Any}"><code>LaplaceRedux.validate_subnetwork_indices</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>validate<em>subnetwork</em>indices( subnetwork_indices::Union{Nothing,Vector{Vector{Int}}}, params )</p><p>Determines whether subnetwork_indices is a valid input for specified parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/subnet.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LinearAlgebra.det-Tuple{LaplaceRedux.KronDecomposed}" href="#LinearAlgebra.det-Tuple{LaplaceRedux.KronDecomposed}"><code>LinearAlgebra.det</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">det(K::KronDecomposed)</code></pre><p>Log-determinant of the KronDecomposed block-diagonal matrix, as the exponentiated log-determinant.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L168-L172">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LinearAlgebra.logdet-Tuple{LaplaceRedux.KronDecomposed}" href="#LinearAlgebra.logdet-Tuple{LaplaceRedux.KronDecomposed}"><code>LinearAlgebra.logdet</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">logdet(K::KronDecomposed)</code></pre><p>Log-determinant of the KronDecomposed block-diagonal matrix, as the product of the determinants of the blocks</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L159-L163">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.fit-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any, Any}" href="#MLJModelInterface.fit-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any, Any, Any}"><code>MLJModelInterface.fit</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MMI.fit(m::Union{LaplaceRegressor,LaplaceClassifier}, verbosity, X, y)</code></pre><p>Fit a Laplace model using the provided features and target values.</p><p><strong>Arguments</strong></p><ul><li><code>m::Laplace</code>: The Laplace (LaplaceRegressor or LaplaceClassifier) model to be fitted.</li><li><code>verbosity</code>: Verbosity level for logging.</li><li><code>X</code>: Input features, expected to be in a format compatible with MLJBase.matrix.</li><li><code>y</code>: Target values.</li></ul><p><strong>Returns</strong></p><ul><li><code>fitresult</code>: a tuple (la,decode) cointaing  the fitted Laplace model and y[1],the first element of the categorical y vector.</li><li><code>cache</code>: a tuple containing a deepcopy of the model, the current state of the optimiser and the training loss history.</li><li><code>report</code>: A Namedtuple containing the loss history of the fitting process.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L123-L138">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.fitted_params-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}" href="#MLJModelInterface.fitted_params-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}"><code>MLJModelInterface.fitted_params</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>function  MMI.fitted_params(model::LaplaceRegressor, fitresult)</p><p>This function extracts the fitted parameters from a <code>LaplaceRegressor</code> model.</p><p><strong>Arguments</strong></p><ul><li><code>model::LaplaceRegressor</code>: The Laplace regression model.</li><li><code>fitresult</code>:  the Laplace approximation (<code>la</code>).</li></ul><p><strong>Returns</strong></p><p>A named tuple containing:</p><ul><li><code>μ</code>: The mean of the posterior distribution.</li><li><code>H</code>: The Hessian of the posterior distribution.</li><li><code>P</code>: The precision matrix of the posterior distribution.</li><li><code>Σ</code>: The covariance matrix of the posterior distribution.</li><li><code>n_data</code>: The number of data points.</li><li><code>n_params</code>: The number of parameters.</li><li><code>n_out</code>: The number of outputs.</li><li><code>loss</code>: The loss value of the posterior distribution.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L442-L465">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.is_same_except-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Symbol}}" href="#MLJModelInterface.is_same_except-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Symbol}}"><code>MLJModelInterface.is_same_except</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">function MMI.is_same_except(m1::LaplaceModels, m2::LaplaceModels, exceptions::Symbol...)</code></pre><p>If both <code>m1</code> and <code>m2</code> are of <code>MLJType</code>, return <code>true</code> if the following conditions all hold, and <code>false</code> otherwise:</p><ul><li><p><code>typeof(m1) === typeof(m2)</code></p></li><li><p><code>propertynames(m1) === propertynames(m2)</code></p></li><li><p>with the exception of properties listed as <code>exceptions</code> or bound to an <code>AbstractRNG</code>, each pair of corresponding property values is either &quot;equal&quot; or both undefined. (If a property appears as a <code>propertyname</code> but not a <code>fieldname</code>, it is deemed as always defined.)</p></li></ul><p>The meaining of &quot;equal&quot; depends on the type of the property value:</p><ul><li><p>values that are themselves of <code>MLJType</code> are &quot;equal&quot; if they are equal in the sense of <code>is_same_except</code> with no exceptions.</p></li><li><p>values that are not of <code>MLJType</code> are &quot;equal&quot; if they are <code>==</code>.</p></li></ul><p>In the special case of a &quot;deep&quot; property, &quot;equal&quot; has a different meaning; see <code>MLJBase.deep_properties</code> for details.</p><p>If <code>m1</code> or <code>m2</code> are not <code>MLJType</code> objects, then return <code>==(m1, m2)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L353-L380">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.training_losses-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}" href="#MLJModelInterface.training_losses-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Any}"><code>MLJModelInterface.training_losses</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MMI.training_losses(model::Union{LaplaceRegressor,LaplaceClassifier}, report)</code></pre><p>Retrieve the training loss history from the given <code>report</code>.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: The model for which the training losses are being retrieved.</li><li><code>report</code>: An object containing the training report, which includes the loss history.</li></ul><p><strong>Returns</strong></p><ul><li>A collection representing the loss history from the training report.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L480-L491">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJModelInterface.update-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Any, 5}}" href="#MLJModelInterface.update-Tuple{Union{LaplaceClassifier, LaplaceRegressor}, Vararg{Any, 5}}"><code>MLJModelInterface.update</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MMI.update(m::Union{LaplaceRegressor,LaplaceClassifier}, verbosity, X, y)</code></pre><p>Update the Laplace model using the provided new data points.</p><p><strong>Arguments</strong></p><ul><li><code>m</code>: The Laplace (LaplaceRegressor or LaplaceClassifier) model to be fitted.</li><li><code>verbosity</code>: Verbosity level for logging.</li><li><code>X</code>: New input features, expected to be in a format compatible with MLJBase.matrix.</li><li><code>y</code>: New target values.</li></ul><p><strong>Returns</strong></p><ul><li><code>fitresult</code>: a tuple (la,decode) cointaing  the updated fitted Laplace model and y[1],the first element of the categorical y vector.</li><li><code>cache</code>: a tuple containing a deepcopy of the model, the updated current state of the optimiser and training loss history.</li><li><code>report</code>: A Namedtuple containing the complete loss history of the fitting process.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/direct_mlj.jl#L215-L230">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.@zb-Tuple{Any}" href="#LaplaceRedux.@zb-Tuple{Any}"><code>LaplaceRedux.@zb</code></a> — <span class="docstring-category">Macro</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Macro for zero-based indexing. Example of usage: (@zb A[0]) = ...</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/kronecker/utils.jl#L4-L6">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.EmpiricalFisher" href="#LaplaceRedux.Curvature.EmpiricalFisher"><code>LaplaceRedux.Curvature.EmpiricalFisher</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Constructor for curvature approximated by empirical Fisher.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/fisher.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.GGN" href="#LaplaceRedux.Curvature.GGN"><code>LaplaceRedux.Curvature.GGN</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Constructor for curvature approximated by Generalized Gauss-Newton.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/ggn.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}" href="#LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}"><code>LaplaceRedux.Curvature.full_batched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">full_batched(curvature::EmpiricalFisher, d::Tuple)</code></pre><p>Compute the full empirical Fisher for batch of inputs-outputs, with the batch dimension at the end.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/fisher.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}" href="#LaplaceRedux.Curvature.full_batched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}"><code>LaplaceRedux.Curvature.full_batched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">full_batched(curvature::GGN, d::Tuple)</code></pre><p>Compute the full GGN for batch of inputs-outputs, with the batch dimension at the end.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/ggn.jl#L52-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}" href="#LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.EmpiricalFisher, Tuple}"><code>LaplaceRedux.Curvature.full_unbatched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">full_unbatched(curvature::EmpiricalFisher, d::Tuple)</code></pre><p>Compute the full empirical Fisher for a single datapoint.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/fisher.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}" href="#LaplaceRedux.Curvature.full_unbatched-Tuple{LaplaceRedux.Curvature.GGN, Tuple}"><code>LaplaceRedux.Curvature.full_unbatched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">full_unbatched(curvature::GGN, d::Tuple)</code></pre><p>Compute the full GGN for a singular input-ouput datapoint. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/ggn.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.gradients-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray, Union{Number, AbstractArray}}" href="#LaplaceRedux.Curvature.gradients-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray, Union{Number, AbstractArray}}"><code>LaplaceRedux.Curvature.gradients</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">gradients(curvature::CurvatureInterface, X::AbstractArray, y::Number)</code></pre><p>Compute the gradients with respect to the loss function: <code>∇ℓ(f(x;θ),y)</code> where <code>f: ℝᴰ ↦ ℝᴷ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/utils.jl#L75-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.jacobians-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}" href="#LaplaceRedux.Curvature.jacobians-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">jacobians(curvature::CurvatureInterface, X::AbstractArray; batched::Bool=false)</code></pre><p>Computes the Jacobian <code>∇f(x;θ)</code> where <code>f: ℝᴰ ↦ ℝᴷ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/utils.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.jacobians_batched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}" href="#LaplaceRedux.Curvature.jacobians_batched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians_batched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">jacobians_batched(curvature::CurvatureInterface, X::AbstractArray)</code></pre><p>Compute Jacobians of the model output w.r.t. model parameters for points in X, with batching.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/utils.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Curvature.jacobians_unbatched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}" href="#LaplaceRedux.Curvature.jacobians_unbatched-Tuple{LaplaceRedux.Curvature.CurvatureInterface, AbstractArray}"><code>LaplaceRedux.Curvature.jacobians_unbatched</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">jacobians_unbatched(curvature::CurvatureInterface, X::AbstractArray)</code></pre><p>Compute the Jacobian of the model output w.r.t. model parameters for the point X, without batching. Here, the nn function is wrapped in an anonymous function using the () -&gt; syntax, which allows it to be differentiated using automatic differentiation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/curvature/utils.jl#L16-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Data.toy_data_linear" href="#LaplaceRedux.Data.toy_data_linear"><code>LaplaceRedux.Data.toy_data_linear</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">toy_data_linear(N=100)</code></pre><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">toy_data_linear()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/data/functions.jl#L3-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Data.toy_data_multi" href="#LaplaceRedux.Data.toy_data_multi"><code>LaplaceRedux.Data.toy_data_multi</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">toy_data_multi(N=100)</code></pre><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">toy_data_multi()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/data/functions.jl#L78-L87">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Data.toy_data_non_linear" href="#LaplaceRedux.Data.toy_data_non_linear"><code>LaplaceRedux.Data.toy_data_non_linear</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">toy_data_non_linear(N=100)</code></pre><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">toy_data_non_linear()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/data/functions.jl#L35-L44">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LaplaceRedux.Data.toy_data_regression" href="#LaplaceRedux.Data.toy_data_regression"><code>LaplaceRedux.Data.toy_data_regression</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">toy_data_regression(N=25, p=1; noise=0.3, fun::Function=f(x)=sin(2 * π * x))</code></pre><p>A helper function to generate synthetic data for regression.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl/blob/aae3ee38316118373f00378435cddac6c947357c/src/data/functions.jl#L121-L125">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorials/calibration/">« Calibrated forecasts</a><a class="docs-footer-nextpage" href="../mlj_interface/">MLJ interface »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 26 November 2024 14:01">Tuesday 26 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
