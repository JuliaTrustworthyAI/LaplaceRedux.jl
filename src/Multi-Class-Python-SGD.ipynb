{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91563b1a-ecf7-4505-a59e-70e012ba8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f421c514-5587-4858-a5fa-0ac562c7c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load data from CSV file using pandas\n",
    "df = pd.read_csv('data1.csv')\n",
    "\n",
    "# Split the dataframe into x and y tensors\n",
    "x = torch.from_numpy(df[['x1', 'x2']].to_numpy()).to(torch.float32)\n",
    "y = torch.from_numpy(df['y'].to_numpy(dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ef594b-5286-4098-a228-a1effcd46771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_23904\\1740726160.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(x.T).float().T\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_23904\\1740726160.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_unique = torch.unique(torch.tensor(y))\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_23904\\1740726160.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_indices = torch.searchsorted(y_unique, torch.tensor(y))\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(x.T).float().T\n",
    "\n",
    "# Convert y to a tensor of indices and one-hot encode it\n",
    "y_unique = torch.unique(torch.tensor(y))\n",
    "y_indices = torch.searchsorted(y_unique, torch.tensor(y))\n",
    "y_train = nn.functional.one_hot(y_indices, num_classes=len(y_unique)).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38efd010-fddb-438a-b086-d817ca685a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(x, y_train))\n",
    "n_hidden = 3\n",
    "D = X.shape[1]\n",
    "out_dim = y_train.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, n_hidden),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_hidden, out_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d4c1b7-9dd9-4e4e-bbde-5c6fcfa6f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "epochs = 100\n",
    "avg_loss = lambda data: torch.mean(torch.stack([loss_fn(model(x), y) for (x, y) in data]))\n",
    "show_every = epochs // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e66f99-2410-477f-b30f-eebbac5abf66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10\n",
      "Avg Loss:  1.1412208080291748\n",
      "Epoch  20\n",
      "Avg Loss:  0.782179057598114\n",
      "Epoch  30\n",
      "Avg Loss:  0.511333703994751\n",
      "Epoch  40\n",
      "Avg Loss:  0.3474577069282532\n",
      "Epoch  50\n",
      "Avg Loss:  0.24560989439487457\n",
      "Epoch  60\n",
      "Avg Loss:  0.17748203873634338\n",
      "Epoch  70\n",
      "Avg Loss:  0.12997011840343475\n",
      "Epoch  80\n",
      "Avg Loss:  0.09598128497600555\n",
      "Epoch  90\n",
      "Avg Loss:  0.07127176225185394\n",
      "Epoch  100\n",
      "Avg Loss:  0.05311905965209007\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    for (x, y) in data:\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if epoch % show_every == 0:\n",
    "        print(\"Epoch \", epoch)\n",
    "        print(\"Avg Loss: \", avg_loss(data).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b95a56-8936-4f47-be79-6a9007d2fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(model, 'classification',\n",
    "             subset_of_weights='all',\n",
    "             hessian_structure='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36eedab5-ad96-4272-8626-485de48d4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "la.fit(DataLoader(TensorDataset(X, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d1e48d-47a8-448c-ad2b-7d6ddb343b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "la.optimize_prior_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fd6544-412c-4bda-911c-c4314a0683b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probit_predictions = la(X, link_approx='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41ff86f-cf3f-497f-9fb9-8b066bad02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_probit_df = pd.DataFrame(probit_predictions.numpy(), columns=['class1', 'class2', 'class3', 'class4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d01fca-036e-4d17-8e00-377df5ad58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_probit_df.to_csv('predictions1-Python.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af060a6-43b6-4101-8825-244ec1292c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6695, 0.0289, 0.1736, 0.1279],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6693, 0.0289, 0.1735, 0.1282],\n",
      "        [0.6699, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6699, 0.0287, 0.1739, 0.1275],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6693, 0.0288, 0.1744, 0.1275],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6695, 0.0288, 0.1743, 0.1274],\n",
      "        [0.6699, 0.0287, 0.1738, 0.1276],\n",
      "        [0.6698, 0.0288, 0.1738, 0.1277],\n",
      "        [0.6296, 0.0412, 0.1714, 0.1578],\n",
      "        [0.6698, 0.0288, 0.1738, 0.1276],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6674, 0.0293, 0.1742, 0.1290],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6698, 0.0287, 0.1742, 0.1273],\n",
      "        [0.6699, 0.0287, 0.1741, 0.1273],\n",
      "        [0.6608, 0.0313, 0.1718, 0.1361],\n",
      "        [0.6510, 0.0342, 0.1717, 0.1432],\n",
      "        [0.6700, 0.0287, 0.1740, 0.1274],\n",
      "        [0.6666, 0.0294, 0.1772, 0.1268],\n",
      "        [0.0302, 0.7201, 0.0820, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7211, 0.0813, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0813, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7208, 0.0812, 0.1680],\n",
      "        [0.0300, 0.7210, 0.0814, 0.1675],\n",
      "        [0.0302, 0.7199, 0.0819, 0.1680],\n",
      "        [0.0300, 0.7209, 0.0816, 0.1675],\n",
      "        [0.0300, 0.7210, 0.0812, 0.1678],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7211, 0.0814, 0.1675],\n",
      "        [0.0300, 0.7211, 0.0814, 0.1675],\n",
      "        [0.0300, 0.7206, 0.0813, 0.1681],\n",
      "        [0.0300, 0.7211, 0.0813, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0302, 0.7203, 0.0820, 0.1675],\n",
      "        [0.0300, 0.7211, 0.0814, 0.1675],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.0300, 0.7212, 0.0812, 0.1676],\n",
      "        [0.1737, 0.0747, 0.7184, 0.0332],\n",
      "        [0.1734, 0.0747, 0.7187, 0.0332],\n",
      "        [0.1734, 0.0747, 0.7187, 0.0332],\n",
      "        [0.1738, 0.0747, 0.7183, 0.0332],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1816, 0.0819, 0.6996, 0.0369],\n",
      "        [0.1828, 0.0829, 0.6970, 0.0373],\n",
      "        [0.1926, 0.0960, 0.6671, 0.0443],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1740, 0.0762, 0.7156, 0.0341],\n",
      "        [0.1740, 0.0761, 0.7159, 0.0340],\n",
      "        [0.1781, 0.0793, 0.7069, 0.0357],\n",
      "        [0.1737, 0.0759, 0.7164, 0.0340],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1734, 0.0747, 0.7187, 0.0332],\n",
      "        [0.1730, 0.0759, 0.7172, 0.0339],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1734, 0.0747, 0.7187, 0.0332],\n",
      "        [0.1736, 0.0747, 0.7185, 0.0332],\n",
      "        [0.1735, 0.0749, 0.7184, 0.0333],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1737, 0.0766, 0.7154, 0.0343],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1735, 0.0747, 0.7186, 0.0331],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1279, 0.1599, 0.0355, 0.6766],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1273, 0.1627, 0.0362, 0.6739],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6766],\n",
      "        [0.1279, 0.1599, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1277, 0.1603, 0.0355, 0.6764],\n",
      "        [0.1274, 0.1626, 0.0362, 0.6738],\n",
      "        [0.1279, 0.1600, 0.0355, 0.6766],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6766],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1278, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1285, 0.1599, 0.0357, 0.6758],\n",
      "        [0.1277, 0.1601, 0.0355, 0.6767],\n",
      "        [0.1286, 0.1595, 0.0356, 0.6763],\n",
      "        [0.1287, 0.1594, 0.0356, 0.6763]])\n"
     ]
    }
   ],
   "source": [
    "print(probit_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c808641c-6918-47fc-b820-7b1f7e2b4732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9486,     0.0002,     0.0351,     0.0161],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9485,     0.0002,     0.0351,     0.0162],\n",
      "        [    0.9487,     0.0002,     0.0353,     0.0158],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0159],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9483,     0.0002,     0.0356,     0.0159],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9485,     0.0002,     0.0355,     0.0159],\n",
      "        [    0.9487,     0.0002,     0.0352,     0.0159],\n",
      "        [    0.9487,     0.0002,     0.0352,     0.0160],\n",
      "        [    0.9451,     0.0002,     0.0341,     0.0205],\n",
      "        [    0.9487,     0.0002,     0.0352,     0.0160],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9473,     0.0002,     0.0359,     0.0167],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9486,     0.0002,     0.0354,     0.0158],\n",
      "        [    0.9487,     0.0002,     0.0353,     0.0158],\n",
      "        [    0.9463,     0.0002,     0.0347,     0.0189],\n",
      "        [    0.9455,     0.0002,     0.0344,     0.0199],\n",
      "        [    0.9488,     0.0002,     0.0352,     0.0158],\n",
      "        [    0.9470,     0.0002,     0.0370,     0.0158],\n",
      "        [    0.0007,     0.9450,     0.0090,     0.0452],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9453,     0.0088,     0.0452],\n",
      "        [    0.0007,     0.9455,     0.0089,     0.0449],\n",
      "        [    0.0007,     0.9448,     0.0090,     0.0454],\n",
      "        [    0.0007,     0.9454,     0.0089,     0.0450],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0450],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9453,     0.0088,     0.0452],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9452,     0.0090,     0.0450],\n",
      "        [    0.0007,     0.9455,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0007,     0.9456,     0.0088,     0.0449],\n",
      "        [    0.0481,     0.0065,     0.9445,     0.0008],\n",
      "        [    0.0479,     0.0066,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0481,     0.0065,     0.9445,     0.0008],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0478,     0.0075,     0.9437,     0.0009],\n",
      "        [    0.0478,     0.0076,     0.9437,     0.0009],\n",
      "        [    0.0479,     0.0090,     0.9420,     0.0011],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0069,     0.9443,     0.0009],\n",
      "        [    0.0479,     0.0069,     0.9443,     0.0009],\n",
      "        [    0.0478,     0.0073,     0.9440,     0.0009],\n",
      "        [    0.0479,     0.0069,     0.9443,     0.0009],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0066,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0069,     0.9443,     0.0009],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0480,     0.0065,     0.9446,     0.0008],\n",
      "        [    0.0481,     0.0066,     0.9445,     0.0009],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0070,     0.9442,     0.0009],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0479,     0.0065,     0.9447,     0.0008],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0161,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0297,     0.0004,     0.9540],\n",
      "        [    0.0160,     0.0285,     0.0004,     0.9552],\n",
      "        [    0.0161,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0286,     0.0004,     0.9550],\n",
      "        [    0.0160,     0.0295,     0.0004,     0.9542],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0285,     0.0004,     0.9551],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0164,     0.0286,     0.0004,     0.9546],\n",
      "        [    0.0160,     0.0284,     0.0004,     0.9552],\n",
      "        [    0.0163,     0.0283,     0.0004,     0.9550],\n",
      "        [    0.0164,     0.0283,     0.0004,     0.9550]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(torch.softmax(model(X), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac439d6-5d33-42ed-b2a6-3160095a4364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
