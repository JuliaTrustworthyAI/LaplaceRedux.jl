using .Curvature: Kron, KronDecomposed, mm
using Flux
using Flux.Optimise: Adam, update!
using Flux.Optimisers: destructure
using LinearAlgebra
using MLUtils
using Parameters

function _fit!(la::Laplace, data; batched::Bool=false, batchsize::Int, override::Bool=true)
    if override
        H = _init_H(la)
        loss = 0.0
        n_data = 0
    end

    for d in data
        loss_batch, H_batch = hessian_approximation(la, d; batched=batched)
        loss += loss_batch
        H += H_batch
        n_data += batchsize
    end

    # Store output:
    la.loss = loss
    # Hessian
    la.H = H
    # Posterior precision
    la.P = posterior_precision(la)
    # Posterior covariance
    la.Î£ = posterior_covariance(la, la.P)
    la.curvature.params = get_params(la)
    # Number of observations
    return la.n_data = n_data
end

"""
functional_variance(la::Laplace,ğ‰)

Compute the linearized GLM predictive variance as `ğ‰â‚™Î£ğ‰â‚™'` where `ğ‰=âˆ‡f(x;Î¸)|Î¸Ì‚` is the Jacobian evaluated at the MAP estimate and `Î£ = Pâ»Â¹`.
"""
function functional_variance(la::Laplace, ğ‰)
    Î£ = posterior_covariance(la)
    fvar = map(j -> (j' * Î£ * j), eachrow(ğ‰))
    return fvar
end
