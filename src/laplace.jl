using .Curvature
using Flux
using Flux.Optimise: Adam, update!
using Flux.Optimisers: destructure
using LinearAlgebra
using MLJFlux

mutable struct Laplace <: BaseLaplace
    model::Union{Flux.Chain,MLJFlux.MLJFluxModel}
    likelihood::Symbol
    subset_of_weights::Symbol
    hessian_structure::Symbol
    curvature::Union{Curvature.CurvatureInterface,Nothing}
    Ïƒ::Real
    Î¼â‚€::Real
    Î¼::AbstractVector
    Pâ‚€::Union{AbstractMatrix,UniformScaling}
    H::Union{AbstractArray,Nothing}
    P::Union{AbstractArray,Nothing}
    Î£::Union{AbstractArray,Nothing}
    n_params::Union{Int,Nothing}
    n_data::Union{Int,Nothing}
    n_out::Union{Int,Nothing}
    loss::Real
end

using Parameters

@with_kw struct LaplaceParams 
    subset_of_weights::Symbol=:all
    hessian_structure::Symbol=:full
    backend::Symbol=:EmpiricalFisher
    Ïƒ::Real=1.0
    Î¼â‚€::Real=0.0
    Î»::Real=1.0
    Pâ‚€::Union{Nothing,AbstractMatrix,UniformScaling}=nothing
    loss::Real=0.0
end

"""
    Laplace(model::Any; loss_fun::Union{Symbol, Function}, kwargs...)    

Wrapper function to prepare Laplace approximation.
"""
function Laplace(model::Any; likelihood::Symbol, kwargs...) 

    # Load hyperparameters:
    args = LaplaceParams(;kwargs...)

    # Assertions:
    @assert !(args.Ïƒ != 1.0 && likelihood != :regression) "Observation noise Ïƒ â‰  1 only available for regression."
    @assert args.subset_of_weights âˆˆ [:all, :last_layer] "`subset_of_weights` of weights should be one of the following: `[:all, :last_layer]`"

    # Setup:
    Pâ‚€ = isnothing(args.Pâ‚€) ? UniformScaling(args.Î») : args.Pâ‚€
    nn = model
    n_out = outdim(nn)
    Î¼ = reduce(vcat, [vec(Î¸) for Î¸ âˆˆ Flux.params(nn)])

    # Instantiate LA:
    la = Laplace(
        model, likelihood, 
        args.subset_of_weights, args.hessian_structure, nothing, 
        args.Ïƒ, args.Î¼â‚€, Î¼, Pâ‚€, 
        nothing, nothing, nothing, nothing, nothing,
        n_out, args.loss
    )
    params = get_params(la)
    la.curvature = getfield(Curvature,args.backend)(nn,likelihood,params)   # curvature interface
    la.n_params = length(reduce(vcat, [vec(Î¸) for Î¸ âˆˆ params]))             # number of params
    la.Î¼ = la.Î¼[(end-la.n_params+1):end]                                    # adjust weight vector
    if typeof(la.Pâ‚€) <: UniformScaling
        la.Pâ‚€ = la.Pâ‚€(la.n_params)
    end

    # Sanity:
    if isa(la.Pâ‚€, AbstractMatrix)
        @assert all(size(la.Pâ‚€) .== la.n_params) "Dimensions of prior Hessian $(size(la.Pâ‚€)) do not align with number of parameters ($(la.n_params))"
    end

    return la

end

"""
    functional_variance(la::Laplace,ğ‰)

Compute the linearized GLM predictive variance as `ğ‰â‚™Î£ğ‰â‚™'` where `ğ‰=âˆ‡f(x;Î¸)|Î¸Ì‚` is the Jacobian evaluated at the MAP estimate and `Î£ = Pâ»Â¹`.

"""
function functional_variance(la::Laplace,ğ‰)
    Î£ = posterior_covariance(la)
    fvar = map(j -> (j' * Î£ * j), eachcol(ğ‰))
    return fvar
end


