# Packages
using LinearAlgebra
include("optim.jl")

âˆ‘(vector)=sum(vector)

# Sigmoid function:
function ğ›”(a)
    trunc = 8.0 # truncation to avoid numerical over/underflow
    a = clamp.(a,-trunc,trunc)
    p = exp.(a)
    p = p ./ (1 .+ p)
    return p
end

# Negative log likelihood
function ğ“(w,w_0,H_0,X,y)
    N = length(y)
    D = size(X)[2]
    Î¼ = ğ›”(X*w)
    Î”w = w-w_0
    return - âˆ‘( y[n] * log(Î¼[n]) + (1-y[n]) * log(1-Î¼[n]) for n=1:N) + 1/2 * Î”w'H_0*Î”w
end

# Gradient:
function âˆ‡ğ“(w,w_0,H_0,X,y)
    N = length(y)
    Î¼ = ğ›”(X*w)
    Î”w = w-w_0
    g = âˆ‘((Î¼[n]-y[n]) * X[n,:] for n=1:N)
    return g + H_0*Î”w
end

# Hessian:
function âˆ‡âˆ‡ğ“(w,w_0,H_0,X,y)
    N = length(y)
    Î¼ = ğ›”(X*w)
    H = âˆ‘(Î¼[n] * (1-Î¼[n]) * X[n,:] * X[n,:]' for n=1:N)
    return H + H_0
end

# Main function:
struct BayesLogreg
    Î¼::Vector{Float64}
    Î£::Matrix{Float64}
    ğ‡â‚€::Any
    ğ‡::AbstractArray
    Î£Ì‚::Union{AbstractArray,Nothing}
end

function bayes_logreg(X,y;w_0=nothing,H_0=nothing,ğ“=ğ“,âˆ‡ğ“=âˆ‡ğ“,âˆ‡âˆ‡ğ“=âˆ‡âˆ‡ğ“,constant=true,Î»=1,optim_options...)
    # Setup:
    if constant
        if !all(X[:,1] .== 1)
            X = hcat(ones(size(X)[1]), X)
        else
        end
    end
    N, D = size(X)
    if isnothing(w_0)
        w_0 = zeros(D)
    end
    if isnothing(H_0)
        H_0 = UniformScaling(Î»)
    end
    
    # Model:
    w_map, H_map = newton(ğ“, w_0, âˆ‡ğ“, âˆ‡âˆ‡ğ“, (w_0=w_0, H_0=H_0, X=X, y=y), optim_options...) # fit the model (find mode of posterior distribution)
    Î£_map = inv(H_map) # inverse Hessian at the mode
    Î£_map = Symmetric(Î£_map) # to ensure matrix is Hermitian (i.e. avoid rounding issues)
    
    # Output:
    mod = BayesLogreg(w_map, Î£_map, H_0, H_map, Î£_map)
    return mod
end


#  ------------ Outer constructor methods: ------------
# Accessing fields:
Î¼(mod::BayesLogreg) = mod.Î¼
Î£(mod::BayesLogreg) = mod.Î£
# Coefficients:
coef(mod::BayesLogreg) = mod.Î¼ 

# Sampling from posterior distribution:
using Distributions
sample_posterior(mod::BayesLogreg, n) = rand(MvNormal(mod.Î¼, mod.Î£),n)

# Predictive distribution:
function glm_predictive_distribution(mod::BayesLogreg, X::AbstractArray)
    Î¼ = mod.Î¼ # MAP mean vector
    Î£ = mod.Î£ # MAP covariance matrix
    if !isa(X, Matrix)
        # turn into matrix if necessary:
        X = reshape(X, 1, length(X))
    end
    if size(Î¼)[1] > size(X)[2]
        # add constant if necessary:
        X = hcat(ones(size(X)[1]),X)
    end
    # Predictions:
    yÌ‚ = X*Î¼
    # Predictive variance
    ÏƒÌ‚ = [X[n,:]'Î£*X[n,:] for n=1:size(X)[1]]
    ÏƒÌ‚ = reshape(ÏƒÌ‚, size(yÌ‚)...)
    return yÌ‚, ÏƒÌ‚
end

# Posterior predictions:
function predict(mod::BayesLogreg, X)
    yÌ‚, ÏƒÌ‚ = glm_predictive_distribution(mod, X)
    # Probit approximation
    Îº = 1 ./ sqrt.(1 .+ Ï€/8 .* ÏƒÌ‚) 
    z = Îº .* yÌ‚
    # Truncation to avoid numerical over/underflow:
    trunc = 8.0 
    z = clamp.(z,-trunc,trunc)
    p = exp.(z)
    p = p ./ (1 .+ p)
    return p
end

# Plugin estimate (MAP)
function plugin(mod::BayesLogreg, X)
    yÌ‚, ÏƒÌ‚ = glm_predictive_distribution(mod, X)
    p = Flux.Ïƒ.(yÌ‚)
    return p
end