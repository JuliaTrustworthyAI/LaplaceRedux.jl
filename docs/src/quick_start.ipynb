{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```@meta\n",
    "CurrentModule = BayesLaplace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚îå Error: Failed to revise /Users/FA31DU/Library/CloudStorage/OneDrive-DelftUniversityofTechnology/git/BayesLaplace.jl/src/logit.jl\n",
      "‚îÇ   exception = Revise.ReviseEvalException(\"/Users/FA31DU/Library/CloudStorage/OneDrive-DelftUniversityofTechnology/git/BayesLaplace.jl/src/logit.jl:43\", ErrorException(\"invalid redefinition of constant BayesLogreg\"), Any[(top-level scope at logit.jl:43, 1)])\n",
      "‚îî @ Revise /Users/FA31DU/.julia/packages/Revise/jHTGK/src/packagedef.jl:708\n",
      "‚îå Warning: The running code does not match the saved version for the following files:\n",
      "‚îÇ \n",
      "‚îÇ   /Users/FA31DU/Library/CloudStorage/OneDrive-DelftUniversityofTechnology/git/BayesLaplace.jl/src/logit.jl\n",
      "‚îÇ \n",
      "‚îÇ If the error was due to evaluation order, it can sometimes be resolved by calling `Revise.retry()`.\n",
      "‚îÇ Use Revise.errors() to report errors again. Only the first error in each file is shown.\n",
      "‚îÇ Your prompt color may be yellow until the errors are resolved.\n",
      "‚îî @ Revise /Users/FA31DU/.julia/packages/Revise/jHTGK/src/packagedef.jl:818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogLevel(1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries.\n",
    "using Flux, Plots, Random, PlotThemes, Statistics, BayesLaplace\n",
    "theme(:juno)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points to generate.\n",
    "N = 100\n",
    "M = round(Int, N / 4)\n",
    "Random.seed!(1234)\n",
    "\n",
    "# Generate artificial data.\n",
    "x1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \n",
    "xt1s = Array([[x1s[i] + 0.5; x2s[i] + 0.5] for i = 1:M])\n",
    "x1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \n",
    "append!(xt1s, Array([[x1s[i] - 5; x2s[i] - 5] for i = 1:M]))\n",
    "\n",
    "x1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \n",
    "xt0s = Array([[x1s[i] + 0.5; x2s[i] - 5] for i = 1:M])\n",
    "x1s = rand(M) * 4.5; x2s = rand(M) * 4.5; \n",
    "append!(xt0s, Array([[x1s[i] - 5; x2s[i] + 0.5] for i = 1:M]))\n",
    "\n",
    "# Store all the data for later.\n",
    "xs = [xt1s; xt0s]\n",
    "X = hcat(xs...) # bring into tabular format\n",
    "ts = [ones(2*M); zeros(2*M)];\n",
    "\n",
    "plt = plot()\n",
    "\n",
    "# Plot data points.\n",
    "function plot_data!(plt,X,y)\n",
    "    Plots.scatter!(plt, X[y.==1.0,1],X[y.==1.0,2], color=1, clim = (0,1), label=\"y=1\")\n",
    "    Plots.scatter!(plt, X[y.==0.0,1],X[y.==0.0,2], color=0, clim = (0,1), label=\"y=0\")\n",
    "end\n",
    "\n",
    "plt = plot_data!(plt,X',ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(2, 128, œÉ),                     \u001b[90m# 384 parameters\u001b[39m\n",
       "  Dense(128, 1),                        \u001b[90m# 129 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m513 parameters, 2.254 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function build_model(;input_dim=2,n_hidden=128,output_dim=1)\n",
    "    \n",
    "    # Params:\n",
    "    W‚ÇÅ = input_dim\n",
    "    b‚ÇÅ = n_hidden\n",
    "    W‚ÇÄ = n_hidden\n",
    "    b‚ÇÄ = output_dim\n",
    "    \n",
    "    nn = Chain(\n",
    "        Dense(W‚ÇÅ, b‚ÇÅ, œÉ),\n",
    "        Dense(W‚ÇÄ, b‚ÇÄ))  \n",
    "\n",
    "    return nn\n",
    "\n",
    "end\n",
    "nn = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Œª = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqnorm(x) = sum(abs2, x)\n",
    "weight_regularization(Œª=Œª) = 1/2 * Œª^2 * sum(sqnorm, Flux.params(nn))\n",
    "\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y) + weight_regularization()\n",
    "ps = Flux.params(nn)\n",
    "data = zip(xs,ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Optimise: update!, ADAM\n",
    "opt = ADAM()\n",
    "epochs = 200\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "\n",
    "using Plots\n",
    "anim = Animation()\n",
    "plt = plot(ylim=(0,avg_loss(data)), xlim=(0,epochs), legend=false, xlab=\"Epoch\")\n",
    "avg_l = []\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, params(nn), gs)\n",
    "  end\n",
    "  avg_l = vcat(avg_l,avg_loss(data))\n",
    "  plot!(plt, avg_l, color=1, title=\"Average (training) loss\")\n",
    "  frame(anim, plt)\n",
    "end\n",
    "\n",
    "gif(anim, \"www/nn_training.gif\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/nn_training.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive(ùë¥::Flux.Chain, X::AbstractArray) = Flux.œÉ.(nn(X))\n",
    "# Plot the posterior distribution with a contour plot.\n",
    "function plot_contour(X,y,ùë¥;clegend=true,title=\"\",length_out=30)\n",
    "    x_range = collect(range(minimum(X[:,1]),stop=maximum(X[:,1]),length=length_out))\n",
    "    y_range = collect(range(minimum(X[:,2]),stop=maximum(X[:,2]),length=length_out))\n",
    "    Z = [predictive(ùë¥,[x, y])[1] for x=x_range, y=y_range]\n",
    "    plt = contourf(x_range, y_range, Z', color=:plasma, legend=clegend, title=title, linewidth=0)\n",
    "    plot_data!(plt,X,y)\n",
    "end\n",
    "p_plugin = plot_contour(X',ts,nn;title=\"Plugin\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace appoximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = laplace(nn, Œª=Œª)\n",
    "fit!(la, data);\n",
    "predictive(ùë¥::BayesLaplace.LaplaceRedux, X::AbstractArray) = predict(ùë¥, X)\n",
    "p_laplace = plot_contour(X',ts,la;title=\"Laplace\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior distribution with a contour plot.\n",
    "plt = plot(p_plugin, p_laplace, layout=(1,2), size=(1000,400));\n",
    "savefig(plt, \"www/posterior_predictive.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/posterior_predictive.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
